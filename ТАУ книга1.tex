% This file was converted to LaTeX by Writer2LaTeX ver. 1.4
% see http://writer2latex.sourceforge.net for more info
\documentclass[a4paper]{article}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{fontspec}   
\defaultfontfeatures{Ligatures={TeX},Renderer=Basic}  %% свойства шрифтов по умолчанию
\setmainfont[Ligatures={TeX,Historic}]{Arial} %% задаёт основной шрифт документа
\setsansfont{Comic Sans MS}                    %% задаёт шрифт без засечек
\setmonofont{Courier New}

\usepackage{indentfirst}
\usepackage{xunicode}
\usepackage{xltxtra}
\usepackage{polyglossia}
\setdefaultlanguage{russian}
\setotherlanguage[variant=american]{english}
\usepackage{color}
\usepackage{array}
\usepackage{supertabular}
\usepackage{hhline}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue}
\usepackage{graphicx}
\usepackage{calc}
\newcommand\textsubscript[1]{\ensuremath{{}_{\text{#1}}}}
% Outline numbering
\setcounter{secnumdepth}{4}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\arabic{section}.\arabic{subsection}}
\renewcommand\thesubsubsection{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}
\renewcommand\theparagraph{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}.\arabic{paragraph}}
\makeatletter
\newcommand\arraybslash{\let\\\@arraycr}
\makeatother
% List styles
\newcounter{saveenum}
\newcommand\liststyleWWviiiNumxiii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxvii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxxi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumvii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumlxxiii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumli{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxxvii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi).}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxviii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi).}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxxiv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi)}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumx{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxxxix{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxlviii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxlvi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumlxxvii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxlii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumlxxi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumlxix{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumlxxviii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxxxvii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumviii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumlii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi)}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxxv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxxii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi)}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxx{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi).}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxxxiv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi)}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxvi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumliii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumliv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxxxvi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxlv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxxx{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxlvii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxiv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\labelitemi{}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
}
\newcommand\liststyleWWviiiNumxxxi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxxii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxxv{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\alph{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxxix{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxxvi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxxix{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxliii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlix{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxxx{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\arabic{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxvi{%
\renewcommand\theenumi{\Roman{enumi}}
\renewcommand\theenumii{\alph{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxxvi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\alph{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumix{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\alph{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxvii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\alph{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNuml{%
\renewcommand\theenumi{\Roman{enumi}}
\renewcommand\theenumii{\arabic{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumxxxviii{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\alph{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
\newcommand\liststyleWWviiiNumlxi{%
\renewcommand\theenumi{\arabic{enumi}}
\renewcommand\theenumii{\alph{enumii}}
\renewcommand\theenumiii{\roman{enumiii}}
\renewcommand\theenumiv{\arabic{enumiv}}
\renewcommand\labelenumi{\theenumi.}
\renewcommand\labelenumii{\theenumii.}
\renewcommand\labelenumiii{\theenumiii.}
\renewcommand\labelenumiv{\theenumiv.}
}
% Page layout (geometry)
\setlength\voffset{-1in}
\setlength\hoffset{-1in}
\setlength\topmargin{1.501cm}
\setlength\oddsidemargin{2cm}
\setlength\textheight{25.568cm}
\setlength\textwidth{17.001cm}
\setlength\footskip{1.3610001cm}
\setlength\headheight{0cm}
\setlength\headsep{0cm}
% Footnote rule
\setlength{\skip\footins}{0.119cm}
\renewcommand\footnoterule{\vspace*{-0.018cm}\setlength\leftskip{0pt}\setlength\rightskip{0pt plus 1fil}\noindent\textcolor{black}{\rule{0.25\columnwidth}{0.018cm}}\vspace*{0.101cm}}
% Pages styles
\makeatletter
\newcommand\ps@Standard{
  \renewcommand\@oddhead{}
  \renewcommand\@evenhead{}
  \renewcommand\@oddfoot{[Warning: Draw object ignored]}
  \renewcommand\@evenfoot{\@oddfoot}
  \renewcommand\thepage{\arabic{page}}
}
\newcommand\ps@ii{
  \renewcommand\@oddhead{}
  \renewcommand\@evenhead{}
  \renewcommand\@oddfoot{[Warning: Draw object ignored]}
  \renewcommand\@evenfoot{\@oddfoot}
  \renewcommand\thepage{\arabic{page}}
}
\newcommand\ps@i{
  \renewcommand\@oddhead{}
  \renewcommand\@evenhead{}
  \renewcommand\@oddfoot{[Warning: Draw object ignored]}
  \renewcommand\@evenfoot{\@oddfoot}
  \renewcommand\thepage{\arabic{page}}
}
\makeatother
\pagestyle{Standard}
\setlength\tabcolsep{1mm}
\renewcommand\arraystretch{1.3}
\newcommand\wideslash[2]{{}^{#1}/_{#2}}
\newcommand\boldsubformula[1]{\text{\mathversion{bold}$#1$}}
\newcommand\normalsubformula[1]{\text{\mathversion{normal}$#1$}}
\newlength{\idxmathdepth}\newlength{\idxmathtotal}\newlength{\idxmathwidth}\newlength{\idxraiseme}
\newcommand{\idxdheight}[1]{\protect\settoheight{\idxmathtotal}{\(\displaystyle#1\)}\protect\settodepth{\idxmathdepth}{\(\displaystyle#1\)}\protect\settowidth{\idxmathwidth}{\(\displaystyle#1\)}\protect\addtolength{\idxmathtotal}{\idxmathdepth}\protect\setlength{\idxraiseme}{\idxmathtotal/2-\idxmathdepth}}
\newcommand{\idxtheight}[1]{\protect\settoheight{\idxmathtotal}{\(\textstyle #1\)}\protect\settodepth{\idxmathdepth}{\(\textstyle #1\)}\protect\settowidth{\idxmathwidth}{\(\textstyle#1\)}\protect\addtolength{\idxmathtotal}{\idxmathdepth}\protect\setlength{\idxraiseme}{\idxmathtotal/2-\idxmathdepth}}
\newcommand{\idxsheight}[1]{\protect\settoheight{\idxmathtotal}{\(\scriptstyle #1\)}\protect\settodepth{\idxmathdepth}{\(\scriptstyle #1\)}\protect\settowidth{\idxmathwidth}{\(\scriptstyle#1\)}\protect\addtolength{\idxmathtotal}{\idxmathdepth}\protect\setlength{\idxraiseme}{\idxmathtotal/2-\idxmathdepth}}
\newcommand{\idxssheight}[1]{\protect\settoheight{\idxmathtotal}{\(\scriptscriptstyle #1\)}\protect\settodepth{\idxmathdepth}{\(\scriptscriptstyle #1\)}\protect\settowidth{\idxmathwidth}{\(\scriptscriptstyle#1\)}\protect\addtolength{\idxmathtotal}{\idxmathdepth}\protect\setlength{\idxraiseme}{\idxmathtotal/2-\idxmathdepth}}
\newcommand\multiscripts[5]{\mathchoice{\idxdheight{#4}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#1\underset{#2}{\overset{#3}{#4}}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#5}{\idxtheight{#4}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#1\underset{#2}{\overset{#3}{#4}}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#5}{\idxsheight{#4}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#1\underset{#2}{\overset{#3}{#4}}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#5}{\idxssheight{#4}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#1\underset{#2}{\overset{#3}{#4}}\rule[-\idxmathdepth]{0mm}{\idxmathtotal}#5}}
\newcommand\mathoverstrike[1]{\mathchoice{\idxdheight{#1}\rlap{\rule[\idxraiseme]{\idxmathwidth}{0.4pt}}{#1}}{\idxtheight{#1}\rlap{\rule[\idxraiseme]{\idxmathwidth}{0.4pt}}{#1}}{\idxsheight{#1}\rlap{\rule[\idxraiseme]{\idxmathwidth}{0.4pt}}{#1}}{\idxssheight{#1}\rlap{\rule[\idxraiseme]{\idxmathwidth}{0.4pt}}{#1}}}
\title{ }
\author{Image\&Matros ®}
\date{2017-02-16}
\begin{document}

Рассчитаем левые собственные векторы. Учтем при этом (2.4.14). Таким образом, для первого собственного вектора  $\vec
d_1$ должны выполняться условия
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec d_1^T=ν_1\left[\begin{matrix}0&0&1\end{matrix}\right]\;,\;\;\;\;\;\vec d_1^T\vec v_1=2ν_1=1$,
\end{russian}}

{\begin{russian}\sffamily
откуда 
\end{russian}}

{\begin{russian}\sffamily
\ \  $ν_1=\frac 1 2$ \ \ \ и \ \ \  $\vec d_1^T=\left[\begin{matrix}0&0&0.5\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Аналогично получим
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec d_2=\left[\begin{matrix}0\\1\\-1\end{matrix}\right];_{}^{}\vec
d_3=\left[\begin{matrix}1\\-1\\0.5\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Теперь можно записать выражение для переходной матрицы. Из (2.4.28) имеем
\end{russian}}

\begin{equation*}
e^{\normalsubformula{\text{At}}}=\left[\begin{matrix}0&0&0.5\\0&0&1\\0&0&1\end{matrix}\right]e^{-t}+\left[\begin{matrix}0&1&-1\\0&1&-1\\0&0&0\end{matrix}\right]e^{-2t}+\left[\begin{matrix}1&-1&0.5\\0&0&0\\0&0&0\end{matrix}\right]e^{-3t}
\end{equation*}
{\begin{russian}\sffamily
и окончательно
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$e^{\normalsubformula{\text{At}}}=\left[\begin{matrix}e^{-3t}&e^{-2t}-e^{-3t}&0.5e^{-t}-e^{-2t}+0.5e^{-3t}\\0&e^{-2t}&e^{-t}-e^{-2t}\\0&0&e^{-t}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим ещё несколько примеров.
\end{russian}}

{\begin{russian}\sffamily
Для
\end{russian}}

\begin{equation*}
A=\left[\begin{matrix}-3&1&0\\0&-2&1\\0&0&-1\end{matrix}\right]\;;\;\;\;\;\;\;\;\;\;λ_1=-1\;;\;\;\;λ_2=-2\;;\;\;\;\;λ_3=-3
\end{equation*}
{\begin{russian}\sffamily
имеем
\end{russian}}

\begin{equation*}
\begin{matrix}\sqrt A=j\left[\begin{matrix}0\hfill\null &0\hfill\null &\frac 1 2\hfill\null \\0\hfill\null &0\hfill\null
&1\hfill\null \\0\hfill\null &0\hfill\null &1\hfill\null \end{matrix}\right]+j\sqrt 2\left[\begin{matrix}0\hfill\null
&1\hfill\null &-1\hfill\null \\0\hfill\null &1\hfill\null &-1\hfill\null \\0\hfill\null &0\hfill\null &0\hfill\null
\end{matrix}\right]+j\sqrt 3\left[\begin{matrix}1\hfill\null &-1\hfill\null &0.5\hfill\null \\0\hfill\null
&0\hfill\null &0\hfill\null \\0\hfill\null &0\hfill\null &0\hfill\null \end{matrix}\right]=\hfill\null
\\=j\left[\begin{matrix}\sqrt 3\hfill\null &\sqrt 2-\sqrt 3\hfill\null &\frac 1 2-\sqrt 2+\frac{\sqrt 3} 2\hfill\null
\\0\hfill\null &\sqrt 2\hfill\null &1-\sqrt 2\hfill\null \\0\hfill\null &0\hfill\null &1\hfill\null
\end{matrix}\right].\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Проведём проверку:
\end{russian}}

\begin{equation*}
\begin{matrix}j^2\left[\begin{matrix}\sqrt 3\hfill\null &\sqrt 2-\sqrt 3\hfill\null &\frac 1 2-\sqrt 2+\frac{\sqrt 3}
2\hfill\null \\0\hfill\null &\sqrt 2\hfill\null &1-\sqrt 2\hfill\null \\0\hfill\null &0\hfill\null &1\hfill\null
\end{matrix}\right]\cdot \left[\begin{matrix}\sqrt 3\hfill\null &\sqrt 2-\sqrt 3\hfill\null &\frac 1 2-\sqrt
2+\frac{\sqrt 3} 2\hfill\null \\0\hfill\null &\sqrt 2\hfill\null &1-\sqrt 2\hfill\null \\0\hfill\null &0\hfill\null
&1\hfill\null \end{matrix}\right]=\hfill\null \\=\left[\begin{matrix}-3\hfill\null &1\hfill\null &0\hfill\null
\\0\hfill\null &-2\hfill\null &1\hfill\null \\0\hfill\null &0\hfill\null &-1\hfill\null \end{matrix}\right].\hfill\null
\end{matrix}\hfill 
\end{equation*}

\bigskip

{\begin{russian}\sffamily
Для той же матрицы найдём  $A^5$:
\end{russian}}

{\begin{russian}\sffamily
 $λ_1^5=-1\;,\;\;\;\;\;λ_2^5=-32\;,\;\;\;\;\;λ_3^5=-243$ \ \ \ и
\end{russian}}

\begin{equation*}
\begin{matrix}A^5=-\left[\begin{matrix}0\hfill\null &0\hfill\null &\frac 1 2\hfill\null \\0\hfill\null &0\hfill\null
&1\hfill\null \\0\hfill\null &0\hfill\null &1\hfill\null \end{matrix}\right]-32\left[\begin{matrix}0\hfill\null
&1\hfill\null &-1\hfill\null \\0\hfill\null &1\hfill\null &-1\hfill\null \\0\hfill\null &0\hfill\null &0\hfill\null
\end{matrix}\right]-243\left[\begin{matrix}1\hfill\null &-1\hfill\null &\frac 1 2\hfill\null \\0\hfill\null
&0\hfill\null &0\hfill\null \\0\hfill\null &0\hfill\null &0\hfill\null \end{matrix}\right]=\hfill\null
\\=\left[\begin{matrix}-243\hfill\null &211\hfill\null &-90\hfill\null \\0\hfill\null &-32\hfill\null &31\hfill\null
\\0\hfill\null &0\hfill\null &-1\hfill\null \end{matrix}\right].\hfill\null \end{matrix}\hfill 
\end{equation*}
\subsection{Свойства движений линейных систем}
\hypertarget{RefHeadingToc455659705}{}\subsubsection{Матричная весовая и переходная функции}
\hypertarget{RefHeadingToc455659706}{}
\bigskip

{\begin{russian}\sffamily
Пусть заданы уравнения некоторого динамического объекта
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot x}(t)=A(t)\vec x+B(t)\vec u(t)$;\ \ (2.5.1)
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec y(t)=C(t)\vec x(t)$.\ \ (2.5.2)
\end{russian}}

{\begin{russian}\sffamily
В соответствии с формулой Коши выражение для вектора выхода 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec y(t)=C(t)Φ(t,t_0)\vec x(t_0)+\overset t{\underset{t\multiscripts{_0}{{}}{{}}{}{}}{\int }}C(t)Φ(t,ξ)B(ξ)\vec
u(ξ)\mathit{dξ}$.\ \ (2.5.3)
\end{russian}}

{\begin{russian}\sffamily
Анализируя качество работы объекта, удобно рассматривать движение  $\vec y(t)$ как сумму свободной составляющей,
обусловленной в основном свойствами самого объекта, и вынужденной составляющей, несущей отпечаток входного сигнала -
вектора управления. Строго говоря, это разделение условно, но очевидно, что свободную составляющую целесообразно
отождествить с первым слагаемым правой части равенства (2.5.3). Отсюда следует вывод, что основные свойства объекта
определяются его переходной матрицей  $Φ\left(t,t_0\right)$, в то время как степень их проявления зависит от вектора
начальных условий.
\end{russian}}

{\begin{russian}\sffamily
Отметим, однако, что первопричиной всякого движения объекта является вектор управления. Это означает, что даже при
анализе собственных движений объекта следует учитывать и матрицу управления  $B(t)$. 
\end{russian}}

{\begin{russian}\sffamily
Обозначим 
\end{russian}}

{\begin{russian}\sffamily
\ \  $w_y\left(t,τ\right)=C\left(t\right)Φ\left(t,τ\right)B\left(τ\right)$.\ \ (2.5.4)
\end{russian}}

{\begin{russian}\sffamily
Очевидно, что для  $i$-й координаты вектора выхода при нулевых начальных условиях справедливо выражение 
\end{russian}}

{\begin{russian}\sffamily
\ \  $y_i\left(t\right)=\overset t{\underset{t_0}{\int }}\overset{n_u}{\underset{j=1}{\sum
}}w_{\normalsubformula{\text{ij}}}\left(t,ξ\right)u_j\left(ξ\right)\mathit{dξ}$.
\end{russian}}

{\begin{russian}\sffamily
Если положить 
\end{russian}}

\begin{equation*}
u_k(ξ)=δ(ξ-τ)
\end{equation*}
{\begin{russian}\sffamily
и  $u_j(ξ)=0$ при  $j\neq k$, то в соответствии со свойствами  $δ$-функции получим
\end{russian}}

{\begin{russian}\sffamily
\ \  $y_i(t)=w_{\normalsubformula{\text{ik}}}(t,τ)$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, \textit{элемент, стоящий в } $i$\textit{-й строке и в } $k$\textit{-м столбце матрицы }
$w_y\left(t,τ\right)$\textit{, можно интерпретировать как реакцию } $i$\textit{-й координаты вектора } $\vec
y\left(t\right)$\textit{ на дельта-функцию } $δ\left(t-τ\right)$\textit{ в } $k$\textit{-й координате вектора
управления } $\vec u\left(t\right)$\textit{.}
\end{russian}}

{\begin{russian}\sffamily
Матрица  $w_y\left(t,τ\right)$ называется \textit{матричной весовой или матричной импульсной переходной функцией}
объекта по вектору выхода. Аналогич­ным образом определяется матричная весовая функция объекта по вектору состояния
\end{russian}}

{\begin{russian}\sffamily
\ \  $w_x\left(t,τ\right)=Φ\left(t,τ\right)B\left(τ\right)$.\ \ (2.5.5)
\end{russian}}

{\centering  \includegraphics[width=14.776cm,height=5.068cm]{1-img021.png} \par}

\bigskip

{\begin{russian}\sffamily
\ \ Интеграл от матричной весовой функции
\end{russian}}

{\begin{russian}\sffamily
\ \  $H\left(t,t_0\right)=\overset t{\underset{t_0}{\int }}w\left(t,τ\right)\mathit{dτ}$\ \ (2.5.6)
\end{russian}}

{\begin{russian}\sffamily
называют матричной переходной функцией объекта. Элементы этой матрицы могут рассматриваться как реакции координат
вектора выхода (вектора состояния) на единичные функции по соответствующим координатам вектора управления. Если на вход
объекта поступает постоянный во времени вектор управления  $\vec u_0\times 1(t-t_0)$, то при нулевых начальных условиях
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec y\left(t\right)=H\left(t,t_0\right)\vec u_0$.\ \ (2.5.7)
\end{russian}}

{\begin{russian}\sffamily
В качестве примера на рис. 2.12 изображены элементы матричной переходной \ функции по вектору состояния для системы,
представленной на рис. 2.11.
\end{russian}}

{\centering  \includegraphics[width=14.002cm,height=10.305cm]{1-img022.png} \par}

\bigskip

{\begin{russian}\sffamily
В стационарном случае рассмотренные матрицы являются функцией одного аргумента:
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$w_y\left(t,t_0\right)=w_y\left(t-t_0\right)=w_y\left(τ\right)=\normalsubformula{\text{Ce}}^{\mathit{Aτ}}B=\mathit{CΦ}\left(τ\right)B$\ \ (2.5.8)
\end{russian}}

{\begin{russian}\sffamily
и 
\end{russian}}

{\begin{russian}\sffamily
\ \  $H_y\left(t\right)=\overset t{\underset 0{\int
}}\mathit{CF}\left(t-t\right)\normalsubformula{\text{Bd}}t$.\ \ (2.5.9)
\end{russian}}

{\begin{russian}\sffamily
Это выражение для переходной функции можно упростить. Производя замену аргумента
\end{russian}}

{\begin{russian}\sffamily
\ \  $s=t-t$,
\end{russian}}

{\begin{russian}\sffamily
получим
\end{russian}}

\begin{equation*}
H_y\left(t\right)=-\overset 0{\underset{σ=t}{\int }}\mathit{CΦ}\left(σ\right)\normalsubformula{\text{Bd}}σ
\end{equation*}
{\begin{russian}\sffamily
и окончательно
\end{russian}}

{\begin{russian}\sffamily
\ \  $H_y\left(t\right)=\overset t{\underset 0{\int
}}\mathit{CΦ}\left(τ\right)\normalsubformula{\text{Bd}}τ$.\ \ (2.5.10)
\end{russian}}

{\begin{russian}\sffamily
Используя представление переходной матрицы через матричную экспоненту, можно получить
\end{russian}}

{\begin{russian}\sffamily
\ \  $H_y\left(t\right)=C\left\{\normalsubformula{\text{Et}}+A\frac{t^2} 2+A^2\frac{t^3}{3!}+A^3\frac{t^4}{4!}+\ldots
\right\}B$.\ \ (2.5.11)
\end{russian}}

{\begin{russian}\sffamily
Один из наиболее употребимых способов вычисления  $Φ\left(t\right)$ и  $H\left(t\right)$ состоит в определении (расчете)
соответствующих окаймленных матричных рядов.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 2.5.1. Объект управления соответствует схеме в переменных состояния, приведенной на рис. 2.13.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=12.118cm,height=5.054cm]{1-img023.png} \par}

\bigskip

{\begin{russian}\sffamily
Этой схеме соответствуют уравнения
\end{russian}}

\begin{equation*}
\left\{\begin{matrix}\dot x_1=x_2,\\\dot x_2=-2x_2+u,\\y=2x_1+x_{2.}\end{matrix}\right.
\end{equation*}
{\begin{russian}\sffamily
Требуется найти переходную матрицу, матричные весовую и переходную функции, реакцию объекта на постоянный входной
сигнал.
\end{russian}}

{\begin{russian}\sffamily
Прежде всего, найдем переходную матрицу. Элемент первой строки и первого столбца этой матрицы можно определить как
реакцию координаты  $x_1$ на начальные условия  $x_1\left(0\right)=1,\;\;\;x_2\left(0\right)=0$ при  $u=0$. Решение
первого дифференциального уравнения дает 
\end{russian}}

\begin{equation*}
ϕ_{11}\left(t\right)=x_1\left(t\right)=1.
\end{equation*}
{\begin{russian}\sffamily
Аналогично
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_{22}\left(t\right)=x_2\left(t\right)$ \ \ при \ \  $x_2\left(0\right)=1,_{}^{}x_1\left(0\right)=u=0$.
\end{russian}}

{\begin{russian}\sffamily
Решая при этих условиях второе дифференциальное уравнение, получим 
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_{22}\left(t\right)=e^{-2t}$.
\end{russian}}

{\begin{russian}\sffamily
Очевидно,  $ϕ_{21}\left(t\right)=0$, так как координата  $x_2$ не зависит от  $x_1$. Для того чтобы определить 
$ϕ_{12}\left(t\right)$, следует взять интеграл
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $ϕ_{12}\left(t\right)=\overset t{\underset 0{\int }}e^{-2τ}\mathit{dτ}=0.5\left(1-e^{-2t}\right)$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом,
\end{russian}}

{\begin{russian}\sffamily
\ \  $Φ(t)=\left[\begin{matrix}1&0.5\left(1-e^{-2t}\right)\\0&e^{-2t}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
В соответствии с уравнениями объекта
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$A=\left[\begin{matrix}0&1\\0&-2\end{matrix}\right];_{}^{}B=\left[\begin{matrix}0\\1\end{matrix}\right];_{}^{}C=\left[\begin{matrix}2&1\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
поэтому
\end{russian}}

\begin{equation*}
w_y\left(t\right)=\mathit{CΦ}(t)B=1
\end{equation*}
{\begin{russian}\sffamily
и 
\end{russian}}

{\begin{russian}\sffamily
\ \  $H_y\left(t\right)=\overset t{\underset 0{\int }}\mathit{CΦ}\left(τ\right)\normalsubformula{\text{Bd}}τ=t$.
\end{russian}}

{\begin{russian}\sffamily
При нулевых начальных условиях и  $u=u_0=\normalsubformula{\text{const}}$
\end{russian}}

{\begin{russian}\sffamily
\ \  $y\left(t\right)=u_0\cdot t$.
\end{russian}}

{\begin{russian}\sffamily
Если начальные условия ненулевые, то
\end{russian}}

{\begin{russian}\sffamily
\ \  $y(t)=\mathit{CΦ}(t)\vec x\left(0\right)+u_0(t)=2x_1(0)+x_2(0)+u_0\cdot t$.
\end{russian}}

{\begin{russian}\sffamily
При этом
\end{russian}}

\begin{equation*}
\begin{matrix}\vec x(t)=Φ\left(t\right)\vec x\left(0\right)+H_x(t)u_0=Φ\left(t\right)\vec x\left(0\right)+\overset
t{\underset 0{\int }}Φ\left(τ\right)\normalsubformula{\text{Bd}}τ\cdot u_0=\hfill\null
\\=\left[\begin{matrix}x_1\left(0\right)+\frac 1 2\left(1-e^{-2t}\right)x_2\left(0\right)\hfill\null
\\e^{-2t}x_2\left(0\right)\hfill\null \end{matrix}\right]+\left[\begin{matrix}\frac 1 2t+\frac 1
4\left(e^{-2t}-1\right)\hfill\null \\\frac 1 2\left(1-e^{-2t}\right)\hfill\null \end{matrix}\right]u_0.\hfill\null
\end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Видно, что в выходной координате участвуют не все составляющие движения, присутствующие в векторе состояния. Еще более
характерная ситуация возникнет, если изменить исходные данные. Если положить
\end{russian}}

\begin{equation*}
\left\{\begin{matrix}\dot x_1=x_2,\\\dot x_2=2x_2+u,\\y=-2x_1+x_2,\end{matrix}\right.
\end{equation*}

\bigskip

{\begin{russian}\sffamily
то поведение выходной координаты принципиально не изменится:
\end{russian}}

{\begin{russian}\sffamily
\ \  $y(t)=-2x_1(0)+x_2(0)+u_0\cdot t$,
\end{russian}}

{\begin{russian}\sffamily
но процесс по координатам состояния будет неограниченно расти:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x(t)=\left[\begin{matrix}x_1\left(0\right)-\frac 1 2\left(1-e^{2t}\right)x_2\left(0\right)+\frac 1
4\left(e^{2t}-1\right)-\frac 1 2\normalsubformula{\text{tu}}_0\\e^{2t}x_2\left(0\right)+\frac 1
2\left(e^{2t}-1\right)u_0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Такие случаи, когда вектор выхода не отражает характерные свойства объекта, могущие привести к катастрофическим
результатам, будут подробно обсуждаться в последующих разделах.
\end{russian}}


\bigskip

\subsubsection{Модальная (спектральная) интерпретация решения векторно-матричных дифференциальных линейных стационарных
уравнений}
\hypertarget{RefHeadingToc455659707}{}{\begin{russian}\sffamily
Рассмотрим сначала движение автономной системы
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot x}\left(t\right)=A\vec x(t),_{}^{}_{}^{}\vec x\left(t_0\right)=\vec x_0$.\ \ (2.5.12)
\end{russian}}

{\begin{russian}\sffamily
Пусть все собственные числа матрицы  $A$ различны. Тогда ее собственные векторы  $\vec v_i,\;\;i=1,2,...,n$ образуют
базис в пространстве  $R^n$, то есть являются линейно независимыми. В соответствии с (2.3.5) и \ (2.4.28) решение
уравнения (2.5.12) можно записать в виде
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x\left(t\right)=\overset n{\underset{i=1}{\sum }}e^{λ_it}\vec v_i\vec d_i^T\vec{}x\left(0\right)$.
\end{russian}}

{\begin{russian}\sffamily
Обозначим скаляр
\end{russian}}

{\begin{russian}\sffamily
\ \  $μ_i=\vec d_i^T\vec x\left(0\right)$,\ \ \ \ (2.5.13)
\end{russian}}

{\begin{russian}\sffamily
тогда
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x\left(t\right)=\overset n{\underset{i=1}{\sum }}μ_ie^{λ_it}\vec v_i.$\ \ \ \ (2.5.14)
\end{russian}}

{\begin{russian}\sffamily
Очевидно, что свободное движение вектора состояния объекта является линейной комбинацией движений по собственным
векторам матрицы  $A$. Такие движения называют модами системы, а матрицу собственных векторов  $V$ - модальной
матрицей. Коэффициент  $μ_i$ соответствует величине возбуждения \textenglish{i} - й моды системы, обусловленной
начальными условиями. Иначе говоря, каждая мода возбуждается соответствующим выбором начального состояния. 
\end{russian}}

{\begin{russian}\sffamily
Согласно (2.5.13),
\end{russian}}

{\begin{russian}\sffamily

$μ_i=\left[\begin{matrix}d_{\mathit{i1}}&d_{\mathit{i2}}&...&d_{\normalsubformula{\text{in}}}\end{matrix}\right]\left[\begin{matrix}x_1(0)\\x_2(0)\\...\\x_n(0)\end{matrix}\right]=d_{\mathit{i1}}x_1(0)+d_{\mathit{i2}}x_2(0)+...+d_{\normalsubformula{\text{in}}}x_n(0)$.
\end{russian}}

{\begin{russian}\sffamily
Если вектор начальных условий  $\vec x(0)$ совпадает по направлению с \textenglish{i} - м собственным вектором, то есть 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x(0)=α\cdot \vec v_i$,
\end{russian}}

{\begin{russian}\sffamily
то, учитывая, что согласно (2.4.13) и (2.4.14), \  $\vec d_i^T\vec v_j=0$ при  $i\neq j$ и \  $\vec d_i^T\vec v_i=1$,
получаем
\end{russian}}

\begin{equation*}
μ_i=\vec d_i^T\vec x(0)=α_i_{}^{}и_{}^{}μ_j=\vec d_j^T\vec x(0)=0_{}^{}\normalsubformula{\text{при}}_{}^{}j\neq i.
\end{equation*}
{\begin{russian}\sffamily
Таким образом, при указанном выборе начальных условий возбуждается только \textenglish{i}-я мода, или «частота».
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим с этих же позиций движение неавтономного объекта
\end{russian}}

\begin{equation*}
\vec{\dot x}(t)=A\vec x(t)+B\vec u(t).
\end{equation*}
{\begin{russian}\sffamily
Изложенный подход можно использовать и в этом случае, если вектор  $B\vec u(t)$ разложить по собственным векторам
матрицы  $A$:
\end{russian}}

{\begin{russian}\sffamily
\ \  $B\vec u(t)=\overset n{\underset{i=1}{\sum }}β_i\left(t\right)\times \vec v_i_{}^{}.$\ \ (2.5.15)
\end{russian}}

{\begin{russian}\sffamily
Для того чтобы определить скалярные функции  $β_i(t)$, умножим обе части этого равенства слева на  $\vec d_j^T$:
\end{russian}}

\begin{equation*}
\vec d_j^TB\vec u(t)=\overset n{\underset{i=1}{\sum }}β_i\left(t\right)\vec d_j^T\vec v_i,
\end{equation*}
{\begin{russian}\sffamily
откуда, учитывая (2.4.13) и (2.4.14), получаем
\end{russian}}

{\begin{russian}\sffamily
\ \  $β_i\left(t\right)=\vec d_i^TB\vec u(t).$\ \ \ \ (2.5.16)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, в соответствии с формулой Коши (2.3.19) и выражением для переходной матрицы (2.4.28) имеем
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $\begin{matrix}\vec x\left(t\right)=e^{\normalsubformula{\text{At}}}\vec x\left(0\right)+\overset t{\underset
0{\int }}e^{A\left(t-τ\right)}\cdot \overset n{\underset{i=1}{\sum }}β_i\left(τ\right)\vec v_i\mathit{dτ}=\hfill\null
\\=e^{\normalsubformula{\text{At}}}\vec x\left(0\right)+\overset t{\underset 0{\int }}\overset n{\underset{j=1}{\sum
}}e^{λ_j\left(t-τ\right)}\overset n{\underset{i=1}{\sum }}β_i\left(τ\right)\vec
v_j\vec{}d_j^T\vec{}v_i\mathit{dτ}=\hfill\null \\=\overset n{\underset{j=1}{\sum }}\left\{μ_ie^{λ_jt}+\overset
t{\underset 0{\int }}e^{λ_j\left(t-τ\right)}\vec{}d_j^TB\vec u\left(τ\right)\mathit{dτ}\right\}\cdot \vec
v_j.\hfill\null \end{matrix}\hfill $\ \ (2.5.17)
\end{russian}}

{\begin{russian}\sffamily
Если вынуждающая функция  $\vec u(t)$ выбирается таким образом, чтобы вектор  $B\vec u(t)$ совпадал с направлением
одного из собственных векторов матрицы  $A$, то она будет возбуждать только одну соответствующую моду - «частоту».
\end{russian}}

\subsection{Модели стационарных линейных систем в комплексной плоскости на основе преобразования Лапласа}
\hypertarget{RefHeadingToc455659708}{}\subsubsection{Матрица передаточных функций }
\hypertarget{RefHeadingToc455659709}{}{\begin{russian}\sffamily
Известно, что преобразование Лапласа определяется парой преобразований
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\vec X(p)=L\left\{\vec x(t)\right\}=\overset{\infty }{\underset 0{\int }}\vec
x\left(t\right)e^{-\normalsubformula{\text{pt}}}\normalsubformula{\text{dt}},\hfill\null \\\vec
x\left(t\right)=L^{-1}\left\{\vec X(p)\right\}=\frac 1{2π\cdot j}\overset{C+j\infty }{\underset{C-j\infty }{\int }}\vec
X(p)e^{\normalsubformula{\text{pt}}}\normalsubformula{\text{dp}}_{}^{}.\hfill\null \end{matrix}\hfill $\ \ (2.6.1)
\end{russian}}

{\begin{russian}\sffamily
Первое из них называется прямым, а второе - обратным. Векторная функция  $\vec x(t)$ называется оригиналом, а  $\vec
X(p)$ - изображением этого оригинала по Лапласу;  $p$- комплексная переменная преобразования Лапласа. Преобразование
Лапласа можно осуществить, если  $p=σ+\mathit{jω}$ и  $σ>σ_c$, где  $σ_c$ - абсцисса абсолютной сходимости. Величина 
$σ_C$ выбирается исходя из требования, чтобы функция  $\vec x(t)e^{-\mathit{σt}}$\textrussian{ при }
$σ>σ_C$\textrussian{ была абсолютно интегрируемой.}
\end{russian}}

{\begin{russian}\sffamily
При вычислении обратного преобразования Лапласа интегрирование ведется на плоскости комплексной переменной
\textenglish{\textit{p}} \ по прямой, параллельной мнимой оси, лежащей на прямой \textit{с}, причем \textit{с}
выбирается так, чтобы все полюсы  $\vec X(p)$ оказались слева от прямой интегрирования (рис. 2.14). На этом рисунке
показано расположение полюсов некоторой функции  $\vec X(p)$.
\end{russian}}

{\centering  \includegraphics[width=13.705cm,height=6.429cm]{1-img024.png} \par}

\bigskip

{\begin{russian}\sffamily
Пусть, как обычно, уравнения объекта имеют вид
\end{russian}}

\begin{equation*}
\begin{matrix}\vec{\dot x}(t)=A\vec x(t)+B(t)\vec u(t);\hfill\null \\\vec y(t)=C\vec x(t).\hfill\null \end{matrix}\hfill

\end{equation*}
{\begin{russian}\sffamily
Перейдем к изображениям по Лапласу:
\end{russian}}

\begin{equation*}
\begin{matrix}p\vec X(p)-\vec x(0)=A\vec X(p)+B\vec U(p);\hfill\null \\Y(p)=C\vec X(p).\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Перенесем \  $A\vec X(p)$ в левую часть равенства, а  $\vec x(0)$ - в правую:
\end{russian}}

\begin{equation*}
(\normalsubformula{\text{pE}}-A)\vec X(p)=\vec x(0)+B\vec U(p).
\end{equation*}
{\begin{russian}\sffamily
Отсюда получаем выражение для изображения вектора состояния
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ } $\vec X(p)=(\normalsubformula{\text{pE}}-A)^{-1}\vec x(0)+(\normalsubformula{\text{pE}}-A)^{-1}B\vec
U(p)$.
\end{russian}}

{\begin{russian}\sffamily
Сравнивая это равенство с формулой Коши
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ } $\vec x(t)=e^{\normalsubformula{\text{At}}}\cdot \vec x(0)+\overset t{\underset 0{\int
}}e^{A(t-τ)}\cdot B\vec u(τ)\mathit{dτ}$,
\end{russian}}

{\begin{russian}\sffamily
отмечаем, что резольвента матрицы  $A$ –  $(\normalsubformula{\text{pE}}-A)^{-1}$ – может рассматриваться как
изображение по Лапласу от переходной матрицы (матричной экспо­ненты):
\end{russian}}

{\begin{russian}\sffamily
\ \  $_{}^{}(\normalsubformula{\text{pE}}-A)^{-1}=L\left\{e^{\normalsubformula{\text{At}}}\right\}$.
\end{russian}}

{\begin{russian}\sffamily
Справедливо равенство
\end{russian}}

{\begin{russian}\sffamily
\ \  $(\normalsubformula{\text{pE}}-A)^{-1}=\frac{I(p)}{ϕ_A(p)},$\ \ \ \ (2.6.2)
\end{russian}}

{\begin{russian}\sffamily
где  $I(p)$- присоединенная матрица для матрицы \textit{А};  $ϕ_A(p)$- характеристический полином матрицы  $A$.  $I(p)$
и  $ϕ_A(p)$ могут быть определены по методу Фаддеева - Леверье.
\end{russian}}

{\begin{russian}\sffamily
При нулевых начальных условиях
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec X(p)=(\normalsubformula{\text{pE}}-A)^{-1}B\vec U(p),$\ \ (2.6.3)
\end{russian}}

{\begin{russian}\sffamily
где функция
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{ux}}}(p)=(\normalsubformula{\text{pE}}-A)^{-1}\cdot B$\ \ (2.6.4)
\end{russian}}

{\begin{russian}\sffamily
называется матричной передаточной функцией от вектора управления до вектора состояния или передаточной функцией по
каналу «\textenglish{u}-\textenglish{x}».
\end{russian}}

{\begin{russian}\sffamily
Аналогично при нулевых начальных условиях
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec Y(p)=C(\normalsubformula{\text{pE}}-A)^{-1}B\vec U(p),$\ \ (2.6.5)
\end{russian}}

{\begin{russian}\sffamily
где функция
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{uy}}}(p)=C(\normalsubformula{\text{pE}}-A)^{-1}\cdot B$\ \ (2.6.6)
\end{russian}}

{\begin{russian}\sffamily
называется матричной передаточной функцией от вектора управления до вектора выхода или передаточной функцией по каналу
«\textenglish{u}-\textenglish{y}». Функцию  $(\normalsubformula{\text{pE}}-A)^{-1}$ называют резольвентой матрицы  $A$.
\end{russian}}

{\begin{russian}\sffamily
С использованием \ передаточной функции можно записать:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\vec X(p)=W_{\normalsubformula{\text{ux}}}(p)\cdot \vec U(p);\hfill\null \\\vec
Y(p)=W_{\normalsubformula{\text{uy}}}(p)\cdot \vec U(p).\hfill\null \end{matrix}\hfill $\ \ (2.6.7)
\end{russian}}

{\begin{russian}\sffamily
Принимая во внимание, что изображение по Лапласу  $δ$ - функции равно единице, можно представить передаточную функцию
как изо­бра­жение от весовой функции
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$w_y(t)=\normalsubformula{\text{Ce}}^{\normalsubformula{\text{At}}}B;\ L\left\{w_y(t)\right\}=\normalsubformula{\text{CL}}\left\{e^{\normalsubformula{\text{At}}}\right\}B=W(p)$\ \ (2.6.8)
\end{russian}}

{\begin{russian}\sffamily
Передаточная функция является функцией от матрицы  $A$, поэтому в соответствии с (2.4.27) можно записать
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{uy}}}(p)=\overset n{\underset{i=1}{\sum }}\frac{C\cdot \vec v_i\cdot \vec
d_i^TB}{(p-λ_i)}$\ \ (2.6.9)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \  $Y(p)=\overset n{\underset{i=1}{\sum }}\frac{C\cdot \vec v_i\cdot \vec d_i^TB}{(p-λ_i)}\cdot \vec
U(p)$.\ \ (2.6.10)
\end{russian}}

{\begin{russian}\sffamily
Графическое изображение последней формулы представлено в виде структурной схемы, изображённой на рис. 2.15.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=17.253cm,height=10.806cm]{1-img025.png} \par}
{\begin{russian}\sffamily
ПРИМЕР 2.6.1. Для объекта, схема в переменных состояния которого приведена на рис.2.16, уравнения состояния имеют вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\dot x_1=x_2-u_1\;;\hfill\null \\\dot x_2=x_3+u_1\;;\hfill\null \\\dot x_3=x_2+u_2\;;\hfill\null
\end{matrix}\hfill $ \ \ \ \ \ \ \ \ \ \ \  $\begin{matrix}y_1=x_1\;;\hfill\null \\y_2=x_3.\hfill\null
\end{matrix}\hfill $
\end{russian}}

{\begin{russian}\sffamily
Им соответствуют матрицы
\end{russian}}

\begin{equation*}
A=\left[\begin{matrix}0&1&0\\0&0&1\\0&1&0\end{matrix}\right];_{}^{}B=\left[\begin{matrix}-1&0\\1&0\\0&1\end{matrix}\right];_{}^{}C=\left[\begin{matrix}1&0&0\\0&0&1\end{matrix}\right].
\end{equation*}
{\begin{russian}\sffamily
Характеристический полином имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_A(λ)=λ^3-λ$.
\end{russian}}

{\begin{russian}\sffamily
Собственные числа
\end{russian}}

{\begin{russian}\sffamily
\ \  $λ_1=0;\;\;\;\;λ_2=1;\;\;\;\;λ_3=-1$.
\end{russian}}

{\centering  \includegraphics[width=12.462cm,height=5.583cm]{1-img026.png} \par}

\bigskip

{\begin{russian}\sffamily
Присоединенная матрица
\end{russian}}

\begin{equation*}
I\left(λ\right)=\left[\begin{matrix}λ^2-1&λ&1\\0&λ^2&λ\\0&λ&λ^2\end{matrix}\right].
\end{equation*}
{\begin{russian}\sffamily
Резольвента
\end{russian}}

{\begin{russian}\sffamily
\ \  $\left(\mathit{λE}-A\right)^{-1}=\frac{I\left(λ\right)}{ϕ_A\left(λ\right)}=\left[\begin{matrix}\frac 1 λ&\frac
1{λ^2-1}&\frac 1{λ(λ^2-1)}\\0&\frac λ{λ^2-1}&\frac 1{λ^2-1}\\0&\frac 1{λ^2-1}&\frac λ{λ^2-1}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (2.6.4) передаточная функция по вектору состояния
\end{russian}}

\begin{equation*}
W_{\normalsubformula{\text{ux}}}(p)=\left(\normalsubformula{\text{pE}}-A\right)^{-1}B=\left[\begin{matrix}\frac{-p^2+p+1}{p(p^2-1)}&\frac
1{p(p^2-1)}\\\frac p{p^2-1}&\frac 1{p^2-1}\\\frac 1{p^2-1}&\frac p{p^2-1}\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и по вектору выхода
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$W_{\normalsubformula{\text{uy}}}(p)=C\left(\normalsubformula{\text{pE}}-A\right)^{-1}B=\left[\begin{matrix}\frac{-p^2+p+1}{p(p^2-1)}&\frac
1{p(p^2-1)}\\\frac 1{p^2-1}&\frac p{p^2-1}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Используя присоединенную матрицу, можно найти матрицу правых собственных векторов
\end{russian}}

{\begin{russian}\sffamily
\ \  $V=\left[\begin{matrix}1&1&1\\0&1&-1\\0&1&1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Присоединенная матрица для  $A^T$
\end{russian}}

{\begin{russian}\sffamily
\ \  $I^d\left(λ\right)=\left[\begin{matrix}λ^2-1&0&0\\λ&λ^2&λ\\1&λ&λ^2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Левые собственные векторы
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec d_1=\left[\begin{matrix}1\\0\\-1\end{matrix}\right];\;\;\;\vec
d_2=\left[\begin{matrix}0\\0.5\\0.5\end{matrix}\right];\;\;\;\vec
d_3=\left[\begin{matrix}0\\-0.5\\0.5\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Базовые матрицы
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec v_1\vec d_1^T=\left[\begin{matrix}1&0&-1\\0&0&0\\0&0&0\end{matrix}\right]$; \  $\vec v_2\vec
d_2^T=\left[\begin{matrix}0&0.5&0.5\\0&0.5&0.5\\0&0.5&0.5\end{matrix}\right]$;
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec v_3\vec d_3^T=\left[\begin{matrix}0&-0.5&0.5\\0&0.5&-0.5\\0&-0.5&0.5\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Вычислим коэффициенты суммы (2.6.9):
\end{russian}}

{\begin{russian}\sffamily
\ \  $C\vec v_1\vec d_1^TB=\left[\begin{matrix}-1&-1\\0&0\end{matrix}\right]$; \ \ \  $C\vec v_2\vec
d_2^TB=\left[\begin{matrix}0.5&0.5\\0.5&0.5\end{matrix}\right]$;
\end{russian}}

\begin{equation*}
C\vec v_3\vec d_3^TB=\left[\begin{matrix}-0.5&0.5\\-0.5&0.5\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и получим результат, совпадающий, естественно, с уже полученным
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{uy}}}(p)=\frac 1 p\left[\begin{matrix}-1&-1\\0&0\end{matrix}\right]+\frac 1{p-1}\cdot
\frac 1 2\left[\begin{matrix}1&1\\1&1\end{matrix}\right]+\frac 1{p+1}\cdot \frac 1
2\left[\begin{matrix}-1&1\\-1&1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Практически без дополнительных выкладок получаем
\end{russian}}


\bigskip


\bigskip

{\begin{russian}\sffamily
\ \  $w_y(t)=\left[\begin{matrix}-1&-1\\0&0\end{matrix}\right]+\frac 1
2\left[\begin{matrix}1&1\\1&1\end{matrix}\right]\cdot e^t+\frac 1
2\left[\begin{matrix}-1&1\\-1&1\end{matrix}\right]\cdot e^{-t}$.\ \ 
\end{russian}}

{\begin{russian}\sffamily
Интегрируя весовую функцию, получаем матричную переходную функцию
\end{russian}}

{\begin{russian}\sffamily
\ \  $H_y(t)=\left[\begin{matrix}-t+\frac 1 2\left(e^t-2+e^{-t}\right)&-t+\frac 1 2\left(e^t-e^{-t}\right)\\\frac 1
2\left(e^t-2+e^{-t}\right)&\frac 1 2\left(e^t-e^{-t}\right)\end{matrix}\right]$.
\end{russian}}


\bigskip


\bigskip

\subsubsection{Основные свойства передаточных функций}
\hypertarget{RefHeadingToc455659710}{}
\bigskip

{\begin{russian}\sffamily
Понятие передаточной функции лежит в основе классической теории автоматического регулирования. В связи с этим ниже
перечисляются основные её свойства, используемые при анализе систем автоматического управления.
\end{russian}}

{\begin{russian}\sffamily
1. Элемент  $i$-й строки и  $j$-го столбца матричной передаточной функции равен отношению изображения  $i$-й координаты
вектора выхода к  $j$-й координате вектора управления при нулевых начальных условиях
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{ij}}}\left(p\right)=\frac{Y_i(p)}{U_j(p)}$.\ \ \ \ (2.6.11)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, при  $U_k(p)=0$ ,  $k\neq j$
\end{russian}}

{\begin{russian}\sffamily
\ \  $ $ $Y_i(p)=\overset{\normalsubformula{\text{nu}}}{\underset{j=1}{\sum
}}W_{\normalsubformula{\text{ij}}}(p)U_j(p)$.\ \ (2.6.12)
\end{russian}}

{\begin{russian}\sffamily
2. Для стационарных объектов с сосредоточенными параметрами элементы матричной передаточной функции - это
дробно-рациональные функции комплексной переменной  $p$:
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$W_{\normalsubformula{\text{ij}}}(p)=\frac{R_{\normalsubformula{\text{ij}}}(p)}{Q_{\normalsubformula{\text{ij}}}(p)}=\frac{b_0p^m+b_1p^{m-1}+...+b_m}{a_0p^n+a_1p^{n-1}+...+a_n}_{}^{}.$\ \ (2.6.13)\ \ 
\end{russian}}

{\begin{russian}\sffamily
3. По известной передаточной функции легко восстанавливаются соответствующие дифференциальные уравнения. По данным
предыду­щего примера
\end{russian}}


\bigskip


\bigskip


\bigskip

{\begin{russian}\sffamily
\ \  $Y_1(p)=\frac{-p^2+p+1}{p(p^2-1)}U_1(p)+\frac 1{p(p^2-1)}U_2(p)$.
\end{russian}}

{\begin{russian}\sffamily
После приведения к общему знаменателю получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$p^3Y_1\left(p\right)-\normalsubformula{\text{pY}}_1\left(p\right)=-p^2U_1(p)+\normalsubformula{\text{pU}}_1(p)+U_1(p)+U_2(p)$,
\end{russian}}

{\begin{russian}\sffamily
и в результате имеем
\end{russian}}

{\begin{russian}\sffamily
\ \  $\dddot y_1(t)-\dot y_1(t)=-\ddot u_1\left(t\right)+\dot u_1(t)+u_1(t)+u_2(t)$.
\end{russian}}

{\begin{russian}\sffamily
4. Знаменатель передаточной функции - это соответствующий харак­те­ри­стический полином. Полюсы передаточной функции -
это \ нули соответ­ству­ющего характеристического полинома.
\end{russian}}

{\begin{russian}\sffamily
5. Поскольку весовая функция является оригиналом для передаточной, то при всех различных полюсах
\end{russian}}

{\begin{russian}\sffamily
\ \  $w_{\normalsubformula{\text{ij}}}(t)=\overset n{\underset{l=1}{\sum }}C_le^{p_lt}$,\ \ \ \ (2.6.14)
\end{russian}}

{\begin{russian}\sffamily
где  $p_l$- полюсы функции;
\end{russian}}

{\begin{russian}\sffamily
\ \  $C_l=\frac{R_{\normalsubformula{\text{ij}}}(p_l)}{Q^{'_{\normalsubformula{\text{ij}}}}(p_l)}=\frac{b_0}{a_0}\cdot
\frac{\overset m{\underset{v=1}{\prod }}(p_l-r_v)}{\overset n{\underset{v=1,v\neq l}{\prod }}(p_l-p_v)}$;\ \ (2.6.15)
\end{russian}}

{\begin{russian}\sffamily
 $b_0,a_0$- коэффициенты при старших степенях  $p_{}^{}$ числителя \ и знаменателя передаточной функции 
$W_{\normalsubformula{\text{ij}}}(p)$;
\end{russian}}

{\begin{russian}\sffamily
 $r_v$- нули  $W_{\normalsubformula{\text{ij}}}(p)$.
\end{russian}}

{\begin{russian}\sffamily
6. В физически реализуемых системах порядок числителя  $m$ элементарной передаточной функции не может превышать порядка
ее знаменателя  $n$.
\end{russian}}

{\begin{russian}\sffamily
7. В простейших случаях элементарная передаточная функция может быть непосредственно получена из соответствующего
дифференци­аль­но­го уравнения. Например, для динамического звена с уравнением
\end{russian}}

\begin{equation*}
T\frac{\normalsubformula{\text{dy}}(t)}{\normalsubformula{\text{dt}}}+y(t)=T\frac{\normalsubformula{\text{du}}(t)}{\normalsubformula{\text{dt}}}
\end{equation*}
{\begin{russian}\sffamily
путем перехода к изображениям по Лапласу при нулевых начальных условиях получаем
\end{russian}}

{\begin{russian}\sffamily
\ \  $T\;p\;Y(p)+Y(p)=T\;p\;U(p)$,\ \ 
\end{russian}}

{\begin{russian}\sffamily
откуда
\end{russian}}


\bigskip


\bigskip

{\begin{russian}\sffamily
\ \  $W(p)=\frac{Y(p)}{U(p)}=\frac{\normalsubformula{\text{Tp}}}{\normalsubformula{\text{Tp}}+1}$.
\end{russian}}

{\begin{russian}\sffamily
При описании пассивных электрических цепей передаточные функции могут вычисляться в соответствии с правилами
электротехники с использованием полных символических сопротивлений. Так, например, для схемы, приведенной на рис.2.17,
\end{russian}}

{\centering  \includegraphics[width=12.965cm,height=7.038cm]{1-img027.png} \par}

\bigskip

{\begin{russian}\sffamily
\ \  $W(p)=\frac{Y(p)}{U(p)}=\frac{R_2}{R_2+\frac{R_1\cdot \frac 1{\normalsubformula{\text{pC}}}}{R_1+\frac
1{\normalsubformula{\text{pC}}}}}=\frac{R_2}{R_1+R_2}\cdot
\frac{R_1\normalsubformula{\text{Cp}}+1}{\frac{R_2}{R_1+R_2}R_1\normalsubformula{\text{Cp}}+1}$.
\end{russian}}

{\begin{russian}\sffamily
8. Если существует предел переходной функции при стремлении времени к бесконечности, то
\end{russian}}

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}\;h(t)=\underset{p\rightarrow 0}{\text{lim}}\;W(p)$.
\end{russian}}

{\begin{russian}\sffamily
Кроме того, справедливо равенство
\end{russian}}

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow 0}{\text{lim}}\;h(t)=\underset{p\rightarrow \infty }{\text{lim}}\;W(p)$.
\end{russian}}

{\begin{russian}\sffamily
Эти формулы следуют из предельных теорем преобразования Лапласа:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}\;f(t)=\underset{p\rightarrow
0}{\text{lim}}\;\normalsubformula{\text{pF}}(p)$ и  $\underset{t\rightarrow 0}{\text{lim}}\;f(t)=\underset{p\rightarrow
\infty }{\text{lim}}\normalsubformula{\text{pFW}}(p)$.
\end{russian}}

\clearpage\subsection{Комплексный передаточный коэффициент }
\hypertarget{RefHeadingToc455659711}{}\subsubsection{Способы определения понятия «Комплексный передаточный коэффициент»}
\hypertarget{RefHeadingToc455659712}{}
\bigskip

{\begin{russian}\sffamily
Известно несколько подходов к введению понятия \textbf{«Комплексный передаточный коэффициент». }Рассмотрим основные из
них.
\end{russian}}

\liststyleWWviiiNumlxxiv
\begin{itemize}
\item {\begin{russian}\sffamily
Формальная замена комплексной переменной в передаточной функции
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
Изображения по Лапласу вектора выхода и вектора управления \ \ \ \ связаны между собой с помощью передаточной функции
\end{russian}}

{\begin{russian}\sffamily
\ \  $Y(p)=W(p)U(p)$.\ \ \ \ (2.7.1)
\end{russian}}

{\begin{russian}\sffamily
Если в этом равенстве комплексную переменную  $p$ принять чисто мнимой величиной  $p=\mathit{jω}$, то формально получаем
следующее равенство:
\end{russian}}

{\begin{russian}\sffamily
\ \  $Y(\mathit{jω})=W(\mathit{jω})U(\mathit{jω})$.\ \ (2.7.2)
\end{russian}}

{\begin{russian}\sffamily
Здесь комплексный передаточный коэффициент  $W(\mathit{jω})$ определяется формально:
\end{russian}}

{\begin{russian}\sffamily
\ \ \  $W(\mathit{jω})=W(p)|_{p=\mathit{jω}}$.\ \ 
\end{russian}}

{\begin{russian}\sffamily
Строго говоря, эта замена не всегда правомерна.
\end{russian}}

\liststyleWWviiiNumlxxiv
\begin{itemize}
\item {\begin{russian}\sffamily
Использование преобразования Фурье
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
Прямое и обратное преобразования Лапласа выглядят \ \ \ следующим образом:  $ $ 
\end{russian}}

{\begin{russian}\sffamily
 $Y(p)=\overset{\infty }{\underset 0{\int }}y(t)e^{-\normalsubformula{\text{pt}}}\normalsubformula{\text{dt}};\text{    
}y(t)=\frac 1{2\mathit{πj}}\overset{C+\mathit{jω}}{\underset{C-\mathit{jω}}{\int
}}Y(p)e^{\normalsubformula{\text{pt}}}\normalsubformula{\text{dp}}$. \ \ (2.7.3)
\end{russian}}

{\begin{russian}\sffamily
Преобразование Лапласа существует тогда, когда вещественная часть комплексной переменной  $p$ удовлетворяет неравенству 
$σ>σ_C$.  $ $ \ \ \ \ \ \ 
\end{russian}}

{\begin{russian}\sffamily
Если функция  $y(t)$,  $t\in [0,\;\;\infty )$ является односторонней и абсолютно интегрируемой, т.е.  $|\overset{\infty
}{\underset 0{\int }}y(t)\normalsubformula{\text{dt}}|<\infty $, то её абсцисса абсолютной сходимости  $σ_C$<0, и можно
принять  $p=\mathit{jω}$ ( $σ=0$). В этом случае прямое преобразование Лапласа совпадает с прямым преобразованием
Фурье: 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Y(\mathit{jω})=\overset{\infty }{\underset 0{\int }}y(t)e^{-\mathit{jωt}}\normalsubformula{\text{dt}}$.\ \ (2.7.4)
\end{russian}}

{\begin{russian}\sffamily
Практически столь же просто обратное преобразование Лапласа превращается в обратное преобразование Фурье: 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}y(t)=\frac 1{2\mathit{πj}}\overset{+j\infty }{\underset{-j\infty }{\int }}Y(\mathit{jω})e^{j\infty
t}d(\mathit{jω})\Rightarrow \hfill\null \\\Rightarrow y(t)=\frac 1{2π}\overset{+\infty }{\underset{-\infty }{\int
}}Y(\mathit{jω})e^{\mathit{jωt}}\mathit{dω}.\hfill\null \end{matrix}\hfill $\ \ (2.7.5)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, если  $\vec{\dot x}(t)=A\vec x(t)+B\vec u(t);\text{      \{}\vec{\normalsubformula y}(t)=C\vec x(t)$ и
если функции  $\vec x(t)$,  $\vec y(t)$ и  $\vec u(t)$ абсолютно интегрируемы, то можно к указанным уравнениям
применить не только преобразование Лапласа, но и преобразование Фурье:
\end{russian}}

\begin{equation*}
\mathit{jω}\vec X(\mathit{jω})=A\vec X(\mathit{jω})+B\vec U(\mathit{jω});
\end{equation*}
\begin{equation*}
\vec X(\mathit{jω})=(\mathit{jωE}-A)^{-1}\cdot B\cdot \vec U(\mathit{jω});
\end{equation*}
\begin{equation*}
\vec X(\mathit{jω})=W_x(\mathit{jω})\cdot \vec U(\mathit{jω});
\end{equation*}
{\begin{russian}\sffamily
\ \  $W_y(\mathit{jω})=C\cdot (\mathit{jωE}-A)^{-1}B\;.$\ \ (2.7.6)
\end{russian}}

{\begin{russian}\sffamily
Функция  $W_y(\mathit{jω})=C(\mathit{jωE}-A)^{-1}B$ называется комплексным передаточным коэффициентом, или частотной
функцией соответствующего динамического звена или системы. Аналогично передаточной функции она может быть выражена
через левые и правые собственные векторы матрицы  $А$ векторно-матричного дифференциального уравнения этого звена или
системы:
\end{russian}}

{\begin{russian}\sffamily
\ \  $W(\mathit{jω})=\overset n{\underset{i=1}{\sum }}\frac{C\vec v_id_i^TB}{\mathit{jω}-λ_i}$.\ \ \ \ (2.7.7)\ \ \ \ 
\end{russian}}

\subsubsection{Реакция динамических звеньев на гармонические воздействия}
\hypertarget{RefHeadingToc455659713}{}{\begin{russian}\sffamily
Рассмотрим реакцию системы 
\end{russian}}

\begin{equation*}
\vec x(t)=A\cdot \vec x(t)+\vec b\cdot u(t)
\end{equation*}
{\begin{russian}\sffamily
со скалярным управлением \ на гармоническое воздействие
\end{russian}}

{\begin{russian}\sffamily
\ \  $u(t)=U_m\cdot \normalsubformula{\text{Cos}}\mathit{ωt}=\frac{U_m} 2\cdot e^{\mathit{jωt}}+\frac{U_m}
2e^{-\mathit{jωt}}$.\ \ (2.7.8)
\end{russian}}

{\begin{russian}\sffamily
Каждое из слагаемых последнего выражения вызывает свою реакцию, то есть 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x(t)=\vec x_1(t)+\vec x_2(t)$.\ \ \ \ (2.7.9)
\end{russian}}

{\begin{russian}\sffamily
В силу линейности рассматриваемых систем применим принцип суперпозиции, и достаточно определить реакцию на первое
слагаемое
\end{russian}}

{\begin{russian}\sffamily
\ \  $u_1(t)=\frac{U_m} 2\cdot e^{\mathit{jωt}}$.\ \ \ \ (2.7.10)
\end{russian}}

{\begin{russian}\sffamily
Ищем  $\vec x_1(t)$ в виде
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x_1(t)=\frac{\overset{\circ }{\vec X_1}} 2\cdot e^{\mathit{jωt}}$,\ \ \ \ (2.7.11) 
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \  $\overset{\circ }{\vec X_1}=\left[\begin{matrix}\overset{\circ }{X_{11}}\\\overset{\circ }{X_{12}}\\\vdots
\\\overset{\circ }{X_{1n}}\end{matrix}\right]$ ,
\end{russian}}

{\begin{russian}\sffamily
а  $\overset{\circ }{X_{1i}}$- комплексные амплитуды по координатам вектора состояния:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}{{}}{\circ }{X}{_{1i}}=X_{1i}^{\text{max}}e^{\mathit{jϕ}_{1i}}$.\ \ \ \ (2.7.12)
\end{russian}}

{\begin{russian}\sffamily
Подставим  $\vec x_1(t)$ и  $\vec u_1(t)$ в исходное дифференциальное уравнение и проведём элементарные преобразования:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\frac d{\normalsubformula{\text{dt}}}\left(\frac{\multiscripts{}{{}}{\circ }{\vec X}{_1}} 2\cdot
e^{\mathit{jωt}}\right)=A\cdot \frac{\overset{\circ }{\vec X_1}} 2\cdot e^{\mathit{jωt}}+\vec b\cdot \frac{U_m} 2\cdot
e^{\mathit{jωt}}$ ;
\end{russian}}

{\begin{russian}\sffamily
 $\multiscripts{}{{}}{\circ }{\vec X}{_1}\cdot \mathit{jω}\cdot e^{\mathit{jωt}}=A\cdot \overset{\circ }{\vec X_1}\cdot
e^{\mathit{jωt}}+\vec b\cdot U_m\cdot e^{\mathit{jωt}}$ ;
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}{{}}{\circ }{\vec X}{_1}\cdot \mathit{jω}-A\cdot \overset{\circ }{\vec X_1}=\vec b\cdot U_m$ ;
\end{russian}}

\begin{equation*}
\multiscripts{}{{}}{\circ }{\vec X}{_1}=(\mathit{jωE}-A)^{-1}\cdot \vec b\cdot U_m\;,
\end{equation*}
{\begin{russian}\sffamily
то есть 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}{{}}{\circ }{\vec X}{_1}=W(\mathit{jω})\cdot U_m$,\ \ \ \ (2.7.13)
\end{russian}}

{\begin{russian}\sffamily
где матричный комплексный передаточный коэффициент
\end{russian}}

{\begin{russian}\sffamily
\ \  $W(\mathit{jω})=(\mathit{jωE}-A)^{-1}\vec b$,
\end{russian}}

{\begin{russian}\sffamily
что совпадает с (2.7.6).
\end{russian}}

{\begin{russian}\sffamily
Аналогичным образом можно получить реакцию на вторую составляющую входного сигнала  $u_2(t)=\frac{U_m} 2\cdot
e^{-\mathit{jωt}}$:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}{{}}{\circ }{\vec X}{_2}=W(-\mathit{jω})\cdot U_m$.\ \ \ \ (2.7.14)
\end{russian}}

{\begin{russian}\sffamily
Полная реакция системы на гармоническое воздействие (2.7.8) в соответствии с (2.7.13) , (2.7.14) и (2.7.9):
\end{russian}}

{\begin{russian}\sffamily
\ \  \includegraphics[width=9.77cm,height=1.411cm]{1-img028.png} 
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$=\left[\begin{matrix}|W_1(\mathit{jω})|\text{cos}(\mathit{ωt}+ϕ_1)\\|W_2(\mathit{jω})|\text{cos}(\mathit{ωt}+ϕ_2)\\..............\\|W_n(\mathit{jω})|\text{cos}(\mathit{ωt}+ϕ_n)\end{matrix}\right]\;U_m$
.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, элемент матричной функции  $W(\mathit{jω})$, которая, по понятным теперь причинам, называется частотной
функцией, определяется как отношение вынужденной гармонической составляющей (частное решение неоднородного
дифференциального уравнения) к гармоническому входному воздействию при условии записи их в символической форме.
Комплексный передаточный коэффициент определяет изменение в зависимости от частоты амплитуды и фазы гармонического
сигнала при прохождении его от вектора управления до каждой из координат вектора состояния или вектора выхода:
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_i(\mathit{jω})=\frac{X_{i\text{max}}}{U_m}\cdot e^{\mathit{jϕ}_i}$.\ \ \ \ (2.7.15)
\end{russian}}

{\begin{russian}\sffamily
Модуль  $W(\mathit{jω})$ определяет отношение амплитуд:
\end{russian}}

{\begin{russian}\sffamily
\ \  $|W_i(\mathit{jω})|=\frac{X_{i\text{max}}}{U_m}$,\ \ \ \ (2.7.16)
\end{russian}}

{\begin{russian}\sffamily
а фаза – сдвиг по фазе между входным и выходным гармоническими сигналами:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\text{arg}(W_i(\mathit{jω}))=ϕ_i$.\ \ \ \ (2.7.17)
\end{russian}}


\bigskip

\subsubsection{Частотные характеристики}
\hypertarget{RefHeadingToc455659714}{}{\begin{russian}\sffamily
Элементы матричной частотной функции связывают между собой соответствующие координаты векторов выхода и управления:
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{ik}}}(\mathit{jω})=\frac{Y_i(\mathit{jω})}{U_k(\mathit{jω})}$.\ \ \ \ (2.7.18)
\end{russian}}

{\begin{russian}\sffamily
Такие скалярные функции принято иллюстрировать графическими частотными характеристиками:
\end{russian}}

{\begin{russian}\sffamily
\ \ – амплитудно-фазовой характеристикой (АФХ), построенной в полярной системе координат \{модуль, фаза\}; можно
рассматривать и соответствующую декартову систему координат, по осям которой откладываются вещественная и мнимая части
годографа вектора  $W(\mathit{jω})$;
\end{russian}}

{\begin{russian}\sffamily
\ \ – логарифмическими частотными характеристиками (ЛЧХ) - амплитудно-частотной (ЛАЧХ), построенной в осях 
$|W(\mathit{jω})|$ в децибелах, - \textrm{\textit{}}\textit{ \ }в логарифмическом масштабе, и фазочастотной (ЛФЧХ),
построенной в осях фаза - \textrm{} в логарифмическом масштабе.
\end{russian}}

{\begin{russian}\sffamily
Модуль частотной функции в децибелах определяется в соответствии с выражением
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$|W_{\normalsubformula{\text{ik}}}(\mathit{jω})|_{\normalsubformula{\text{дб}}}=20\text{lg}|W_{\normalsubformula{\text{ik}}}(\mathit{jω})|$.\ \ (2.7.19)
\end{russian}}

{\begin{russian}\sffamily
В качестве примера для звена  $W(p)=\left(\frac{4p+1}{0.08p+1}\right)^2\cdot \frac k{p^3}$ приведены АФХ (рис.2.18) и
ЛЧХ (рис.2.19).
\end{russian}}

{\centering  \includegraphics[width=12.594cm,height=9.181cm]{1-img029.png} \par}

\bigskip


\bigskip


\bigskip


\bigskip


\bigskip

{\centering  \includegraphics[width=16.801cm,height=12.568cm]{1-img030.png} \par}
{\centering\begin{russian}\sffamily
Рис 2.19. Логарифмические амплитудно-частотная 
\end{russian}\par}

{\centering\begin{russian}\sffamily
и фазочастотная характеристики
\end{russian}\par}


\bigskip

{\begin{russian}\sffamily
В учебной литературе по теории автоматического управления достаточ­но подробно рассматривается \ методика построения
частотных характеристик типовых или более общего вида динамических звеньев и систем. Поэтому в настоящем пособии эти
вопросы не затрагиваются.
\end{russian}}


\bigskip

\subsection[Графическое представление объектов и систем \ \ \ \ \ управления]{Графическое представление объектов и
систем \ \ \ \ \ управления}
\hypertarget{RefHeadingToc455659715}{}{\begin{russian}\sffamily
Графическое изображение объектов и систем управления с использованием функциональных блоков, передаточных функций,
сигналов и их изображений называют структурными схемами. Для представления систем в виде совокупности отдельных
функционально определенных блоков (подсистем) используются функциональные схемы.
\end{russian}}

\subsubsection{Соглашение об обозначениях}
\hypertarget{RefHeadingToc455659716}{}{\begin{russian}\sffamily
Элементарное динамическое звено (система) с передаточной функцией  $W(p)$ представлено на рис 2.20, где
\end{russian}}

{\begin{russian}\sffamily
 $Y_{\normalsubformula{\text{вх}}}(p)$– изображение по Лапласу входного сигнала;
\end{russian}}

{\begin{russian}\sffamily
 $Y_{\normalsubformula{\text{вых}}}(p)$– изображение по Лапласу выходного сигнала; 
\end{russian}}

{\begin{russian}\sffamily
 $W(p)$– передаточная функция звена.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=8.308cm,height=2.355cm]{1-img031.png} \par}

\bigskip

{\begin{russian}\sffamily
Связь между элементами выражается уравнением
\end{russian}}

{\begin{russian}\sffamily
\ \  $Y_{\normalsubformula{\text{вых}}}(p)=W(p)Y_{\normalsubformula{\text{вх}}}(p)$.
\end{russian}}

{\begin{russian}
\textsf{Варианты изображения элементов сравнения, или сумматоров на структурных схемах представлены \ на рис.2.21.}
\end{russian}}


\bigskip

{\centering  \includegraphics[width=15.663cm,height=4.348cm]{1-img032.png} \par}

\bigskip

{\begin{russian}\sffamily
Все три варианта равносильны и описываются уравнением
\end{russian}}

{\begin{russian}\sffamily
\ \  $U_3=U_1-U_2$.
\end{russian}}

{\begin{russian}\sffamily
Если на вход сумматора подается несколько входных сигналов, то он изображается в виде, представленном на рис.2.22 (три
входных сигнала). 
\end{russian}}

{\centering  \includegraphics[width=10.689cm,height=4.683cm]{1-img033.png} \par}
{\begin{russian}\sffamily
\ \ Варианты элементов умножения на структурных схемах представлены на рис 2.23. Оба вида равносильны в применении и
описываются уравнением  $U_2=K\times U_1$.
\end{russian}}

{\centering  \includegraphics[width=12.515cm,height=3.942cm]{1-img034.png} \par}

\bigskip

{\begin{russian}
\textsf{В качестве примера функциональной схемы на рис 2.24 представлена функциональная схема системы \ стабилизации
крена ракеты. На рисунке использованы обозначения:}
\end{russian}}

{\begin{russian}\sffamily
БЦВМ – бортовая цифровая вычислительная машина;
\end{russian}}

{\begin{russian}\sffamily
УМ – усилитель мощности;
\end{russian}}

{\begin{russian}\sffamily
РМ – рулевая машина;
\end{russian}}

{\begin{russian}\sffamily
ЦАП – цифроаналоговый преобразователь;
\end{russian}}

{\begin{russian}\sffamily
АЦП – аналого-цифровой преобразователь;
\end{russian}}

{\begin{russian}\sffamily
 $δ$ - положение управляющего органа (сопло, руль);
\end{russian}}

{\begin{russian}\sffamily
 $ϕ$ - угол крена;
\end{russian}}

{\begin{russian}\sffamily
 $\dot ϕ$- угловая скорость крена.
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \ \ Возмущающие факторы:
\end{russian}}

{\begin{russian}\sffamily
 $W$ – ветер;
\end{russian}}

{\begin{russian}\sffamily
 $T$ – окружающая температура;
\end{russian}}

{\begin{russian}\sffamily
 $P_{\normalsubformula{\text{AT}}}$ – атмосферное давление;
\end{russian}}

{\begin{russian}\sffamily
 $\vec r$ – вектор командных сигналов.
\end{russian}}


\bigskip

\subsubsection{Структурные схемы и графы стационарных систем}
\hypertarget{RefHeadingToc455659717}{}\paragraph{Типовые соединения многомерных линейных систем}
{\begin{russian}\sffamily
Одной из характерных задач анализа САУ является задача преобразования и упрощения исходных структурных схем. При этом
используются правила преобразования простейших, типовых соеди­не­ний, к которым относят параллельное
(согласно-параллельное) (рис 2.25), последовательное (рис 2.26) \ и встречно-параллельное, когда одно динамическое
звено включено в обратную связь другому (рис 2.27). Для каждой из этих ситуаций нетрудно найти передаточную функцию
эквивалентного звена.
\end{russian}}

{\begin{russian}\sffamily
Пусть исходные динамические звенья имеют следующее описание:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\vec{\dot x}_1(t)=A\multiscripts{_1}{{}}{{}}{}{}\vec x_1(t)+B_1\vec u_1(t);\;\;\;\;\;\;\;\vec
y_1(t)=C_1\vec x_1(t)\;\;;\hfill\null \\\vec{\dot x}_2(t)=A\multiscripts{_2}{{}}{{}}{}{}\vec x_2(t)+B_2\vec
u_2(t);\;\;\;\;\vec y_2(t)=C_2\vec x_2(t)\;\;.\hfill\null \end{matrix}\hfill $\ \ (2.8.1)\ \ 
\end{russian}}


\bigskip

{\centering  \includegraphics[width=16.51cm,height=12.779cm]{1-img035.png} \par}

\bigskip

{\begin{russian}\sffamily
\textbf{\textit{Параллельное соединение}} (рис. 2.25)
\end{russian}}

{\begin{russian}\sffamily
\ \ В случае параллельного соединения звеньев введем в рассмот­ре­ние следующие очевидные равенства из блочных векторов
и матриц:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\left[\begin{matrix}\vec{\dot x}_1\\\vec{\dot
x}_2\end{matrix}\right]=\left[\begin{matrix}A_1&0\\0&A_2\end{matrix}\right]\cdot \left[\begin{matrix}\vec x_1\\\vec
x_2\end{matrix}\right]+\left[\begin{matrix}B_1\\B_2\end{matrix}\right]\cdot \vec u;\;\;\;\;\;\vec
y=\left[\begin{matrix}C_1&C_2\end{matrix}\right]\cdot \left[\begin{matrix}\vec x_1\\\vec
x_2\end{matrix}\right]$.\ \ (2.8.2)
\end{russian}}

{\begin{russian}\sffamily
В соответствии с этим можно записать выражение для эквивалентной
\end{russian}}

{\begin{russian}\sffamily
передаточной функции соединения
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_Э(p)=C(\normalsubformula{\text{pE}}-A)^{-1}B$, \ \ \ \ \ \ \ (2.8.3)\ \ 
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$A=\left[\begin{matrix}A_1&0\\0&A_2\end{matrix}\right];_{}^{}B=\left[\begin{matrix}B_1\\B_2\end{matrix}\right];_{}^{}C=\left[\begin{matrix}C_1&C_2\end{matrix}\right]$.\ \ (2.8.4)
\end{russian}}

{\begin{russian}\sffamily
Учитывая, что
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y=\vec y_1+\vec y_2$,
\end{russian}}

{\begin{russian}\sffamily
а
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec Y_1(p)=W_1(p)\vec U(p);_{}^{}\vec Y_2(p)=W_2(p)\vec U(p)$,
\end{russian}}


\bigskip

{\begin{russian}\sffamily
получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_Э(p)=W_1(p)+W_2(p)$.\ \ (2.8.5)
\end{russian}}


\bigskip


\bigskip

{\centering  \includegraphics[width=10.795cm,height=7.382cm]{1-img036.png} \par}

\bigskip

{\begin{russian}\sffamily
С другой стороны, передаточную функцию эквивалентного звена можно расписать следующим образом:
\end{russian}}

\begin{equation*}
W_Э(p)=C\cdot (\normalsubformula{\text{pE}}-A)^{-1}\cdot
B=\left[\begin{matrix}C_1&C_2\end{matrix}\right]\;\;\left(\normalsubformula{\text{pE}}\;\;-\;\left[\begin{matrix}A_1&0\\0&A_2\end{matrix}\right]\;\right)^{-1}\;\left[\begin{matrix}B_1\\B_2\end{matrix}\right]=
\end{equation*}
{\begin{russian}\sffamily
\ \ 
$=\left[\begin{matrix}C_1&C_2\end{matrix}\right]\;\left[\begin{matrix}\normalsubformula{\text{pE}}_{\mathit{n1}}-A_1&0\\0&\normalsubformula{\text{pE}}_{\mathit{n2}}-A_2\end{matrix}\right]^{-1}\left[\begin{matrix}B_1\\B_2\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
где \  $n_1,n_2$– размерности соответствующих единичных матриц.
\end{russian}}

{\begin{russian}\sffamily
Продолжим преобразования:
\end{russian}}

\begin{equation*}
W_Э(p)=C\left[\begin{matrix}(\normalsubformula{\text{pE}}_{\mathit{n1}}-A_1)^{-1}&0\\0&(\normalsubformula{\text{pE}}_{\mathit{n2}}-A_2)^{-1}\end{matrix}\right]\left[\begin{matrix}B_1\\B_2\end{matrix}\right]=
\end{equation*}
\begin{equation*}
=\left[\begin{matrix}C_1&C_2\end{matrix}\right]\left[\begin{matrix}(\normalsubformula{\text{pE}}_{\mathit{n1}}-A_1)^{-1}B_1\\(\normalsubformula{\text{pE}}_{\mathit{n2}}-A_2)^{-1}B_2\end{matrix}\right]=
\end{equation*}
{\begin{russian}\sffamily
\ \ 
$=C_1(\normalsubformula{\text{pE}}_{\mathit{n1}}-A_1)^{-1}B_1+C_2(\normalsubformula{\text{pE}}_{\mathit{n2}}-A_2)^{-1}B_2$.\ \ 
\end{russian}}

{\begin{russian}\sffamily
Таким образом, в результате получаем 
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $\begin{matrix}W_Э(p)=W_1(p)+W_2(p)\;;\text{     }\hfill\null \\W_Э(p)=\frac{C_1I_1(p)\cdot
B_1}{Q_1(p)}+\frac{C_2I_2(p)\cdot B_2}{Q_2(p)}\;,\hfill\null \end{matrix}\hfill $\ \ (2.8.6)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
 $I_1,I_2$– соответствующие присоединенные матрицы для матриц  $А_1$ \ \ и  $А_2$;
\end{russian}}

{\begin{russian}\sffamily
 $Q_1(p)\;,\;\;\;Q_2(p)$ - характеристические полиномы первого и второго звеньев, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \  $Q_1(p)=ϕ_{\mathit{A1}}(p)=\text{det}(\normalsubformula{\text{pE}}_{\mathit{n1}}-A_1)$;
\end{russian}}

{\begin{russian}\sffamily
\ \  $Q_2(p)=ϕ_{\mathit{A2}}(p)=\text{det}(\normalsubformula{\text{pE}}_{\mathit{n2}}-A_2)$.
\end{russian}}

{\begin{russian}\sffamily
Характеристический полином эквивалентной системы \ (матрицы  $А$) имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $Q(p)=Q_1(p)\cdot Q_2(p)$.\ \ \ \ (2.8.7)
\end{russian}}

{\begin{russian}\sffamily
Отсюда следует, что нули характеристического полинома (полюсы) эквивалентной передаточной функции соединения состоят из
нулей характеристических полиномов (полюсов передаточных функций) первого и второго звеньев.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, \textit{если каждое из параллельных звеньев устойчиво, то и всё соединение в целом устойчиво; если в
соединении присутствует \ хотя бы одно неустойчивое звено, то \ соединение в целом неустойчиво} (связь между характером
полюсов передаточной функции и устойчивостью соответствующей системы будет обсуждаться в п. 2.9).
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\textbf{\textit{Последовательное соединение }}(рис. 2.26)
\end{russian}}


\bigskip

{\centering  \includegraphics[width=11.113cm,height=3.254cm]{1-img037.png} \par}

\bigskip

{\centering\begin{russian}\sffamily
При последовательном соединении блочные уравнения имеют вид
\end{russian}\par}

{\begin{russian}\sffamily
\ \  $\left[\begin{matrix}\dot x_1\\\dot
x_2\end{matrix}\right]=\left[\begin{matrix}A_1&0\\B_2C&A_2\end{matrix}\right]\cdot
\left[\begin{matrix}x_1\\x_2\end{matrix}\right]+\left[\begin{matrix}B_1\\0\end{matrix}\right]u;_{}^{}y=\left[\begin{matrix}0&C_2\end{matrix}\right]\;\left[\begin{matrix}x_1\\x_2\end{matrix}\right]$,\ \ (2.8.8)
\end{russian}}

{\begin{russian}\sffamily
и в выражении (2.8.3) для эквивалентной функции
\end{russian}}


\bigskip

{\begin{russian}\sffamily

$A=\left[\begin{matrix}A_1&0\\B_2C_1&A_2\end{matrix}\right];_{}^{}B=\left[\begin{matrix}B_1\\0\end{matrix}\right];_{}^{}C=\left[\begin{matrix}0&C_2\end{matrix}\right]$.\ \ (2.8.9)
\end{russian}}

{\begin{russian}\sffamily
Кроме того, нетрудно получить связь между передаточными функциями отдельных звеньев, входящих в соединение, и
эквивалентной передаточ­ной функцией
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_Э(p)=W_1(p)W_2(p)$.\ \ (2.8.10)
\end{russian}}

{\begin{russian}\sffamily
Вывод о связи между устойчивостью отдельных звеньев и устойчивостью их последовательного соединения аналогичен выводу
для случая параллельного включения. 
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\textbf{\textit{Встречно-параллельное включение звеньев }}рис. 2.27
\end{russian}}


\bigskip

{\centering  \includegraphics[width=12.091cm,height=6.509cm]{1-img038.png} \par}

\bigskip

{\begin{russian}\sffamily
Для встречно-параллельного соединения, учитывая, что  $\vec u_1=\vec u\mp \vec y_2$, получаем
\end{russian}}

{\begin{russian}\sffamily
\ \  $A=\left[\begin{matrix}A_1&\mp
B_1C_2\\B_2C_1&A_2\end{matrix}\right];_{}^{}B=\left[\begin{matrix}B_1\\0\end{matrix}\right];_{}^{}C=\left[\begin{matrix}C_1&0\end{matrix}\right]$\ \ (2.8.11)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $W_Э(p)=\left[E\pm W_1(p)W_2(p)\right]^{-1}W_1(p)$.\ \ (2.8.12)\ \ Поскольку полюсы передаточной функции
эквивалентного соединения в данном случае не удается выразить непосредственно через полюсы передаточных функций
отдельных звеньев, то однозначного ответа об устойчивости соединения без дополнительного анализа \ получить не удается.
\end{russian}}

\paragraph{Графы динамических систем}
{\begin{russian}\sffamily
Графом называется множество вершин и ребер, в котором каждому ребру \ соответствует две вершины \ - начало и конец
ребра.
\end{russian}}

{\begin{russian}\sffamily
\ \ Основные характеристики графов:
\end{russian}}

\liststyleWWviiiNumi
\begin{enumerate}
\item {\begin{russian}\sffamily
каждой вершине на графе, изображаемой кружком или точкой, ставится в соответствие величина одной из переменных
(координат системы);
\end{russian}}
\item {\begin{russian}\sffamily
каждое ребро, изображаемое на графе линией со стрелкой, имеет вершину –“начало” и вершину – “конец”. Стрелка обозначает
направление передачи сигнала от начала к концу, таким образом, граф прохождения сигналов является направленным
(антисимметричным) графом;
\end{russian}}
\item {\begin{russian}\sffamily
величина, соответствующая началу (вершине) ребра, называется входной величиной ребра. Если из вершины выходит несколько
ребер, то входные величины этих ребер одинаковы и равны величине соответствующей вершины;
\end{russian}}
\item {\begin{russian}\sffamily
ребро изображает одно из звеньев в системе и ему ставится в соответствие передаточная функция;
\end{russian}}
\item {\begin{russian}\sffamily
если к вершине подходит несколько ребер, то сопоставляемая ей величина равна сумме выходных величин ребер.
\end{russian}}
\end{enumerate}

\bigskip

{\begin{russian}\sffamily
Между графом прохождения сигналов и структурной схемой имеется взаимно однозначное соответствие. Стрелка структурной
схемы соответствует вершине графа, а прямоугольник (звено) – ребру. При необходимости в граф системы могут вводиться
дополнительные единичные ребра для выявления промежуточных координат, являющихся, как правило, выходами отдельных
ребер. Для примера приведены графические представления некоторой системы в виде структурной схемы
\ \ \ \ \ \ \ \ \ \ \ (рис. 2.28) и графа (рис. 2.29).
\end{russian}}

{\begin{russian}\sffamily
Простейшие правила преобразования структурных схем и графов линейных систем представлены в таблице.
\end{russian}}

{\centering  \includegraphics[width=16.563cm,height=7.223cm]{1-img039.png} \par}
 \includegraphics[width=17.776cm,height=6.567cm]{1-img040.png} 


\bigskip

\begin{flushleft}
\tablefirsthead{}
\tablehead{}
\tabletail{}
\tablelasttail{}
\begin{supertabular}{|m{0.647cm}|m{6.3120003cm}|m{5.3cm}m{0.301cm}m{3.317cm}|}
\hline
\centering{\begin{russian}\sffamily №п/п\end{russian}} &
{\begin{russian}\sffamily Структурная схема\end{russian}} &
\multicolumn{1}{m{5.3cm}|}{{\begin{russian}\sffamily \ \ \ \ \ Граф \end{russian}}} &
\multicolumn{2}{m{3.818cm}|}{{\begin{russian}\sffamily Эквивалентная передаточная функция\end{russian}}}\\\hline
{\begin{russian}\sffamily 1\end{russian}} &
\multicolumn{4}{m{15.830001cm}|}{{\begin{russian}\sffamily \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Параллельное соединение
звеньев\end{russian}}}\\\hline
[Warning: Draw object ignored][Warning: Draw object ignored] &
~
 &
\multicolumn{2}{m{5.801cm}|}{~
} &
~

~

 $\begin{matrix}W_Э=W_1(p)+\hfill\null \\+W_2(p)\hfill\null \end{matrix}\hfill $\\\hline
{\begin{russian}\sffamily 2\end{russian}} &
\multicolumn{4}{m{15.830001cm}|}{{\begin{russian}\sffamily \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Последовательное соединение
звеньев\end{russian}}}\\\hline
[Warning: Draw object ignored] &
~
 &
\multicolumn{2}{m{5.801cm}|}{~
} &
~

 $\begin{matrix}W_Э=W_1(p)\cdot ?\hfill\null \\\cdot W_2(p)\hfill\null \end{matrix}\hfill $
~
\\\hline
{\begin{russian}\sffamily 3\end{russian}} &
\multicolumn{4}{m{15.830001cm}|}{{\begin{russian}\sffamily \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Встречно-параллельное
соединение звеньев\end{russian}}}\\\hline
[Warning: Draw object ignored] &
~
 &
\multicolumn{2}{m{5.801cm}|}{~
} &
~

 $\begin{matrix}W_э(p)=W_1(p)/?\hfill\null \\/1\pm W_1(p)W_2(p)\hfill\null \end{matrix}\hfill $\\\hline
\end{supertabular}
\end{flushleft}

\bigskip

{\begin{russian}\sffamily
Встречаются и более сложные случаи соединения звеньев, так, например, соединения с перекрестными связями (рис. 2.30).
\end{russian}}


\bigskip


\bigskip

 \includegraphics[width=16.166cm,height=6.35cm]{1-img041.png} 


\bigskip

{\begin{russian}\sffamily
В этих случаях можно пользоваться правилом переноса динамического звена через сумматор или точку разветвления.
\end{russian}}

{\begin{russian}\sffamily
\textit{\ Любое динамическое звено можно перенести через сумматор или точку разветвления; при этом звено должно войти во
все входящие и ответвляющиеся ветви. В те ветви, в которые звено входит без изменения направления распространения
сигнала, звено проходит со своей передаточной функцией. В тех ветвях, при продвижении в которые меняется направление
распространения сигнала, передаточная функция звена изменяется на обратную}. 
\end{russian}}

{\begin{russian}\sffamily
\ Это правило иллюстрируется элементарными примерами, приведёнными на рис. 2.31 – 2.34. 
\end{russian}}


\bigskip


\bigskip

{\centering  \includegraphics[width=15.399cm,height=6.297cm]{1-img042.png} \par}
{\centering  \includegraphics[width=15.769cm,height=6.085cm]{1-img043.png} \par}

\bigskip


\bigskip


\bigskip


\bigskip

{\centering  \includegraphics[width=14.753cm,height=11.806cm]{1-img044.png} \par}

\bigskip

{\centering  \includegraphics[width=13.785cm,height=13.361cm]{1-img045.png} \par}

\bigskip

{\begin{russian}\sffamily
В качестве примера проведём упрощение \ структурной схемы, приведённой на рис. 2.30. Перенесём динамическое звено с
передаточной функцией  $W_2$ \ через точку разветвления  $p_1$. После этого получим схему, состоящую только из
элементарных соединений (рис. 2.35).
\end{russian}}


\bigskip


\bigskip

{\centering  \includegraphics[width=16.166cm,height=7.108cm]{1-img046.png} \par}
{\begin{russian}\sffamily
Теперь исходная система может быть представлена в упрощенном виде \ \ \ \ \ \ \ (рис 2.36) и будет описываться
выражением  $W_э=\frac{W_2}{1+W_2W_3}\cdot \left(\frac{W_1}{W_2}+W_4\right)$.
\end{russian}}


\bigskip


\bigskip

{\centering  \includegraphics[width=12.091cm,height=3.572cm]{1-img047.png} \par}
\paragraph{Формула Мейсона}
{\begin{russian}\sffamily
В случае громоздких систем с большим числом звеньев и перекрестных связей наиболее эффективным является использование
для получения эквивалентных передаточных функций правила Мейсона. В связи с этим введем необходимые дополнительные
определения.
\end{russian}}

{\begin{russian}\sffamily
Прямой путь между двумя заданными вершинами графа – это непрерывная последовательность ветвей одного направления, в
которой каждая из вершин встречается не более одного раза.
\end{russian}}

{\begin{russian}\sffamily
Контур – замкнутая цепь, при однократном обходе которой в направлении, указанном стрелками, каждая из вершин встречается
не более одного раза.
\end{russian}}

{\begin{russian}\sffamily
Согласно правилу Мейсона, передаточная функция  $W$ между входом в точке  $А$ и выходом в точке  $B$ равна
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{AB}}}(p)=\overset χ{\underset{K=1}{\sum }}\frac{W_K(p)\cdot Δ_K(p)}{Δ(p)}$,\ \ (2.8.13)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
 $χ$– число прямых путей между вершинами  $A$ и  $B$;
\end{russian}}

{\begin{russian}\sffamily
 $W_k(p)$– передаточная функция k-го прямого пути от вершины $A$ к вершине $B$ (она равна произведению передаточных
функций всех ребер, входящих в последовательность прямого пути);
\end{russian}}

{\begin{russian}\sffamily
 $Δ(p)$– определитель графа;
\end{russian}}

{\begin{russian}\sffamily
 $Δ_k(p)$– k-й минор определителя графа, равный определителю более простого графа, который получается из данного графа
путем удаления из него всех ребер и вершин, лежащих на k-м прямом пути, а также всех ребер, входящих в эти вершины и
исходящих из этих вершин.
\end{russian}}

{\begin{russian}\sffamily
Определитель графа определяется из соотношения
\end{russian}}


\bigskip

\begin{equation*}
Δ(p)=1-\underset i{\sum }W_{\normalsubformula{\text{oi}}}(p)+\underset{i,j}{\sum
}W_{\normalsubformula{\text{oi}}}(p)W_{\normalsubformula{\text{oj}}}(p)-
\end{equation*}

\bigskip

{\begin{russian}\sffamily
\ \  $-\underset{i,j,k}{\sum
}W_{\normalsubformula{\text{oi}}}(p)W_{\normalsubformula{\text{oj}}}(p)W_{\normalsubformula{\text{ok}}}(p)+\ldots
$,\ \ (2.8.14)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
 $W_{\normalsubformula{\text{oi}}}(p)$– передаточные функции различных контуров графа;
\end{russian}}

{\begin{russian}\sffamily
 $W_{\normalsubformula{\text{oi}}}(p)W_{\normalsubformula{\text{oj}}}(p)$– произведения передаточных функций
непересекаю­щих­ся пар контуров;
\end{russian}}

{\begin{russian}\sffamily
 $W_{\normalsubformula{\text{oi}}}(p)W_{\normalsubformula{\text{oj}}}(p)W_{\normalsubformula{\text{oz}}}(p)$\ \ –
произведения \ передаточных функций непересек­аю­щих­ся троек контуров.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 2.8.1. Найти передаточную функцию  $W_{\normalsubformula{\text{uy}}}$ для системы, структурная схема которой
приведена на рис. 2.37.
\end{russian}}

{\centering  \includegraphics[width=13.309cm,height=5.292cm]{1-img048.png} \par}

\bigskip

{\begin{russian}\sffamily
Этой схеме соответствует граф, представленный на рис. 2.38.
\end{russian}}

{\centering  \includegraphics[width=13.335cm,height=5.292cm]{1-img049.png} \par}

\bigskip

{\begin{russian}\sffamily
Для этого графа:
\end{russian}}

\liststyleWWviiiNumx
\begin{itemize}
\item {\begin{russian}\sffamily
передаточная функция единственного прямого пути
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{пр}}}=W_1\;W_2$;
\end{russian}}

\liststyleWWviiiNumxxxix
\begin{itemize}
\item {\begin{russian}\sffamily
передаточные функции контуров
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \  $W_{01}=-W_1\;W_3$; \ \ \ \ \ \ \ \ \  $W_{02}=W_2\;W_4$;
\end{russian}}


\bigskip

\liststyleWWviiiNumxlviii
\begin{itemize}
\item {\begin{russian}\sffamily
главный определитель
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \  $Δ=1+W_1\;W_3\;-\;W_2\;W_4$; $ $
\end{russian}}

\liststyleWWviiiNumxlvi
\begin{itemize}
\item {\begin{russian}\sffamily
определитель прямого пути
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \  $Δ_1=1$;
\end{russian}}

\liststyleWWviiiNumxv
\begin{itemize}
\item {\begin{russian}\sffamily
искомая передаточная функция
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{uy}}}=\frac{W_{1\;}W_2}{1+W_1\;W_3\;-\;W_2\;W_4}$.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 2.8.2. Найти передаточную функцию между точками  $A$ и  $B$ для графа, приведённого на рис. 2.39.
\end{russian}}

{\centering  \includegraphics[width=16.007cm,height=12.832cm]{1-img050.png} \par}

\bigskip


\bigskip

{\begin{russian}\sffamily
Передаточные функции прямых путей:
\end{russian}}

{\begin{russian}\sffamily
\ \ W\textsubscript{1}=W\textsubscript{a}·W\textsubscript{b}·W\textsubscript{c};
\end{russian}}

{\begin{russian}\sffamily
\ \ \textenglish{W}\textenglish{\textsubscript{2}}\textenglish{=W}\textenglish{\textsubscript{a}}·\textenglish{W}\textenglish{\textsubscript{d}}·\textenglish{W}\textenglish{\textsubscript{e}}·\textenglish{W}\textenglish{\textsubscript{c}}\textenglish{;}
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ W}\textenglish{\textsubscript{3}}\textenglish{=W}\textenglish{\textsubscript{a}}·\textenglish{W}\textenglish{\textsubscript{d}}·\textenglish{W}\textenglish{\textsubscript{g}}·\textenglish{W}\textenglish{\textsubscript{h}}\textenglish{.}
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Передаточные функции контуров:
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \ W\textsubscript{01}=
W\textsubscript{d}·W\textsubscript{g}·W\textsubscript{h}·W\textsubscript{n}·W\textsubscript{r}·W\textsubscript{p}·W\textsubscript{l};
\end{russian}}

{\begin{russian}\sffamily
\ \ \textenglish{W}\textenglish{\textsubscript{02}}\textenglish{=
W}\textenglish{\textsubscript{d}}·\textenglish{W}\textenglish{\textsubscript{e}}·\textenglish{W}\textenglish{\textsubscript{c}}·\textenglish{W}\textenglish{\textsubscript{n}}·\textenglish{W}\textenglish{\textsubscript{r}}·\textenglish{W}\textenglish{\textsubscript{p}}·\textenglish{W}\textenglish{\textsubscript{l}}\textenglish{;}
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ W}\textenglish{\textsubscript{03}}\textenglish{=
W}\textenglish{\textsubscript{b}}·\textenglish{W}\textenglish{\textsubscript{c}}·\textenglish{W}\textenglish{\textsubscript{n}}·\textenglish{W}\textenglish{\textsubscript{r}}·\textenglish{W}\textenglish{\textsubscript{p}}·\textenglish{W}\textenglish{\textsubscript{l}}\textenglish{;}
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ W}\textenglish{\textsubscript{04}}\textenglish{=
W}\textenglish{\textsubscript{c}}·\textenglish{W}\textenglish{\textsubscript{n}}·\textenglish{W}\textenglish{\textsubscript{r}}·\textenglish{W}\textenglish{\textsubscript{m}}\textenglish{;}
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ W}\textenglish{\textsubscript{05}}\textenglish{=
W}\textenglish{\textsubscript{r}}·\textenglish{W}\textenglish{\textsubscript{p}}·\textenglish{W}\textenglish{\textsubscript{q}}\textenglish{;}
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ W}\textenglish{\textsubscript{06}}\textenglish{=W}\textenglish{\textsubscript{g}}\textenglish{
W}\textenglish{\textsubscript{s}}\textenglish{;}
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ W}\textenglish{\textsubscript{07}}\textenglish{=
W}\textenglish{\textsubscript{g}}·\textenglish{W}\textenglish{\textsubscript{f}}\textenglish{.}
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Произведения передаточных функций \ непересекающихся пар контуров:
\end{russian}}

{\begin{russian}\sffamily
W\textsubscript{02}·W\textsubscript{07}; \ W\textsubscript{03}·W\textsubscript{06};
\ W\textsubscript{03}·W\textsubscript{07}; \ W\textsubscript{04}·W\textsubscript{06};
\ W\textsubscript{04}·W\textsubscript{07}; \ W\textsubscript{05}·W\textsubscript{06};
\ W\textsubscript{05}·W\textsubscript{07}. 
\end{russian}}

\liststyleWWviiiNumlxxvii
\begin{itemize}
\item {\begin{russian}\sffamily
Непересекающихся троек контуров нет.
\end{russian}}
\end{itemize}
\liststyleWWviiiNumxlii
\begin{itemize}
\item {\begin{russian}\sffamily
Определитель графа:
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
Δ=1- W\textsubscript{01 }- W\textsubscript{02 }- W\textsubscript{03 }- W\textsubscript{04 }- W\textsubscript{05 }-
W\textsubscript{06 }- W07+
\end{russian}}

{\begin{russian}\sffamily
+
W\textsubscript{02}·W\textsubscript{07}+W\textsubscript{03}·W\textsubscript{06}+W\textsubscript{03}·W\textsubscript{07}+W\textsubscript{04}·W\textsubscript{06}+W\textsubscript{04}·W\textsubscript{07}+W\textsubscript{05}·W\textsubscript{06}+W\textsubscript{05}·W\textsubscript{07}
.
\end{russian}}

\liststyleWWviiiNumxlii
\begin{itemize}
\item {\begin{russian}\sffamily
Миноры определителя графа:
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \ Δ\textsubscript{1}=1-W\textsubscript{05}-W\textsubscript{07}-W\textsubscript{06}+W\textsubscript{05}·W\textsubscript{06}+W\textsubscript{05}·W\textsubscript{07};
\end{russian}}

{\begin{russian}\sffamily
\ \ Δ\textsubscript{2}=1-W\textsubscript{05}-W\textsubscript{07}+W\textsubscript{05}·W\textsubscript{07};
\end{russian}}

{\begin{russian}\sffamily
\ \ Δ\textsubscript{3}=1-W\textsubscript{05}.
\end{russian}}


\bigskip

\liststyleWWviiiNumlxxi
\begin{itemize}
\item {\begin{russian}\sffamily
Результирующая передаточная функция
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
 $W_{\normalsubformula{\text{AB}}}=\frac{W_1Δ_1+W_2Δ_2+W_3Δ_3} Δ$.
\end{russian}}


\bigskip

\clearpage\setcounter{page}{85}\pagestyle{ii}
\subsection{Устойчивость систем}
\hypertarget{RefHeadingToc455659718}{}\subsubsection{Асимптотические свойства собственного движения и весовой матрицы
линейной системы}
\hypertarget{RefHeadingToc455659719}{}{\begin{russian}\sffamily
Пусть нелинейное дифференциальное уравнение состояния имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \   $\overset .{\vec x}(t)=F\{\vec x(t),\vec u(t),t\}$.\ \ (2.9.1)\ \ 
\end{russian}}

{\begin{russian}\sffamily
Пусть также  $\vec u_0(t)$ – некоторая заданная (номинальная) функция времени и  $\vec x_0(t_0)$– некоторый номинальный
вектор начальных условий.
\end{russian}}

{\begin{russian}\sffamily
Решение  $\vec x_0(t)$ является устойчивым в смысле Ляпунова, если для любого  $t_0$ и для любого  $ε>0$ существует 
$δ(ε,t_0)>0$ такое, что при
\end{russian}}

{\begin{russian}\sffamily
\ \  $\|\vec x(t_0)-\vec x_0(t_0)\|\le δ$\ \ \ \ (2.9.2)
\end{russian}}

{\begin{russian}\sffamily
удовлетворяется неравенство
\end{russian}}

{\begin{russian}\sffamily
\ \  $\|\vec x(t)-\vec x_0(t)\|\le ε$.\ \ \ \ (2.9.3)
\end{russian}}

{\begin{russian}\sffamily
Норма вектора  $\vec x$ в простейшем случае совпадает с его евклидовой длиной
\end{russian}}

{\begin{russian}\sffamily
\ \  $\|\vec x\|=(\overset n{\underset{i=1}{\sum }}x_{i^2})^{1/2}$.\ \ \ \ (2.9.4)
\end{russian}}

{\begin{russian}\sffamily
Возможно также использование и других форм нормы, например
\end{russian}}

{\begin{russian}\sffamily
\ \  $\|\vec x\|=\underset i{\text{max}}|x_i|;\;\;\;\;\|\vec x\|=\overset n{\underset{i=1}{\sum }}|x_i|$.\ \ (2.9.5)
\end{russian}}

{\begin{russian}\sffamily
Введение нормы в пространстве состояний дает возможность ввести понятие близости точек пространства. Устойчивость в
смысле Ляпунова гарантирует, что состояние  $\vec x(t)$ не отклоняется далеко от «номинального» режима  $\vec x_0(t)$
при начальном состоянии  $\vec x(t_0)$, достаточно близком к номинальному начальному состоянию  $\vec x_0(t_0)$.
\end{russian}}

{\begin{russian}\sffamily
Решение  $\vec x_0(t)$ называется асимптотически устойчивым, если оно устойчиво в смысле Ляпунова, и для любого  $t_0$
существует такое  $ρ(t_0)$, что при 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\|\vec x(t_0)-\vec x_0(t_0)\|\le ρ$\ \ \ \ (2.9.6)
\end{russian}}

{\begin{russian}\sffamily
выполняется условие
\end{russian}}

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}\|\vec x(t)-\vec x_0(t)\|=0$.\ \ \ \ (2.9.7)
\end{russian}}

{\begin{russian}\sffamily
Решение  $\vec x_0(t)$ является асимптотически устойчивым в целом, если оно устойчиво по Ляпунову, и для любых  $t_0$ и 
$\vec x(t_0)$
\end{russian}}

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}\|\vec x(t)-\vec x_0(t)\|=0$.\ \ \ \ (2.9.8)
\end{russian}}

{\begin{russian}\sffamily
Применительно к нелинейным системам, вследствие сложности харак­терных для них явлений, обсуждается обычно устойчивость
решений. В линейных системах ситуация проще, и в этом случае целесообразнее говорить об устойчивости уже не решения, а
самой системы. Пусть дано уравнение системы
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}{{}}.{\vec x}{_C}(t)=A(t)\overset{}{\vec x_C}(t)+B(t)\vec u(t)$,\ \ (2.9.9)
\end{russian}}

{\begin{russian}\sffamily
и для  $t_0$,  $\vec x_{\mathit{C0}}(t_0)$ и  $\vec u_0(t)$ при  $t\ge t_0$ известно \  $\vec x_{\mathit{C0}}(t)$, то
есть справедливо уравнение 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}{{}}.{\vec x}{_{\mathit{C0}}}(t)=A(t)\overset{}{\vec x_{\mathit{C0}}}(t)+B(t)\vec
u_0(t)$.\ \ (2.9.10)
\end{russian}}

{\begin{russian}\sffamily
Естественно, что при других начальных условиях  $\vec x_{\mathit{C1}}(t_0)$ решение  $\vec x_{\mathit{C1}}(t)$ будет
другим
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}{{}}.{\vec x}{_{\mathit{C1}}}(t)=A(t)\overset{}{\vec x_{\mathit{C1}}}(t)+B(t)\vec
u_0(t)$.\ \ (2.9.11)
\end{russian}}

{\begin{russian}\sffamily
Вычтем из (2.9.11) уравнение (2.9.10):
\end{russian}}

{\begin{russian}\sffamily
\ \  $\frac d{\normalsubformula{\text{dt}}}\left\{\vec x_{\mathit{C1}}(t)-\vec
x_{\mathit{C0}}(t)\right\}=A(t)\left\{\vec x_{\mathit{C1}}(t)-\vec x_{\mathit{C0}}(t)\right\}$\ \ (2.9.12)
\end{russian}}

{\begin{russian}\sffamily
Обозначив
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x(t)=\vec x_{\mathit{C1}}(t)-\vec x_{\mathit{C0}}(t)$,
\end{russian}}

{\begin{russian}\sffamily
при начальных условиях 
\end{russian}}

\begin{equation*}
\vec x(t_0)=\vec x_{\mathit{C1}}(t_0)-\vec x_{\mathit{C0}}(t_0)
\end{equation*}
{\begin{russian}\sffamily
получим уравнение
\end{russian}}

{\begin{russian}\sffamily
\ \  $\overset .{\vec x}(t)=A(t)\vec x(t)$, \ \ \ при \ \ \ \  $t=t_0$  $\vec x=\vec x(t_0)$.\ \ (2.9.13)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, понятие устойчивости \textit{решения} можно свести к поня­тию устойчивости \textit{линейной системы}.
\end{russian}}

{\begin{russian}\sffamily
\textit{Линейная система устойчива в определенном смысле (по Ляпунову, асимптотически или асимптотически в целом), если
тривиальное решение } $\vec x_0(t)\equiv 0$\textit{ устойчиво в этом смысле}.
\end{russian}}

{\begin{russian}\sffamily
\textit{Линейная система асимптотически устойчива тогда и только тогда, когда она асимптотически устойчива в целом}.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, исследование вопроса устойчивости решений линейной неавтономной системы сводится к исследованию решения
соответствующего однородного дифференциального уравнения, которое определяется матрицей  $A(t)$ и имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x(t)=Φ(t,t_0)\vec x(t_0)$;\ \ \ \ (2.9.14)
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec y=C(t)Φ(t,t_0)\vec x(t_0)$.\ \ \ \ (2.9.15)
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим три возможных случая.
\end{russian}}

{\begin{russian}\sffamily
1.  $Φ(t,t_0)$– ограниченная матрица в интервале  $[t_0,\infty )$, то есть существует такое положительное число  $М$,
что
\end{russian}}

\begin{equation*}
|Φ_{\normalsubformula{\text{ij}}}(t,t_0)|\le M,\;\;\;\;\;\;\;t\ge t_0;i,j=1,2..,n.
\end{equation*}
{\begin{russian}\sffamily
Тогда получаем, что
\end{russian}}

{\begin{russian}\sffamily
\ \  $\|\vec x(t)\|\le n^2M\underset i{\text{max}}|x_i(t_0)|$,
\end{russian}}

{\begin{russian}\sffamily
и условие устойчивости выполняется, если взять, например,
\end{russian}}

{\begin{russian}\sffamily
\ \  $δ\le \frac ε{n^2M}$.
\end{russian}}

{\begin{russian}\sffamily
2. Переходная матрица удовлетворяет условию
\end{russian}}

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}Φ(t,t_0)=0$.\ \ 
\end{russian}}

{\begin{russian}\sffamily
При этом движение, а значит, и сама система являются асимптотически устойчивыми.
\end{russian}}

{\begin{russian}\sffamily
3.  $Φ(t,t_0)$– неограниченная матрица в интервале  $[t_0,\infty )$. При этом движение неустойчиво, так как для любого 
$\vec x(t_0)\neq 0$
\end{russian}}

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}\vec x(t)=\infty $.
\end{russian}}

{\begin{russian}\sffamily
Это означает и неустойчивость самой системы.
\end{russian}}

{\begin{russian}\sffamily
Если система является наблюдаемой и управляемой (эти понятия будут рассмотрены в пп. 3.2, 3.3), то устойчивость системы
можно исследовать с помощью весовой функции. Система асимптотически устойчива, если
\end{russian}}

{\begin{russian}\sffamily
\ \   $\underset{t\rightarrow \infty }{\text{lim}}w_y(t,τ)=0$.
\end{russian}}

{\begin{russian}\sffamily
Итак, линейная система является асимптотически устойчивой, если ее переходная матрица с течением времени стремится к
нулевой матрице. Для стационарных систем, то есть для систем с постоянными параметрами, это условие \ эквивалентно
требованию, чтобы все собственные числа матрицы  $А$ имели отрицательные действительные части, то есть лежали в левой
полуплоскости плоскости комплексной переменной  $λ$ . Это следует из формы представления переходной матрицы через
собственные числа и правые и левые собственные векторы матрицы  $А$ в соответствии с (2.4.28). Таким образом, анализ
устойчивости системы может быть сведен к анализу расположения собственных чисел матрицы  $А$, или, что то же самое,
расположения полюсов передаточной функции полностью управляемой и наблюдаемой системы.
\end{russian}}

{\begin{russian}\sffamily
В теории автоматического управления разработан ряд методов, называемых критериями устойчивости, позволяющих
проанализировать расположение собственных чисел относительно мнимой оси плоскости  $λ$ и не требующих при этом точного
решения соответствующего характеристического уравнения. К первой группе этих методов относятся так называемые
алгебраические критерии, которые путем элементарных вычислений по коэффициентам характеристического полинома позволяют
проанализировать устойчивость исследуемой системы с известными значениями ее параметров.
\end{russian}}

\subsubsection{Необходимое условие устойчивости}
\hypertarget{RefHeadingToc455659720}{}{\begin{russian}\sffamily
\textit{Для устойчивости системы с характеристическим полиномом}
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ(λ)=a_0λ^n+a_1λ^{n-1}+...a_{n-1}λ+a_n$\ \ (2.9.16)
\end{russian}}

{\begin{russian}\sffamily
необходимо, чтобы при  $a_0>0$ все коэффициенты характеристического полинома были положительны, то есть  $a_i>0$ при 
$i=1\;,\;\;2\;,\;\;...\;,\;n$.
\end{russian}}

{\begin{russian}\sffamily
Докажем это утверждение. Если  $λ_1\;,\;λ_2\;,\;\text{,,,}\;,\;\;λ_n$ - нули характеристического полинома (корни
характеристического уравнения  $ϕ(λ)=0$), то (2.9.16) может быть записано в виде
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ(λ)=(λ-λ_1)(λ-λ_2)\;...\;(λ-λ_n)$.\ \ (2.9.17)
\end{russian}}

{\begin{russian}\sffamily
Если  $λ_i$ - вещественный корень в левой полуплоскости, \ то есть  $λ_i=-α_i$ ( $α_i>0$ - положительное вещественное
число), то
\end{russian}}

\begin{equation*}
(λ-λ_i)=(λ+α_i)
\end{equation*}
{\begin{russian}\sffamily
и произведение таких сомножителей даст полином только с положительными коэффициентами.
\end{russian}}

{\begin{russian}\sffamily
Пусть  $λ_i$ - комплексный \ корень в левой полуплоскости, \ то есть  $λ_i=-α_i+\mathit{jω}_i$ \ \ ( $α_i>0$). Тогда при
всех вещественных коэффициентах характеристического полинома среди его нулей должен быть комплексно - сопряжённый: 
\includegraphics[width=3.634cm,height=0.741cm]{1-img051.png} . Произведение двух соответствующих сомножителей даст
полином второй степени с положительными коэффициентами:
\end{russian}}

{\begin{russian}\sffamily
\ \  $(λ-λ_i)(λ-λ_{i+1})=λ^2+2α_iλ+α_i^2+ω_i^2)$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Следует обратить внимание на то, что рассмотренное условие устойчивости не является достаточным. Если среди
коэффициентов характеристического полинома имеются отрицательные, то это означает, что соответствующая система
неустойчива. Если все коэффициенты положительны, то система может быть как устойчивой, так и неустойчивой. В этом
случае необходим дополнительный анализ.
\end{russian}}


\bigskip

\subsubsection{Критерий устойчивости Гурвица}
\hypertarget{RefHeadingToc455659721}{}{\begin{russian}\sffamily
Пусть характеристический полином некоторой системы имеет вид (2.9.16). Сопоставим этому полиному матрицу \ Гурвица:
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$G=\left[\begin{matrix}a_1&a_3&a_5&...&0&0\\a_0&a_2&a_4&...&0&0\\0&a_1&a_3&...&0&0\\...&...&...&...&...&...\\0&0&0&...&a_{n-1}&0\\0&0&0&...&a_{n-2}&a_n\end{matrix}\right]$.\ \ (2.9.18)
\end{russian}}

{\begin{russian}\sffamily
По главной диагонали стоят коэффициенты полинома, остальные элементы строятся по следующему принципу: вверх от
диагонального элемента ставятся коэффициенты полинома в порядке возрастания индексов, \ вниз - коэффициенты полинома в
порядке убывания индексов. Элементы, требующие индексов, больших степени полинома или отрицательных, устанавливаются
нулевыми.
\end{russian}}


\bigskip


\bigskip

{\begin{russian}\sffamily\bfseries
Критерий Гурвица
\end{russian}}

{\begin{russian}\sffamily
\ \textit{Для устойчивости системы необходимо и достаточно, чтобы при а}\textit{\textsubscript{0}}\textit{>0 были
положительны \ все (n) главные миноры матрицы \ \ \ \ Гурвица.}
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим \ \ примеры конкретизации критерия Гурвица для простейших случаев.
\end{russian}}

\liststyleWWviiiNumlxix
\begin{itemize}
\item \begin{equation*}
n=1
\end{equation*}
\end{itemize}
{\begin{russian}\sffamily
Запишем дифференциальное уравнение
\end{russian}}

{\begin{russian}\sffamily
\ \  \includegraphics[width=5.091cm,height=1.524cm]{1-img052.png} 
\end{russian}}

{\begin{russian}\sffamily
и характеристическое уравнение
\end{russian}}

{\begin{russian}\sffamily
\ \  $a_0λ+a_1=0$.
\end{russian}}

{\begin{russian}\sffamily
В данном случае применение критерия Гурвица даёт тривиальный результат:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\;а_0>0,\;\;\;a_1>0\;$.
\end{russian}}

\liststyleWWviiiNumlxxviii
\begin{itemize}
\item \begin{equation*}
n=2
\end{equation*}
\end{itemize}
{\begin{russian}\sffamily
Запишем дифференциальное уравнение
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $\text{  }a_0\cdot \frac{d^2y}{\normalsubformula{\text{dt}}^2}+a_1\cdot
\frac{\normalsubformula{\text{dy}}}{\normalsubformula{\text{dt}}}+a_2y=0$,
\end{russian}}

{\begin{russian}\sffamily
характеристическое уравнение
\end{russian}}

\begin{equation*}
a_0λ^2+a_0λ+a_1=0
\end{equation*}
{\begin{russian}\sffamily
и матрицу Гурвица
\end{russian}}

{\begin{russian}\sffamily
\ \  $G=\left[\begin{matrix}a_1&0\\a_0&a_2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Как и в предыдущем случае, при  $a_0>0$ применение критерия Гурвица даёт тривиальный результат:
\end{russian}}

{\begin{russian}\sffamily
\ \  $a_1>0,\text{   }a_2>0$.
\end{russian}}

{\begin{russian}\sffamily
Отметим, что \textit{для систем первого и второго порядка необходимое условие устойчивости является и достаточным}.
\end{russian}}

\liststyleWWviiiNumxxxvii
\begin{itemize}
\item \begin{equation*}
n=3
\end{equation*}
\end{itemize}
{\begin{russian}\sffamily
Запишем характеристическое уравнение
\end{russian}}

\begin{equation*}
a_0λ^3+a_1λ^2+a_2λ+a_3=0
\end{equation*}
{\begin{russian}\sffamily
и матрицу Гурвица
\end{russian}}

{\begin{russian}\sffamily
\ \  $G=\left[\begin{matrix}a_1&a_3&0\\a_0&a_2&0\\0&a_1&a_3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Для устойчивости системы по критерию Гурвица необходимо и достаточно, чтобы при  $a_0>0$ были положительны первый 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Δ_1=a_1>0$,
\end{russian}}

{\begin{russian}\sffamily
второй
\end{russian}}

\begin{equation*}
\text{      }Δ_2=|\begin{matrix}a_1&a_3\\a_0&a_2\end{matrix}|=a_1a_2-a_0a_3>0
\end{equation*}
{\begin{russian}\sffamily
и третий
\end{russian}}

\begin{equation*}
\text{    }Δ_3=|\begin{matrix}a_1&a_3&0\\a_0&a_2&0\\0&a_1&a_3\end{matrix}|=a_3Δ_2>0
\end{equation*}
{\begin{russian}\sffamily
главные миноры матрицы Гурвица. С учётом необходимого условия устойчивости (требования положительности всех
коэффициентов характеристического уравнения) критерий Гурвица для устойчивости системы третьего порядка требует
выполнения неравенства
\end{russian}}

{\begin{russian}\sffamily
\ \  $a_1a_2-a_0a_3>0$.\ \ \ \ (2.9.19)
\end{russian}}

\liststyleWWviiiNumviii
\begin{itemize}
\item \begin{equation*}
n=4
\end{equation*}
\end{itemize}
{\begin{russian}\sffamily
Запишем характеристическое уравнение
\end{russian}}

\begin{equation*}
a_0λ^4+a_1λ^3+a_2λ^2+a_3λ+a_4=0
\end{equation*}
{\begin{russian}\sffamily
и матрицу Гурвица
\end{russian}}

{\begin{russian}\sffamily
\ \  $G=\left[\begin{matrix}a_1&a_3&0&0\\a_0&a_2&a_4&0\\0&a_1&a_3&0\\0&a_0&a_2&a_4\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Для устойчивости системы по критерию Гурвица необходимо и достаточно, чтобы при  $a_0>0$ были положительны первый 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Δ_1=a_1>0$,
\end{russian}}

{\begin{russian}\sffamily
второй
\end{russian}}

{\begin{russian}\sffamily
\ \  $\text{      }Δ_2=|\begin{matrix}a_1&a_3\\a_0&a_2\end{matrix}|=a_1a_2-a_0a_3>0$,
\end{russian}}

{\begin{russian}\sffamily
третий
\end{russian}}

\begin{equation*}
\text{    }Δ_3=|\begin{matrix}a_1&a_3&0\\a_0&a_2&a_4\\0&a_1&a_3\end{matrix}|=a_3(a_1a_2-a_0a_3)-a_4a_1^2>0
\end{equation*}
{\begin{russian}\sffamily
и четвёртый
\end{russian}}

\begin{equation*}
\;Δ_4=a_4Δ_3>0
\end{equation*}
{\begin{russian}\sffamily
главные миноры матрицы Гурвица. С учётом необходимого условия устойчивости (требования положительности всех
коэффициентов характеристического уравнения) критерий Гурвица для устойчивости системы четвёртого порядка требует
выполнения неравенства
\end{russian}}

{\begin{russian}\sffamily
\ \  $a_3(a_1a_2-a_0a_3)-a_4a_1^2>0$.\ \ (2.9.20)
\end{russian}}

{\begin{russian}\sffamily
\ \ Для системы пятого порядка критерий Гурвица выливается в требование выполнения уже двух неравенств:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}a_1a_2-a_0a_3>0\;,\hfill\null \\(a_1a_2-a_0a_3)(a_3a_4-a_2a_5)-(a_1a_4-a_0a_5)^2>0\;.\hfill\null
\end{matrix}\hfill $\ \ (2.9.21)
\end{russian}}

{\begin{russian}\sffamily
С дальнейшим увеличением порядка систем использование критерия Гурвица становится всё более громоздким и теряет смысл.
Если возникает необходимость привлечения вычислительной техники, то в наше время проще непосредственно вычислить корни
характеристического уравнения. Тем не менее, для систем третьего - четвёртого порядков привлекает простота
использования критерия Гурвица.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 2.9.1. Рассмотрим систему, представленную на рис. 2.40, с входным сигналом  $v$, сигналом ошибки  $ε$ и выходным
сигналом  \includegraphics[width=0.459cm,height=0.6cm]{1-img053.png} .
\end{russian}}


\bigskip

{\centering  \includegraphics[width=10.319cm,height=3.784cm]{1-img054.png} \par}
{\begin{russian}\sffamily
Этой системе соответствует передаточная функция
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{\normalsubformula{\text{vy}}}(p)=\frac{\frac k{(\normalsubformula{\text{Tp}}+1)^3}}{1+\frac
k{(\normalsubformula{\text{Tp}}+1)^3}}=\frac k{T^3p^3+3T^2p^2+3\normalsubformula{\text{Tp}}+1+k}$.
\end{russian}}

{\begin{russian}\sffamily
В соответствии со свойствами передаточных функций характеристический полином замкнутой системы имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ(p)=T^3p^3+3T^2p^2+3\normalsubformula{\text{Tp}}+1+k$. $ $
\end{russian}}

{\begin{russian}\sffamily
По критерию Гурвица система устойчива, если выполняется \ неравенство
\end{russian}}

{\begin{russian}\sffamily
\ \  $a_1a_2-a_0a_3=9T^3-T^3(1+k)>0$.
\end{russian}}

{\begin{russian}\sffamily
Отсюда, с учётом требования положительности всех коэффициентов характеристического полинома, следует, что система
устойчива, если при  $T>0$ выполняются неравенства
\end{russian}}

{\begin{russian}\sffamily
\ \  $-1<k<8$.
\end{russian}}

{\begin{russian}\sffamily
Значения параметров, при которых система находится на границе устойчивости, принято называть критическими. В данном
примере у коэффициента  $k$ имеется два критических значения - нижнее  $k_{\normalsubformula{\text{кр}}}^н=-1$ и
верхнее  $k_{\normalsubformula{\text{кр}}}^в=8$.
\end{russian}}

\subsubsection{Частотный критерий устойчивости (критерий Найквиста)}
\hypertarget{RefHeadingToc455659722}{}{\begin{russian}\sffamily
Часто рассмотрению подлежат замкнутые системы, структурные схемы которых могут быть приведены к типовому виду,
представленному на рис. 2.41. Как правило, передаточная функция разомкнутой системы  $W(p)$ имеет относительно простой
вид и несложно определить расположение её полюсов относительно мнимой оси. Таким образом, предполагается, что анализ
устойчивости разомкнутой системы проведён. В то же время анализ устойчивости замкнутой системы представляет собой
нетривиальную задачу. Критерий устойчивости Найквиста оперирует с частотными характеристиками, достаточно нагляден и
позволяет использовать физические представления о свойствах исследуемой системы. Критерий \ Найквиста позволяет судить
об устойчивости системы в замкнутом состоянии по частотным характеристикам разомкнутой системы.
\end{russian}}

 \includegraphics[width=11.509cm,height=4.26cm]{1-img055.png} 

\paragraph[\ Понятие логарифмического вычета]{\ Понятие логарифмического вычета}
{\begin{russian}\sffamily
Пусть задана некоторая функция  $Ψ(p)$, аналитичная всюду в области  $G$, за исключением конечного числа изолированных
особых точек. Будем полагать, что все особые точки являются полюсами. Будем полагать также, что граница  $C$ области 
$G$ не содержит ни нулей, ни полюсов функции \  $Ψ(p)$.
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим логарифмическую производную функции  $Ψ(p)$
\end{russian}}

{\begin{russian}\sffamily
\ \  $L(p)=\frac d{\normalsubformula{\text{dp}}}\left[\text{ln}Ψ(p)\right]=\frac{Ψ^'(p)}{Ψ(p)}$\ \ (2.9.22)
\end{russian}}

{\begin{russian}\sffamily
и назовем логарифмическим вычетом функции  $Ψ(p)$ в точке  $p=a$ вычет в этой точке ее логарифмической производной
\end{russian}}

{\begin{russian}\sffamily
\ \  $\text{LnRes}\left\{Ψ(p)\text{,a}\right\}=\text{Res}\;\{L(p),a\}$.\ \ (2.9.23)
\end{russian}}

{\begin{russian}\sffamily
Пусть функция  $Ψ(p)$ имеет в точке  $p=a$ ноль порядка  $k$, то есть 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Ψ(p)=(p-a)^kF(p)$,
\end{russian}}

{\begin{russian}\sffamily
где 
\end{russian}}

{\begin{russian}\sffamily
\ \  $F(a)\neq 0$.
\end{russian}}

{\begin{russian}\sffamily
Тогда 
\end{russian}}

\begin{equation*}
Ψ^'(p)=k(p-a)^{k-1}F(p)+(p-a)^kF^'(p)
\end{equation*}
{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \  $L(p)=\frac k{p-a}+\frac{F^'(p)}{F(p)}$.\ \ (2.9.24)
\end{russian}}

{\begin{russian}\sffamily
Отметим, что полюсы функций  $F(p)$ и  $F^'(p)$ совпадают. Так как нули аналитической функции изолированы, то в
достаточно малом круге  $|p-a|<ρ$ \ функция  $F^'(p)/F(p)$ является аналитической и может быть разложена \ в
окрестности точки  $p=a$ в ряд Тейлора:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\frac{F^'(p)}{F(p)}=\overset{\infty }{\underset{n=0}{\sum }}α_n(p-a)^n$.
\end{russian}}

{\begin{russian}\sffamily
С учётом этого \ (2.9.24) превращается в 
\end{russian}}

{\begin{russian}\sffamily
\ \  $L(p)=\frac k{p-a}+\overset{\infty }{\underset{n=0}{\sum }}α_n(p-a)^n$.\ \ 
\end{russian}}

{\begin{russian}\sffamily
Эта формула представляет собой разложение в ряд Лорана функции  $L(p)$ в окрестности точки  $p=a$. Из этой формулы
следует, что точка  $p=a$ является полюсом первого порядка функции  $L(p)$ и 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\text{Res}\{L(p),a\}=k$.\ \ \ \ (2.9.25)
\end{russian}}

{\begin{russian}\sffamily
Пусть теперь функция  $Ψ(p)$ имеет в точке  $p=b$ полюс кратности \  $s$, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \  $Ψ(p)=(p-b)^{-s}J(p)$,
\end{russian}}

{\begin{russian}\sffamily
где \textenglish{b} не является ни нулём, ни полюсом функции  $J(p)$. Тогда 
\end{russian}}

\begin{equation*}
Ψ^'(p)=-s(p-b)^{-(s+1)}J(p)+(p-b)^{-s}J^'(p)
\end{equation*}
{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \  $L(p)=\frac{-s}{p-b}+\frac{J^'(p)}{J(p)}$.
\end{russian}}

{\begin{russian}\sffamily
По аналогии с предыдущим случаем получим, что в окрестности точки  $p=b$
\end{russian}}

{\begin{russian}\sffamily
\ \  $L(p)=\frac{-s}{p-b}+\overset{\infty }{\underset{n=0}{\sum }}β_n(p-b)^n$,\ \ 
\end{russian}}

{\begin{russian}\sffamily
следовательно,
\end{russian}}

{\begin{russian}\sffamily
\ \  $\text{Res}\{L(p),b\}=-s$.\ \ \ \ (2.9.26)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, в нулях и полюсах функции  $Ψ(p)$ ее логарифмическая производная (2.9.22)
\end{russian}}

\begin{equation*}
L(p)=\frac{Ψ^'(p)}{Ψ(p)}
\end{equation*}
{\begin{russian}\sffamily
имеет полюсы первого порядка, причем в нуле функции  $Ψ(p)$ логарифмический вычет равен порядку нуля, а в полюсе –
взятом со знаком минус порядку полюса.
\end{russian}}

{\begin{russian}\sffamily
По теореме вычетов имеем
\end{russian}}

{\begin{russian}\sffamily
\ \  $\frac 1{2\mathit{πj}}\;\underset C{\oint }\;\frac{Ψ^'(p)}{Ψ(p)}\normalsubformula{\text{dp}}=\underset v{\sum
}\text{Res}\left\{\frac{Ψ^'(p)}{Ψ(p)},p_v\right\}=\underset v{\sum }k_v-\underset v{\sum }s_v$,
\end{russian}}

{\begin{russian}\sffamily
или окончательно
\end{russian}}

{\begin{russian}\sffamily
\ \  $\frac 1{2\mathit{πj}}\underset C{\oint }\frac{Ψ^'(p)}{Ψ(p)}\normalsubformula{\text{dp}}=N-Π$,\ \ (2.9.27)\ \ 
\end{russian}}

{\begin{russian}\sffamily
где  $N$– число нулей, а  $Π$–число полюсов функции  $Ψ(p)$ в области \textenglish{G}.
\end{russian}}

\paragraph[\ Принцип приращения аргумента]{\ Принцип приращения аргумента}
{\begin{russian}\sffamily
Обозначим 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Y(p)=|Y(p)|e^{\mathit{jj}_Y(p)}$,\ \ \ \ (2.9.28)
\end{russian}}

{\begin{russian}\sffamily
тогда
\end{russian}}

{\begin{russian}\sffamily
\ \  $\text{ln}Y(p)=\text{ln}|Y(p)|+\mathit{jj}_Y(p)$.\ \ (2.9.29)
\end{russian}}

{\begin{russian}\sffamily
С учётом (2.9.27) получаем:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\frac 1{2\mathit{πj}}\underset C{\oint }\frac{Ψ^'(p)}{Ψ(p)}\normalsubformula{\text{dp}}=\frac
1{2\mathit{πj}}\underset C{\oint }d\left(\text{ln}Ψ(p)\right)=\hfill\null \\=\frac 1{2\mathit{πj}}\underset C{\oint
}d\text{ln}|Ψ(p)|+\frac 1{2\mathit{πj}}\underset C{\oint }\normalsubformula{\text{dj}}ϕ_Ψ(p)=N-Π.\hfill\null
\end{matrix}\hfill $\ \ (2.9.30)
\end{russian}}

{\begin{russian}\sffamily
Поскольку в правой части равенства стоит вещественное число, то мнимая часть левой части равенства также равна нулю.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, если функция  $Ψ(p)$ аналитична в замкнутой области  $G$, ограниченной контуром  $C$, за исключением
конечного числа полюсов в области  $G$, и если функция  $Ψ(p)$ не имеет ни полюсов, ни нулей на контуре  $C$, то
приращение аргумента функции  $Ψ(p)$ при движении вектора  $p$ по замкнутому контуру  $C$ определяется выражением
\end{russian}}

{\begin{russian}\sffamily
\ \  $\mathit{Δϕ}_Ψ^C=2π(N-Π)$.\ \ \ \ (2.9.31)
\end{russian}}

\paragraph[\ Анализ устойчивости замкнутой системы]{\ Анализ устойчивости замкнутой системы}
{\begin{russian}\sffamily
Рассмотрим замкнутую систему с единичной обратной связью \ \ \ \ \ \ \ \ \ \ (рис. 2.41). Пусть известно, что среди  $n$
полюсов  $p_1,p_2,...,p_n$ передаточной функции разомкнутой системы
\end{russian}}

{\begin{russian}\sffamily
\ \  $W(p)=\frac{R(p)}{Q(p)}$\ \ \ \ (2.9.32)
\end{russian}}

{\begin{russian}\sffamily
имеется  $v_1$ нулевых и  $v_2$ чисто мнимых полюсов на верхней полуплоскости плоскости комплексной переменной  $p$ (рис
2.42) , то есть 
\end{russian}}

{\begin{russian}\sffamily
 $Q(p)=p^{v_1}(p-\mathit{jω}_q)^{v_2}Q_1(p)$.\ \ \ \ (2.9.33)
\end{russian}}

{\centering  \includegraphics[width=14.783cm,height=10.806cm]{1-img056.png} \par}
{\begin{russian}\sffamily
Образуем функцию
\end{russian}}

{\begin{russian}\sffamily
\ \  $Ψ(p)=1+W(p)=\frac{Q(p)+R(p)}{Q(p)}=\frac{S(p)}{Q(p)}$,\ \ (2.9.34)
\end{russian}}

{\begin{russian}\sffamily
характерную тем, что ее знаменатель является характеристическим полиномом разомкнутой системы, а числитель –
характеристическим полиномом замкнутой. 
\end{russian}}

{\begin{russian}\sffamily
\ \ Выберем в качестве области  $G$ \ всю правую полуплоскость плоскости комплексной переменной  $p$. Контур  $C$
сформируем из мнимой оси, за исключением точек, совпадающих с полюсами передаточной функции разомкнутой системы, дуг
окружностей бесконечно малого \ радиуса, охватывающих эти полюсы, как показано на рис. 2.42, и окружности бесконечно
большого радиуса, охватывающей всю правую полуплоскость. 
\end{russian}}

{\begin{russian}\sffamily
Допустим, в общем случае, что разомкнутая система неустойчива и её передаточная функция имеет  $m$ "неустойчивых"
полюсов, то есть  $m$ полюсов \ в правой полуплоскости плоскости комплексной переменной  $p$. Предположим, что
замкнутая система также неустойчива и  $z$ – число неустойчивых полюсов передаточной функции замкнутой системы. 
\end{russian}}

{\begin{russian}\sffamily
Тогда, в соответствии с принципом приращения аргумента,
\end{russian}}

{\begin{russian}\sffamily
\ \  $\mathit{Δϕ}_Ψ^c=2π(z-m).$\ \ \ \ (2.9.35)
\end{russian}}

{\begin{russian}\sffamily
Если обходить контур  $C$ в отрицательном направлении, совпадающем с положительным направлением \ мнимой оси, то
\end{russian}}

{\begin{russian}\sffamily
\ \  $\mathit{Δϕ}_Ψ^{-C}=2π(m-z)$.\ \ \ \ (2.9.36)
\end{russian}}

{\begin{russian}\sffamily
Будем сопоставлять изменение комплексной переменной р при перемещении ее вдоль контура  $C$ на плоскости  $p$ и
соответствующее ему изменение функции \  $Ψ(p)$ на комплексной плоскости  $Ψ$. Для этого разобьем контур  $C$ на
несколько характерных участков.
\end{russian}}

{\begin{russian}\sffamily
\ На участке \textenglish{I} годограф комплексной переменной  $p$ изменяется по окружности бесконечно большого радиуса,
охватывая всю правую полуплоскость, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \  $p_I=\mathit{ρe}^{\mathit{jΘ}},\;\;\;\;\;\;ρ\rightarrow \infty $.\ \ \ \ (2.9.37)
\end{russian}}

{\begin{russian}\sffamily
Ранее отмечалось, что в физически реализуемых системах порядок числителя передаточной функции не может превышать порядок
ее знаменателя. Отсюда следует, что степени полиномов  $S(p)$ и  $Q(p)$ равны, а значит, 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Ψ_|(p)=\underset{ρ\rightarrow \infty
}{\text{lim}}\frac{S(\mathit{ρe}^{\mathit{jΘ}})}{Q(\mathit{ρe}^{\mathit{jΘ}})}=\normalsubformula{\text{const}}$.\ \ (2.9.38)\ \ 
\end{russian}}

{\begin{russian}\sffamily
Таким образом, приращение фазы функции  $Ψ(p)$ при изменении $p$ вдоль первого участка равно нулю:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\mathit{Δϕ}_Ψ^I=0$.\ \ (2.9.39)
\end{russian}}

{\begin{russian}\sffamily
В качестве \ участка \ \textenglish{II} выберем мнимую ось плоскости  $p$, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $p_{\normalsubformula{\text{II}}}=\mathit{jω}$,\ \ (2.9.40)
\end{russian}}

{\begin{russian}\sffamily
за исключением тех ее точек, в которых располагаются полюсы разомкнутой системы. Соответствующая этому изменению  $p$
функция
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Ψ_{||}(p)=Ψ(\mathit{jω}),\;\;\;\;\;\;\;-\infty <ω<\infty $\ \ (2.9.41)
\end{russian}}

{\begin{russian}\sffamily
легко может быть вычислена. 
\end{russian}}

{\begin{russian}\sffamily
Участок \textenglish{III} – это участок движения комплексной переменной  $p$ вдоль окружности бесконечно малого радиуса
с центром в начале координат, где по условию находится \  $v_1$ полюсов передаточной функции разомкнутой системы. При
этом, в соответствии с \ (2.9.33), функция  $Ψ(p)$ будет иметь вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}Ψ_{|||}(p)=\underset{ρ\rightarrow
0}{\text{lim}}\frac{S(\mathit{ρe}^{\mathit{jΘ}})}{ρ^{v_1}e^{\normalsubformula{\text{jv}}_1Θ}(\mathit{ρe}^{\mathit{jΘ}}-\mathit{jω}_q)^{v_2}Q_1(\mathit{ρe}^{\mathit{jΘ}})}=\hfill\null
\\=\underset{ρ\rightarrow 0}{\text{lim}}\frac{S(0)}{(-\mathit{jω}_q)^{v_2}Q_1(0)}\cdot
\frac{e^{-\normalsubformula{\text{jv}}_1Θ}}{ρ^{v_1}},\hfill\null \end{matrix}\hfill $\ \ (2.9.42)
\end{russian}}

{\begin{russian}\sffamily
то есть на плоскости  $Ψ(p)$ будет иметь место перемещение («доворот») по окружности бесконечно большого радиуса.
Направление этого перемещения противоположно по знаку направлению перемещения на плоскости  $p$, а абсолютная величина
приращения угла - \ в  $v_1$ раз больше. Таким образом, третьему участку соответствует изменение фазы функции  $Ψ(p)$
на величину 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\mathit{Δϕ}_Ψ^{|||}=-v_1π$.\ \ \ \ (2.9.43)
\end{russian}}

{\begin{russian}\sffamily
Наконец, рассмотрим движение комплексной переменной  $p$ вдоль окружности бесконечно малого радиуса с центром в точке 
$p=\mathit{jω}_q$, где расположено  $v_2$ полюсов передаточной функции разомкнутой системы. На этом, четвертом участке
контура С,
\end{russian}}

{\begin{russian}\sffamily
\ \  $p_{\normalsubformula{\text{III}}}=\mathit{jω}_q+\mathit{ρe}^{\mathit{jΘ}},\;\;\;\;\;\;ρ\rightarrow 0$.\ \ (2.9.44)
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (2.9.33) \ функция
\end{russian}}

{\begin{russian}\sffamily
\ \  $Ψ_{\normalsubformula{\text{IV}}}(p)=\underset{ρ\rightarrow
0}{\text{lim}}\frac{S(\mathit{jω}_q)}{(\mathit{jω}_q)^{v_1}Q_1(\mathit{jω}_q)}\cdot
\frac{e^{-\normalsubformula{\text{jv}}_2Θ}}{ρ^{ν_2}}$\ \ (2.9.45)
\end{russian}}

{\begin{russian}\sffamily
будет образовывать годограф, перемещающийся на плоскости  $Ψ$ по окружности бесконечно большого радиуса, и
соответствующее приращение фазы будет равно
\end{russian}}

{\begin{russian}\sffamily
\ \  $\mathit{Δϕ}_Ψ^{\normalsubformula{\text{IV}}}=-2v_2\frac π 2$.\ \ \ \ (2.9.46)
\end{russian}}

{\begin{russian}\sffamily
Пользуясь тем, что  $Ψ(p)$ является дробно–рациональной функцией от  $p$, и 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Ψ(p^{\ast })=Ψ^{\ast }(p)$,\ \ \ \ (2.9.47)
\end{russian}}

{\begin{russian}\sffamily
можно произвести обход лишь верхней половины контура  $C$. При этом сменим направление обхода контура С так, чтобы
передвигаться в направлении увеличения  $ω$. Тогда суммарное приращение фазы
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$\mathit{Δϕ}_{Ψ\normalsubformula{\text{Sum}}}=\mathit{Δϕ}_{\mathit{ΨI}}+\mathit{Δϕ}_{Ψ\normalsubformula{\text{II}}}+\mathit{Δϕ}_{Ψ\normalsubformula{\text{III}}}+\mathit{Δϕ}_{Ψ\normalsubformula{\text{IV}}}=π(m-z).$\ \ (2.9.48)
\end{russian}}

{\begin{russian}\sffamily
Удобнее строить не функцию  $Ψ(p)$, а функцию  $W(p)$. Как видно из равенства (2.9.34), годограф функции  $Ψ(p)$
поворачивается вокруг начала координат на тот же угол, что и годограф функции  $W(p)$ поворачивается относительно точки
 $(-1,\mathit{j0})$.
\end{russian}}

{\begin{russian}\sffamily
Вышеприведенные рассуждения позволяют сформулировать критерий устойчивости замкнутой системы, который называют частотным
критерием, или критерием Найквиста.
\end{russian}}


\bigskip

{\begin{russian}\sffamily\bfseries
Критерий Найквиста
\end{russian}}

{\begin{russian}\sffamily
\textit{Если передаточная функция разомкнутой системы имеет }\textenglish{\textit{m}}\textit{ полюсов с положительной
вещественной частью, то для устойчивости системы в замкнутом состоянии необходимо и достаточно, чтобы при изменении }
$ω$\textit{ от 0 до } $+\infty $\textit{ расширенная амплитудно-фазовая характеристика разомкнутой системы повернулась
вокруг точки } $(-1,\mathit{j0})$\textit{ на угол } $+\mathit{mπ}$\textit{. Расширение частотной характеристики }
$W(\mathit{jω})$\textit{ необходимо при наличии у передаточной функции разомкнутой системы полюсов на мнимой оси.
Каждому нулевому полюсу соответствует на амплитудно-фазовой характеристике доворот по окружности бесконечно большого
радиуса на угол } $-π/2$\textit{. Каждому чисто мнимому положительному полюсу соответствует на амплитудно-фазовой
характеристике доворот по окружности бесконечно большого радиуса на угол } $-π$\textit{.}
\end{russian}}

{\begin{russian}\sffamily
Естественно, что, давая формулировку критерия устойчивости, исходят из условия  $z=0$. Можно получить и более общий
результат. Основываясь на формуле (2.9.48), в каждом конкретном случае можно вычислить количество «неустойчивых»
полюсов замкнутой системы:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $z=m-\frac{\mathit{Δϕ}_{\normalsubformula{\text{SUM}}}} π$.\ \ (2.9.49)
\end{russian}}

{\begin{russian}\sffamily
Здесь  $\mathit{Δϕ}_{\normalsubformula{\text{SUM}}}$– результирующий угол поворота расширенной амплитудно-фазовой
характеристики разомкнутой системы вокруг точки  $(-1,\mathit{j0})$ при изменении  $ω$ от 0 до  $+\infty $.
\end{russian}}

{\begin{russian}\sffamily
На практике удобнее пользоваться другой формулировкой критерия, которая предложена Я. З. Цыпкиным и использует понятие
переходов расширенной амплитудно-фазовой характеристикой участка вещественной оси  $(-1\;,\;\;-\infty )$. 
\end{russian}}

{\begin{russian}\sffamily
\textit{Переходом называется пересечение амплитудно-фазовой характеристикой \ вещественной оси на интервале } $(-\infty
\;,\;\;-1\;]$\textit{. Переход считается положительным, если при увеличении частоты в точке перехода фаза растет, и
отрицательным – если уменьшается. Если амплитудно-фазовая характеристика начинается или заканчивается на указанном
участке вещественной оси, то имеет место половина перехода с соответствующим знаком.}
\end{russian}}

{\begin{russian}\sffamily
\ На рис. 2.43 приведены примеры, иллюстрирующие понятие переходов и критерий Найквиста. Все три примера соответствуют
системам, устойчивым в замкнутом состоянии.
\end{russian}}

{\centering  \includegraphics[width=15.533cm,height=14.055cm]{1-img057.png} \par}
{\begin{russian}\sffamily
В системе координат логарифмических частотных характеристик переход имеет место, если фазочастотная характеристика
пересекает линию  $-π\pm \mathit{kπ}$ (к=1,2...) и при этом логарифмическая амплитудно-частотная характеристика идет
выше оси абсцисс (модуль комплексного передаточного коэффициента больше единицы).
\end{russian}}

{\begin{russian}\sffamily
\ Приведем теперь формулировку критерия Найквиста, использующую понятие переходов.
\end{russian}}

{\begin{russian}\sffamily
\textit{Если передаточная функция разомкнутой системы имеет } $m$\textit{ полюсов с положительной вещественной частью,
то для устойчивости системы в замкнутом состоянии необходимо и достаточно, чтобы суммарное число переходов расширенной
логарифмической частотной характеристики было равно } $+m/2$\textit{. \ Если замкнутая система неустойчива, то число ее
«неустойчивых» полюсов}
\end{russian}}

{\begin{russian}\sffamily
\ \ \textenglish{\ \ } $z=m-2\sum Π$,\ \ (2.9.50)
\end{russian}}

{\begin{russian}\sffamily
\textit{где } $\sum Π$\textit{ – суммарное число переходов расширенной частотной характеристики разомкнутой системы.}
\end{russian}}

\paragraph[\ Понятие запасов устойчивости]{\ Понятие запасов устойчивости}
{\begin{russian}\sffamily
Естественно, что каждая система автоматического управления должна быть устойчивой. В инженерной практике часто
используется понятие запасов. Например, в строительстве и машиностроении общепринятым является термин "запас
прочности". Аналогично этому при проектировании систем управления пользуются понятиями запасов устойчивости.
\end{russian}}

{\begin{russian}\sffamily
Запасом устойчивости по модулю \ будем называть число, большее единицы, которое показывает, во сколько раз (на сколько
децибел) нужно изменить исходный передаточный коэффициент разомкнутой системы, чтобы вывести замкнутую систему на
границу устойчивости. Соответственно различают запасы по модулю на увеличение и уменьшение коэффициента. На рис. 2.43
для каждого из вариантов длина отрезка \textbf{oA} численно равна запасу устойчивости по модулю на уменьшение;
величина, обратная длине отрезка \textenglish{\textbf{oB}} для третьего варианта, - запасу устойчивости по модулю на
увеличение.
\end{russian}}

{\begin{russian}\sffamily
Запасом устойчивости по фазе  $ϕ_з$ называют минимальный по модулю угол, на который следует довернуть вектор 
$W(\mathit{jω})$ с модулем, равным единице, чтобы его конец оказался в точке (-1,\textenglish{j}0). На рис. 2.43 для
каждого из вариантов АФХ указан запас устойчивости по фазе.
\end{russian}}

\paragraph[\ Устойчивость систем с запаздыванием]{\ Устойчивость систем с запаздыванием}
{\begin{russian}\sffamily
Звено транспортного запаздывания смещает по времени выходной сигнал относительно входного на величину запаздывания  $τ$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $y(t)=u(t-τ)$.\ \ (2.9.51)
\end{russian}}

{\begin{russian}\sffamily
Передаточная функция и комплексный передаточный коэффициент соответственно представлены выражениями (2.9.52) и (2.9.53):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_з(p)=e^{-\mathit{τp}}$;\ \ (2.9.52)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_з(\mathit{jω})=e^{-j\normalsubformula{\text{ωτ}}}$.\ \ (2.9.53)
\end{russian}}

{\begin{russian}\sffamily
\ \ При исследовании устойчивости системы, в которую входит звено запаздывания, приводят её структурную схему к виду
(рис. 2.44), в котором это звено оказывается включённым последовательно с остальной частью системы.
\end{russian}}

{\centering  \includegraphics[width=11.959cm,height=5.001cm]{1-img058.png} \par}

\bigskip

{\begin{russian}\sffamily
При этом, если обозначить
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_0(p)=\frac{R_0(p)}{Q_0(p)}$,
\end{russian}}

{\begin{russian}\sffamily
то характеристическое уравнение замкнутой системы примет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Q_0(p)+R_0(p)\;e^{-\mathit{pτ}}=0$.\ \ (2.9.54)
\end{russian}}

{\begin{russian}\sffamily
В связи с тем, что разложение в ряд Тейлора экспоненциальной функции имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $e^{-\mathit{pτ}}=1-\mathit{pτ}+\frac 1{2!}(\mathit{pτ})^2-\frac 1{3\;!}(\mathit{pτ})^3+\;...$ ,
\end{russian}}

{\begin{russian}\sffamily
характеристическое уравнение (2.9.54) имеет бесконечно большое число корней. При этом, естественно, алгебраические
критерии устойчивости неприменимы. В то же время для данной системы может быть использован критерий Найквиста.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \ ПРИМЕР 2.9.2. Пусть структурная схема системы с запаздыванием приведена к виду, представленному на рис. 2.44 и
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_0(p)=\frac 2{(\normalsubformula{\text{Tp}}+1)^2}$.
\end{russian}}

{\begin{russian}\sffamily
На рис. 2.45 представлены амплитудно-фазовые характеристики звена запаздывания и последовательно с ним включённого звена
 $W_0(\mathit{jω})$. Так как модуль комплексного передаточного коэффициента звена запаздывания на всех частотах равен
единице, то АФХ разомкнутой системы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W(\mathit{jω})=W_0(\mathit{jω})e^{-j\normalsubformula{\text{ωτ}}}$\ \ (2.9.55)
\end{russian}}

{\begin{russian}\sffamily
отличается от  $W_0(\mathit{jω})$ только фазой:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ϕ(ω)=ϕ_0(ω)-\normalsubformula{\text{ωτ}}$.\ \ (2.9.56)
\end{russian}}

{\begin{russian}\sffamily
Если провести дугу окружности единичного радиуса с центром в начале
\end{russian}}

{\centering  \includegraphics[width=12.776cm,height=11.806cm]{1-img059.png} \par}
{\begin{russian}\sffamily
координат от отрицательной вещественной полуоси до пересечения с АФХ \  $W_0(\mathit{jω})$ в точке  $ω=ω_{'1'}$, то
полученное значение  $\mathit{Δϕ}$ из соотношения
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\mathit{Δϕ}=ω_{'1'}\cdot τ_{\normalsubformula{\text{кр}}}$\ \ (2.9.57)
\end{russian}}

{\begin{russian}\sffamily
позволит найти так называемое \textit{критическое} \textit{время запаздывания } $τ_{\normalsubformula{\text{кр}}}$, то
есть время запаздывания, при котором система выводится на границу устойчивости. Здесь  $ω_{'1'}$ - значение \ частоты,
при которой
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $|W_0(\mathit{jω}_{'1'})|=1$.\ \ (2.9.58)
\end{russian}}

{\begin{russian}\sffamily
В рассматриваемом примере
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $|W_0(\mathit{jω})|=\frac 2{1+(\mathit{ωT})^2}$,\ \ (2.9.59)
\end{russian}}

{\begin{russian}\sffamily
откуда
\end{russian}}

{\begin{russian}\sffamily
\ \  $ω_{'1'}=\frac 1 T$ , \ \ \  $ϕ_0(ω_1)=-\frac π 2$ , \ \  $\mathit{Δϕ}=\frac π 2$\ \ (2.9.60)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $τ_{\normalsubformula{\text{кр}}}=\frac{\mathit{πT}} 2$.\ \ (2.9.61)
\end{russian}}

\subsection{Качество процессов управления}
\hypertarget{RefHeadingToc455659723}{}\subsubsection{Основные показатели качества }
\hypertarget{RefHeadingToc455659724}{}{\begin{russian}\sffamily
Устойчивость - это необходимое, но недостаточное условие эффективной работы системы.
\end{russian}}

{\begin{russian}\sffamily
Комплекс требований, определяющих поведение системы в установившихся и переходных процессах отработки заданного
воздействия, определяется понятием «качество процесса управления», или «качество системы».
\end{russian}}

{\begin{russian}\sffamily
\ \ На этапе разработки системы управления \ рассматривают процессы управления в устойчивых системах при воздействии
особо "тяжелых" для них сигналов, заданных в виде определенных или случайных функций времени.
\end{russian}}

{\begin{russian}\sffamily
Качество работы системы проверяется по ее реакции на характерные входные воздействия:
\end{russian}}

\liststyleWWviiiNumlii
\begin{enumerate}
\item {\begin{russian}\sffamily
дельта функцию  $δ(t)$;
\end{russian}}
\item {\begin{russian}\sffamily
единичную функцию  $1(t)$;
\end{russian}}
\item {\begin{russian}\sffamily
гармонический сигнал \  $A\cdot \text{sin}ω_Ht$;
\end{russian}}
\item {\begin{russian}\sffamily
случайные воздействия с заданными вероятностными характеристиками.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
Качество отработки типовых сигналов оценивают либо непосредственно по выходному сигналу  $y(t)$, либо путем сравнения
этого сигнала  $y(t)$ с реакцией некоторой эталонной системы (рассогласование  $ε_e(t)$ на рис.2.46), либо по ошибке
воспроизведения командного сигнала
\end{russian}}

{\begin{russian}\sffamily
\ \  $ε_v(t)=v(t)-y(t)$.
\end{russian}}

{\centering  \includegraphics[width=11.218cm,height=6.085cm]{1-img060.png} \par}

\bigskip

{\begin{russian}\sffamily
На рис. 2.47 представлена реакция некоторой следящей системы на линейно возрастающий командный сигнал
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $v(t)=(0.5+0.025\;t)\;1(t)$,
\end{russian}}

{\begin{russian}\sffamily
на рис. 2.48 – реакция на единичную функцию.
\end{russian}}

{\centering  \includegraphics[width=16.536cm,height=11.615cm]{1-img061.png} \par}

\bigskip

{\centering  \includegraphics[width=17.066cm,height=12.435cm]{1-img062.png} \par}

\bigskip

{\begin{russian}\sffamily
\textrussian{С помощью этих рисунков удобно проиллюстрировать основные показатели качества, используемуе при анализе
систем управления.}
\end{russian}}


\bigskip

\liststyleWWviiiNumxxv
\begin{enumerate}
\item {\begin{russian}\sffamily
Установившаяся ошибка:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $ε_{\normalsubformula{\text{уст}}}=ε(\infty )=\underset{_{t\rightarrow \infty
}}{\text{lim}}(v(t)-y(t))$.\ \ (2.10.1)
\end{russian}}

\liststyleWWviiiNumxxv
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Время регулирования  $t_р$ - минимальное время, в течение которого переходный процесс перестает выходить за пределы
заданной «трубки». Определяется из условия
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $|ε(t)-ε_{\normalsubformula{\text{уст}}}|\le Δ$ \ при  $t\ge t_p$,\ \ (2.10.2)
\end{russian}}

{\begin{russian}\sffamily
\ где  $Δ$ - заранее заданное значение, определяемое требованиями к точности системы (обычно 2-5\% от значения
командного или выходного сигнала в установившемся режиме).
\end{russian}}

\liststyleWWviiiNumxxv
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Максимальное перерегулирование \textrm{} - наибольший выброс управляемого процесса относительно установившегося
значения по отношению к разности  $ε_{\normalsubformula{\text{уст}}}$ и  $ε(0)$.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \ 
$σ=\frac{|ε_{\normalsubformula{\text{мах}}}-ε_{\normalsubformula{\text{уст}}}|}{|ε_{\normalsubformula{\text{уст}}}-ε(0)|}100\cdot
?$\ \ (2.10.3)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \ Обычно \ требуют \ \  $σ\le 30\div 40$.
\end{russian}}

\liststyleWWviiiNumxxv
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Время нарастания:  $t_н$ - время первого входа процесса в трубку.
\end{russian}}
\item {\begin{russian}\sffamily
Время максимального перерегулирования:  $t_m$.
\end{russian}}
\item {\begin{russian}\sffamily
Число перерегулирований \  $N$ в интервале:  $0\le t\le t_p$ -
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
число выбросов, для которых
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $||ε_{\normalsubformula{\text{уст}}}|-ε_m|>Δ$.
\end{russian}}

\liststyleWWviiiNumxxv
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Частота или период  $T_k$ колебательной составляющей переходного процесса.
\end{russian}}
\end{enumerate}
\subsubsection[Ошибки системы регулирования в установившихся \ \ \ \ \ \ \ \ \ \ \ \ \ \ режимах. Статические и
астатические системы]{Ошибки системы регулирования в установившихся \ \ \ \ \ \ \ \ \ \ \ \ \ \ режимах. Статические и
астатические системы}
\hypertarget{RefHeadingToc455659725}{}{\begin{russian}\sffamily
Рассмотрим одну из самых распространённых структурных схем - схему типа следящей системы (рис.2.49), назначение которой
- с минимальной ошибкой воспроизвести на выходе  $y(t)$ командный сигнал  $v(t)$.
\end{russian}}

{\centering  \includegraphics[width=12.171cm,height=3.757cm]{1-img063.png} \par}

\bigskip

{\begin{russian}\sffamily
\ \ В общем случае разомкнутая система может быть представлена последовательным соединением объекта \ (неизменяемой
части системы) с передаточной функцией  $W_{\normalsubformula{\text{об}}}(p)$ и регулятора (корректирующего звена) с
передаточной функцией  $W_{\normalsubformula{\text{рег}}}(p)$. Кроме того, учтем дополнительно возмущающее воздействие
\  $f(t)$. С учетом этого передаточная функция разомкнутой системы 
$W(p)=W_{\normalsubformula{\text{рег}}}(p)\;W_{\normalsubformula{\text{об}}}(p)$, а исходная структурная схема примет
вид, представленный на рис.2.50.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=15.584cm,height=4.763cm]{1-img064.png} \par}

\bigskip

{\begin{russian}\sffamily
В соответствии с этой структурной схемой изображение по Лапласу от ошибки  $E(p)$ зависит как от командного сигнала, так
и от возмущения:
\end{russian}}

{\begin{russian}\sffamily
\ \  $E(p)=W_{\mathit{vε}}(p)\cdot V(p)+W_{\mathit{fε}}(p)\cdot F(p)=E_v(p)+E_f(p)$,\ \ (2.10.4)
\end{russian}}

{\begin{russian}\sffamily
где 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_{\mathit{vε}}(p)=\frac 1{1+W(p)}$, \ \ (2.10.5) \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_{\mathit{fε}}(p)=\frac{-W_{\normalsubformula{\text{об}}}(p)}{1+W(p)}$ $ $.\ \ (2.10.6)
\end{russian}}

{\begin{russian}\sffamily
Широкий класс командных сигналов и возмущающих воздействий может быть представлен степенными функциями времени
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $(α_0+α_1t+α_2t^2+\;...)\cdot \;1(t)$.\ \ (2.10.7)
\end{russian}}

{\begin{russian}\sffamily
\ \ Сначала рассмотрим реакцию системы на возмущающее воздействие вида 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $f(t)=\frac{f_ν}{ν!}\cdot t^ν\cdot 1(t)$,\ \ (2.10.8)
\end{russian}}

{\begin{russian}\sffamily
где  $f_ν=\normalsubformula{\text{const}}$ и имеет размерность возмущения  $f$, деленную на  $\text{сек}^ν$. Такая
функция имеет ненулевые производные \ от нулевого до  $ν$ порядка и нулевые производные порядка выше, чем  $ν$. Причем 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $f^{(ν)}(t)=f_ν$.\ \ (2.10.9)
\end{russian}}

{\begin{russian}\sffamily
Изображение по Лапласу возмущения (2.10.8) имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F(p)=\frac{f_ν}{p^{ν+1}}$.\ \ (2.10.10)
\end{russian}}

{\begin{russian}\sffamily
Пусть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$W_{\normalsubformula{\text{об}}}(p)=\frac{K_{\normalsubformula{\text{об}}}R_{\normalsubformula{\text{об}}}(p)}{Q_{\normalsubformula{\text{об}}}(p)}$,\ \ (2.10.11)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$W_{\normalsubformula{\text{рег}}}(p)=\frac{K_{\normalsubformula{\text{рег}}}R_{\normalsubformula{\text{рег}}}(p)}{p^lQ_{1\normalsubformula{\text{рег}}}(p)}$\ \ (2.10.12)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$R_{\normalsubformula{\text{об}}}(0)=R_{\normalsubformula{\text{рег}}}(0)=Q_{\normalsubformula{\text{об}}}(0)=Q_{1\normalsubformula{\text{рег}}}(0)=1$.\ \ (2.10.13)
\end{russian}}

{\begin{russian}\sffamily
Тогда изображение ошибки можно представить в виде
\end{russian}}


\bigskip

{\begin{russian}\sffamily
 $E_f(р)=\frac{-K_{\normalsubformula{\text{об}}}\cdot R_{\normalsubformula{\text{об}}}(p)\cdot p^l\cdot
Q_{\normalsubformula{\text{рег}}}(p)}{Q_{\normalsubformula{\text{об}}}(p)\cdot p^l\cdot
Q_{1\normalsubformula{\text{рег}}}(p)+K_{\normalsubformula{\text{об}}}\cdot K_{\normalsubformula{\text{рег}}}\cdot
R_{\normalsubformula{\text{об}}}(p)\cdot R_{\normalsubformula{\text{рег}}}(p)}\cdot \frac{f_ν}{p^{ν+1}}$.\ \ (2.10.14)
\end{russian}}

{\begin{russian}\sffamily
\ \ В соответствии с предельной теоремой преобразования Лапласа, если существует  $\underset{t\rightarrow \infty
}{\text{lim}ε(t)}$, то \ 
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}ε_f(t)=\underset{p\rightarrow 0}{\text{lim}}p\cdot
E_f(p)=\underset{p\rightarrow
0}{\text{lim}}\frac{-K_{\normalsubformula{\text{об}}}}{K_{\normalsubformula{\text{об}}}\cdot
K_{\normalsubformula{\text{рег}}}}\cdot f_ν\cdot p^{l-ν}$.\ \ (2.10.15)
\end{russian}}

{\begin{russian}\sffamily
Если  $ν=l$, то
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\underset{t\rightarrow \infty
}{\text{lim}}ε_f(t)=\frac{-f_ν}{K_{\normalsubformula{\text{рег}}}}$.\ \ (2.10.16)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Очевидно, в этом случае размерность коэффициента  $K_{\normalsubformula{\text{рег}}}$ равна отношению размерностей
возмущения и ошибки, умноженному на  $\normalsubformula{\text{сек}}^{-l}$. Такая система называется
\textit{астатической по возмущающему воздействию с порядком астатизма } $l$\textit{. }Если на вход такой системы подать
возмущающий сигнал типа степенной функции времени с  $ν<l$, то установившаяся ошибка будет равна нулю.
\end{russian}}

{\begin{russian}\sffamily
\ Если  $l=0$, то нетрудно убедится в том, что если возмущение является единичной функцией
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $f(t)=f_0\cdot 1(t)$,\ \ (2.10.17)
\end{russian}}

{\begin{russian}\sffamily
\ то
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ε_f(\infty )=\frac{-K_{\normalsubformula{\text{об}}}}{1+K_{\normalsubformula{\text{об}}}\cdot
K_{\normalsubformula{\text{рег}}}}\cdot f_0$.\ \ (2.10.18)
\end{russian}}

{\begin{russian}\sffamily
Такая система называется \textit{статической}, поскольку при постоянном возмущении ошибка в статике не равна нулю,
пропорциональна величине возмущения  $f_0$ и тем меньше, чем больше коэффициент усиления разомкнутого контура 
$K=K_{\normalsubformula{\text{об}}}K_{\normalsubformula{\text{рег}}}$.
\end{russian}}

{\begin{russian}\sffamily
Аналогичные рассуждения можно провести для случая, когда  $f=0$, а командный сигнал является степенной функцией времени:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $v(t)=\frac{v_ν}{ν!}\cdot t^ν\cdot 1(t)$.\ \ (2.10.19)
\end{russian}}

{\begin{russian}\sffamily
В этом случае положим 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Q(p)=Q_{\normalsubformula{\text{об}}}(p)\cdot Q_{\normalsubformula{\text{рег}}}(p)=p^l\cdot Q_1(p)$ \ и \ \ 
$Q_1(0)=1$.\ \ (2.10.20)
\end{russian}}

{\begin{russian}\sffamily
Тогда
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $\underset{t\rightarrow \infty }{\text{lim}}ε_v(t)=\underset{p\rightarrow 0}{\text{lim}}p\frac{p^l\cdot
Q_1(p)}{p^l\cdot Q_1(p)+K\cdot R(p)}\cdot \frac{v_ν}{p^{ν+1}}$.\ \ (2.10.21)
\end{russian}}

{\begin{russian}\sffamily
Такая система при  $l\neq 0$ \textit{называется астатической по командному сигналу с порядком астатизма, равным }
$l$\textit{.}В этом случае коэффициент  $K$ называется \textit{добротностью} системы. Его размерность 
$\normalsubformula{\text{сек}}^{-l}$.
\end{russian}}

{\begin{russian}\sffamily
Если  $ν=l$, то
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ε_v(\infty )=\frac{v_ν} k=\normalsubformula{\text{const}}$.\ \ (2.10.22)
\end{russian}}

{\begin{russian}\sffamily
Если  $ν<l$, то  $ε_v(\infty )=0$. 
\end{russian}}

{\begin{russian}\sffamily
При  $l=0$ система называется \textit{статической}. Для нее, при 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $v(t)=v_0\cdot 1(t)$,\ \ (2.10.23)
\end{russian}}

{\begin{russian}\sffamily
имеем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ε_v(\infty )=\frac{v_0}{1+K}$.\ \ (2.10.24)
\end{russian}}

{\begin{russian}\sffamily
\textit{В рассмотренном случае регулятор содержал } $l$\textit{ интеграторов, то есть был астатическим, а объект
интеграторов не содержал – был статическим. Если рассмотреть другой вариант, где, в отличие от (2.10.11), (2.10.12),}
\end{russian}}

\begin{equation*}
W_{\normalsubformula{\text{об}}}(p)=\frac{K_{\normalsubformula{\text{об}}}R_{\normalsubformula{\text{об}}}(p)}{p^lQ_{1\normalsubformula{\text{об}}}(p)};\;\;\;W_{\normalsubformula{\text{рег}}}(p)=\frac{K_{\normalsubformula{\text{рег}}}R_{\normalsubformula{\text{рег}}}(p)}{Q_{\normalsubformula{\text{рег}}}(p)}
\end{equation*}
{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$R_{\normalsubformula{\text{об}}}(0)=R_{\normalsubformula{\text{рег}}}(0)=Q_{1\normalsubformula{\text{об}}}(0)=Q_{\normalsubformula{\text{рег}}}(0)=1$,
\end{russian}}

{\begin{russian}\sffamily
то выводы по отработке командного сигнала не изменятся, а при возмущении (2.10.8)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\underset{t\rightarrow \infty }{\text{lim}}ε_f(t)=\underset{p\rightarrow
0}{\text{lim}}\frac{-f_ν}{K_{\normalsubformula{\text{рег}}}}\cdot \frac 1{p^ν}$.
\end{russian}}

{\begin{russian}\sffamily
При  $ν=0$ получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ε_f(\infty )=\frac{-K_{\normalsubformula{\text{об}}}}{1+K_{\normalsubformula{\text{об}}}\cdot
K_{\normalsubformula{\text{рег}}}}\cdot f_0$,
\end{russian}}

{\begin{russian}\sffamily
а при  $ν>0$ ошибка с течением времени неограниченно растёт.\ \ 
\end{russian}}

{\begin{russian}\sffamily
Таким образом, порядок астатизма системы по отношению к какому-либо внешнему воздействию равен числу интегрирующих
звеньев, включенных в обратную связь между координатой ошибки и этим воздействием. 
\end{russian}}

{\begin{russian}\sffamily
\textit{Системой с астатизмом } $l$\textit{-го порядка по отношению к командному сигналу } $v$\textit{ называется
система автоматического управления, вынужденная ошибка которой при отработке сигнала, выражаемого в виде полинома
степени } $l$\textit{ по } $t$
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_0+A_1t+\;...\;+\frac{A_l}{l\;!}t^l$,
\end{russian}}

{\begin{russian}\sffamily
постоянна и пропорциональна величине  $A_l$, то есть старшей производной воздействия. При отработке сигнала, выражаемого
полиномом меньшей степени, установившаяся ошибка в такой системе равна нулю.
\end{russian}}

{\begin{russian}\sffamily
Изложенные выше рассуждения приводят к выводу, что с точки зрения стремления к уменьшению ошибки желательно иметь более
высокий порядок астатизма и более высокое значение  $K_{\normalsubformula{\text{рег}}}$. И то и другое, как правило,
вступает в противоречие с требованиями устойчивости. Уже синтез устойчивой системы с астатизмом выше третьего порядка
ставит перед разработчиком серьёзные проблемы.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\textrm{\ \ \ }ПРИМЕР 2.10.1. Пусть дана система со структурной схемой, представленной на рис.2.51. Система обладает
астатизмом 1-го порядка, как по командному, так и по возмущающему воздействиям, так как система содержит один
\ интегратор с передаточной функцией  $p^{-1}$ в регуляторе (корректирующем звене). Для данной системы:
\end{russian}}

{\begin{russian}\sffamily
1) \ если  $f=\normalsubformula{\text{const}}$ и  $v=\normalsubformula{\text{const}}$, то 
$ε_{\normalsubformula{\text{уст}}}=0$;
\end{russian}}

{\centering  \includegraphics[width=13.044cm,height=5.847cm]{1-img065.png} \par}

\bigskip

\liststyleWWviiiNumlxxii
\begin{enumerate}
\item {\begin{russian}\sffamily
если  $v=v_1\cdot t$,  $v_1=\normalsubformula{\text{const}}$, а  $f$\textrm{\textit{ }}– константа или нулевая величина,
то \textit{кинетическая ошибка} 
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $ε_{\normalsubformula{\text{уст}}}=ε\left(\infty \right)=\frac{v_1} K$,
\end{russian}}

{\begin{russian}\sffamily
где добротность
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $K=K_p\cdot K_{\normalsubformula{\text{об}}}$ ;
\end{russian}}

\liststyleWWviiiNumlxxii
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
если  $f=f_1\cdot t$,  $f_1=\normalsubformula{\text{const}}$, а  $v$ - \ константа или нулевая величина, \ то
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $ε_{\normalsubformula{\text{уст}}}=-\frac{f_1\cdot K_f}{K_p}$;
\end{russian}}

\liststyleWWviiiNumlxxii
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
если  $v=v_2\cdot t^2$, \  $v_2=\normalsubformula{\text{const}}$ или  $f=f_2\cdot t^2$, 
$f_2=\normalsubformula{\text{const}}$, то ошибка будет непрерывно нарастать.
\end{russian}}
\end{enumerate}
\subsubsection{Точность систем при отработке гармонических сигналов}
\hypertarget{RefHeadingToc455659726}{}{\begin{russian}\sffamily
Каждый командный сигнал может быть разложен либо в дискретный (ряд Фурье для периодической функции времени), либо в
непрерывный спектр гармоник (интегральное преобразование Фурье). Для того чтобы воспроизвести командный сигнал с малыми
искажениями, необходимо точно воспроизвести хотя бы существенные гармоники этого спектра. В интервале этих существенных
частот амплитудно-частотная характеристика замкнутой системы (АЧХ) должна быть близка к единице, а фазочастотная (ФЧХ)
- \ к нулю (рис. 2.52). При этом, естественно, полоса пропускания системы должна быть заведомо шире спектра командного
сигнала.
\end{russian}}

{\begin{russian}\sffamily
Для оценки величины  $ω_в$ рассмотрим спектральную плотность сигнала \ (спектр мощности):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $S_V(ω)=V(\mathit{jω})\cdot V(-\mathit{jω})=|V(\mathit{iω})|^2$.\ \ (2.10.25)
\end{russian}}

{\centering  \includegraphics[width=14.275cm,height=8.317cm]{1-img066.png} \par}
{\begin{russian}\sffamily
Полная энергия сигнала определяется выражением
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Е_V=\overset{\infty }{\underset 0{\int }}S_V(ω)\mathit{dω}.$\ \  (2.10.26)
\end{russian}}

{\begin{russian}\sffamily
Величину  $ω_В$ целесообразно выбрать так, чтобы площадь под кривой  $S(ω)$ на интервале частот  $[0,\;ω_В]$ составляла
не менее 90\% от площади под этой кривой во всём диапазоне частот от нуля до бесконечности (рис. 2.53).
\end{russian}}

{\centering  \includegraphics[width=11.275cm,height=6.817cm]{1-img067.png} \par}
{\begin{russian}\sffamily
Применительно к структурной схеме, приведённой на рис. 2.41, \ для которой частотная функция от командного сигнала к
ошибке имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_{\mathit{vε}}(\mathit{jω})=\frac 1{1+W(\mathit{jω})}$ ,\ \ (2.10.27)
\end{russian}}

{\begin{russian}\sffamily
этим требованиям соответствует неравенство
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $|\frac 1{1+W(\mathit{jω})}|<Δ\text{    },\text{      0}\le ω<ω_В$,\ \ (2.10.28)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
где  $Δ$ - некоторая заданная величина. В рассматриваемом диапазоне частот обычно  $|W(\mathit{jω})|\text{>>}1$. Поэтому
неравенство (2.10.28) будет всегда выполняться, если
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\frac 1{-1+|W(\mathit{jω})|}<Δ$.\ \ (2.10.29)
\end{russian}}

{\begin{russian}\sffamily
Отсюда следует
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $|W|>\frac{1+Δ} Δ\approx \frac 1 Δ$.\ \ (2.10.30)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Таким образом, для точного воспроизведения командного сигнала требуется, чтобы в спектре частот от  $0$ до  $ω_В$
выполнялось условие
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $|W|>\frac 1 Δ$.\ \ (2.10.31)
\end{russian}}

{\begin{russian}\sffamily
Обычно принимают:  $Δ=0.05\div 0.1$. Применительно к ЛАЧХ неравенство (2.10.31) превращается в требование того, чтобы в
диапазоне  $0\le ω<ω_В$ выполнялось условие
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $|W(\mathit{jω})|\normalsubformula{\text{дБ}}>(26\div 20)\normalsubformula{\text{дБ}}$.\ \ (2.10.32)
\end{russian}}

\subsubsection[Связь между логарифмическими амплитудно-частотными характеристиками \ и качеством переходных процессов в
САУ]{Связь между логарифмическими амплитудно-частотными характеристиками \ и качеством переходных процессов в САУ}
\hypertarget{RefHeadingToc455659727}{}{\begin{russian}\sffamily
Между частотными и временными характеристиками систем существует однозначная взаимозависимость. Особенно много внимания
уделялось этому вопросу в те времена, когда вычислительная техника была недоступна рядовому инженеру и он должен был
судить о свойствах разрабатываемых систем, пользуясь только косвенными оценками. Часть таких методик косвенных оценок
качества по частотным характеристикам представляет интерес и в настоящее время. На эту тему имеется обширная учебная
литература. В настоящем пособии затрагивается один фрагмент из этих методик, который позволяет достаточно просто
связать качество временных процессов в замкнутых системах с видом амплитудно-частотных логарифмических характеристик
соответствующих разомкнутых систем. Здесь следует отметить, что дальнейшее содержание параграфа относится \ лишь к так
называемым неминимально-фазовым системам, то есть к таким, передаточные функции которых не содержат ни нулей, ни
полюсов с положительной вещественной частью.
\end{russian}}

{\begin{russian}\sffamily
Весь диапазон частот при рассмотрении ЛАЧХ (рис. 2.54) разбивают на три поддиапазона:
\end{russian}}


\bigskip

\liststyleWWviiiNumlxx
\begin{enumerate}
\item {\begin{russian}\sffamily
Область низких частот  $\left[0\le ω<ω_н\right]$. Этот диапазон определяет в значительной мере точность воспроизведения
"медленно" меняющихся воздействий. В этом диапазоне в соответствии с результатами, полученными в \ предыдущем разделе,
\ должно быть выполнено условие:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $L(ω)\ge 20\text{lg}\left(\frac 1 Δ\right)=?\begin{matrix}\left\{26\text{дБ  },\text{  если
}Δ=0.05\;;?\right.\left\{\text{34дБ  ,  если }Δ=0.02\;\;.?\right.\mathit{no}\end{matrix}\{?$\ \ (2.10.33)
\end{russian}}

{\begin{russian}\sffamily
Кроме того, вид ЛАЧХ в этой области указывает на порядок астатизма и \ статическую или кинетическую точность системы.
Наклон низкочастотной асимптоты равен  $-20\cdot ν\;\;$ дБ/дек., где  $ν$- порядок астатизма.
\end{russian}}

{\begin{russian}\sffamily
Ширина интервала  $\left[0,ω_н\right]$ позволяет найти ширину спектра частот управляющих воздействий, воспроизводимых
системой без каких-либо значительных искажений, и позволяет судить о том, какие воздействия для рассматриваемой системы
можно считать медленно изменяющимися.
\end{russian}}


\bigskip

\liststyleWWviiiNumlxx
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Диапазон средних частот  $\left[ω_н,ω_к\right]$– определяет запасы устойчивости и качество системы при воздействии типа
ступенчатой функции. В этом интервале находится частота среза  $ω_с$, позволяющая оценить время регулирования:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $t_р\approx (3\div 4)\frac π{ω_с}$ .\ \ (2.10.34)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \ Частота среза  $ω_с$ примерно равна собственной частоте замкнутой системы (частоте, где у замкнутой системы
может быть некоторый резонанс).
\end{russian}}

{\centering  \includegraphics[width=11.94cm,height=8.156cm]{1-img068.png} \par}

\bigskip

{\begin{russian}\sffamily
Для удовлетворительного качества переходных процессов необходимо, чтобы ЛАЧХ на этом интервале имела наклон -20дБ/дек.,
а длина этого интервала примерно равнялась 1дек\textit{.} На этом интервале определяются запасы устойчивости системы.
Рекомендуемые значения этих запасов составляют примерно 10дБ по модулю и 35 - 40\textsuperscript{0} по фазе.
\end{russian}}


\bigskip

\liststyleWWviiiNumlxx
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Интервал высоких частот  $ω>ω_k$. Этот интервал примерно соответствует 
$|W(\mathit{jω})|_{\normalsubformula{\text{дБ}}}\le -16$ дБ. На этот интервал приходятся сопрягающие частоты,
пренебрежение которыми не оказывает существенного влияния на качество переходных процессов.
\end{russian}}
\end{enumerate}

\bigskip

{\begin{russian}\sffamily
ПРИМЕР 2.10.2 
\end{russian}}

{\begin{russian}\sffamily
Дана система с передаточной функцией
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W(p)=\frac k{p^3}\left(\frac{1+T_1p}{1+T_2p}\right)^2$. 
\end{russian}}

{\begin{russian}\sffamily
Это система с астатизмом третьего порядка. На рис.2.55 представлена её логарифмическая амплитудно-частотная
характеристика. Цифрами 1, 2, 3 обозначены соответственно области низких, средних и \ высоких частот. 
\end{russian}}

{\centering  \includegraphics[width=15.319cm,height=9.816cm]{1-img069.png} \par}

\bigskip


\bigskip

\subsubsection[Соотношение масштабов во временной и частотной \ \ \ \ \ \ \ \ \ \ \ \ \ областях]{Соотношение масштабов
во временной и частотной \ \ \ \ \ \ \ \ \ \ \ \ \ областях}
\hypertarget{RefHeadingToc455659728}{}{\begin{russian}\sffamily
1. \textit{Если \ функция } $f(t)$\textit{ преобразуема по Фурье, \ } $F(\mathit{jω})=Ф\left\{f(t)\right\}$\textit{ - ее
преобразование по Фурье и \ } $a$\textit{ - положительное вещественное число, то справедливо равенство}
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Ф\left\{f\left(\frac t
a\right)\right\}=\normalsubformula{\text{aF}}(\normalsubformula{\text{ja}}ω)$.\ \ (2.10.35)
\end{russian}}

{\begin{russian}\sffamily
Докажем это. Прямое преобразование Фурье выражается формулой
\end{russian}}

{\begin{russian}\sffamily
\ \  $F(j\bar ω)=\overset{\infty }{\underset 0{\int }}f(\bar t)\cdot e^{-j\bar ω\bar t}d\bar t$.\ \ (2.10.36)
\end{russian}}

{\begin{russian}\sffamily
Введем новые переменные  $t=\bar t\cdot a,\overset{}{}ω=\frac{\bar ω} a$ . Тогда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F(\mathit{jωa})=\frac 1 a\overset{\infty }{\underset 0{\int }}f\left(\frac t
a\right)e^{-\normalsubformula{\text{ja}}ω\left(\frac t a\right)}\normalsubformula{\text{dt}}$,
\end{russian}}

{\begin{russian}\sffamily
откуда
\end{russian}}

\begin{equation*}
\normalsubformula{\text{aF}}(\mathit{jωa})=\overset{\infty }{\underset 0{\int }}f\left(\frac t
a\right)e^{-\normalsubformula{\text{ja}}ω\left(\frac t a\right)}\normalsubformula{\text{dt}}
\end{equation*}
{\begin{russian}\sffamily
и равенство (2.10.35) доказано.\ \ \ \ 
\end{russian}}

{\begin{russian}\sffamily
Таким образом, при растяжении (сжатии) в "\textit{а}" раз графика функции  $f(t)$ вдоль оси времени график модуля
спектральной характеристики  $|F(\mathit{jω})|$, во-первых, сжимается (растягивается) вдоль оси частот в "\textit{а}"
раз и, во-вторых, \ увеличиваются (уменьшаются) в "\textit{а}" раз его значения. Известно, что \textit{чем короче
импульс, тем шире его спектр}.
\end{russian}}

{\begin{russian}\sffamily
2. Изображение по Фурье от переходной функции  $h(t)$ \ системы \ с передаточной функцией  $W(p)$ имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $H(\mathit{jω})=\frac{W(\mathit{jω})}{\mathit{jω}}$,\ \ (2.10.37)
\end{russian}}

{\begin{russian}\sffamily
поэтому сама функция  $h(t)$ может быть определена с помощью обратного преобразования Фурье: 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $h(\bar t)=\frac 1{2π}\cdot \overset{+\infty }{\underset{-\infty }{\int }}\frac{W(j\bar ω)}{j\bar ω}e^{j\bar
ω\bar t}d\bar ω$.\ \ (2.10.38)
\end{russian}}

{\begin{russian}\sffamily
По аналогии с пунктом 1 введем новые переменные
\end{russian}}

\begin{equation*}
t=\bar t\cdot a\text{   ,   }ω=\frac{\bar ω} a
\end{equation*}
{\begin{russian}\sffamily
и, подставив их в (2.10.38), получим
\end{russian}}

{\begin{russian}\sffamily
 $h\left(\frac t a\right)=\frac 1{2π}\cdot \overset{+\infty }{\underset{-\infty }{\int
}}\frac{W(\normalsubformula{\text{ja}}ω)}{\normalsubformula{\text{ja}}ω}e^{\normalsubformula{\text{ja}}ω\frac t
a}\normalsubformula{\text{da}}ω=\frac 1{2π}\cdot \overset{+\infty }{\underset{-\infty }{\int
}}\frac{W(\normalsubformula{\text{ja}}ω)}{\mathit{jω}}e^{\mathit{jωt}}\mathit{dω}$.\ \ (2.10.39)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, если частотная характеристика системы получается путем сжатия (или растяжения) вдоль оси частот частотной
характеристики некоторой исходной системы (рис. 2.56), то ее переходная функция соответственно растягивается (или
сжимается) вдоль оси времени.
\end{russian}}


\bigskip


\bigskip

 \includegraphics[width=15.528cm,height=23.308cm]{1-img070.png} 


\bigskip


\bigskip

\subsection[Интегральные критерии качества с позиций общности задач оптимального и модального синтеза]{Интегральные
критерии качества с позиций общности задач оптимального и модального синтеза}
\hypertarget{RefHeadingToc455659729}{}{\begin{russian}\sffamily
При рассмотрении качества систем управления большое место занимает группа интегральных критериев качества. Они
достаточно полно изложены в обширной литературе по теории автоматического регулирования и управления. Это – интегралы
от координат вектора состояния, вектора управления, ошибки регулирования. Интегральные показатели, или критерии
качества, непосредственно выходят на синтез оптимального управления. При этом под оптимальностью понимается минимум
какого-либо интегрального критерия. Наиболее простой из них – это интеграл от квадрата ошибки отработки командного
сигнала на бесконечном интервале времени
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $J_0=\overset{\infty }{\underset{t=0}{\int }}ε^2(t)\normalsubformula{\text{dt}}$.\ \ (2.11.1)
\end{russian}}

{\begin{russian}\sffamily
Однако, как показала практика, стремление к минимизации такого критерия приводит к чрезмерной колебательности переходных
процессов. В связи с этим стали усложнять функционал. Так, например, кроме квадрата ошибки с целью уменьшения выбросов
в переходных процессах в функционал стали вводить квадрат от её производной
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $J_1=\overset{\infty }{\underset{t=0}{\int }}(c_0ε^2(t)+c_1\dot
ε^2(t))\normalsubformula{\text{dt}}$.\ \ (2.11.2)
\end{russian}}

{\begin{russian}\sffamily
Кроме этого оказалось полезным учитывать величину управляющего воздействия: 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $J_2=\overset{\infty }{\underset{t=0}{\int }}(c_0ε^2(t)+c_1\dot
ε^2(t)+c_Uu^2(t))\normalsubformula{\text{dt}}$.\ \ (2.11.3)
\end{russian}}

{\begin{russian}\sffamily
Различные исполнения системы в некоторых случаях стало удобным сравнивать по величине соответствующих интегральных
показателей. Такой анализ неизбежно стал перерастать в синтез оптимального управления \ с различными интегральными
критериями. В одной из наиболее общих форм интегральные критерии, используемые в оптимальном синтезе, записывают в виде
\end{russian}}

{\begin{russian}\sffamily
\ \  $J=\overset{\infty }{\underset 0{\int }}(\vec x^T(t)Q_X\vec x(t)+2\vec x^T(t)Q_{\normalsubformula{\text{XU}}}\vec
u(t)+\vec u^T(t)Q_U\vec u(t))\normalsubformula{\text{dt}}$.\ \ (2.11.4)
\end{russian}}

{\begin{russian}\sffamily
Возникло целое направление в теории оптимальных систем – аналитическое конструирование регуляторов (АКР). Был разработан
специальный математический аппарат, обеспечивающий расчёт управления, которое минимизирует функционал вида (2.11.4).
\end{russian}}

{\begin{russian}\sffamily
Однако возникла очередная проблема - проблема выбора значений элементов матриц  $Q_X$, 
$Q_{\normalsubformula{\text{XU}}}$,  $Q_U$ в соответствующих квадратичных формах. Эту задачу в общем виде формализовать
не удалось до сих пор. В то же время при проектировании систем выявилась важная закономерность: эталонные процессы, к
которым притягивается движение в \ системе, должны соответствовать структуре управляемого \ объекта. Это означает, что
уравнения эталонной системы, отображённой на рис. 2.46, должны иметь такой же вид, как и уравнения объекта. Поэтому в
качестве эталонной системы можно выбрать систему того же порядка, что и объект, но с собственными числами, а значит, и
с характеристическим полиномом, отвечающими требованиям, предъявляемым к замкнутой системе.
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим способ формирования ошибки  $ε_E$, характеризующей отклонение некоторой конкретной системы от эталонной.
Пусть эталонная система  $n$ однородных дифференциальных уравнений первого порядка приведена к одному дифференциальному
уравнению  $n$-го \ \ \ \ \ \ \ \ \ \ порядка:
\end{russian}}

{\begin{russian}\sffamily
\ \  $x_Э^{(n)}+γ_1x_Э^{(n-1)}+...+γ_{n-1}x_Э^{(1)}+γ_nx_Э=0$.\ \ (2.11.5)
\end{russian}}

{\begin{russian}\sffamily
В левую часть равенства (2.11.5) вместо координаты  $x_Э$ подставим одну из координат вектора состояния объекта. Скорее
всего при этом равенство нулю нарушится. Получаем уравнение невязки:
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$x_{\normalsubformula{\text{Об}}}^{(n)}+γ_1x_{\normalsubformula{\text{Об}}}^{(n-1)}+...+γ_{n-1}x_{\normalsubformula{\text{Об}}}^{(1)}+γ_nx_{\normalsubformula{\text{Об}}}=ε_E$.\ \ (2.11.6)
\end{russian}}

{\begin{russian}\sffamily
Переменная  $ε_E$ характеризует отклонение процессов объекта от эталонных. Она равна нулю на интервале времени 
$t=[0,\infty )$ только лишь в том случае, когда процессы в объекте или в проектируемой системе полностью тождественны
процессам в эталонной системе.
\end{russian}}

{\begin{russian}\sffamily
\ \ Учтём уравнение объекта
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}(t)=A\vec x(t)+B\vec u(t)$\ \ (2.11.7)
\end{russian}}

{\begin{russian}\sffamily
и приведём уравнение (2.11.6) к такому виду, чтобы в него входили только координаты векторов состояния  $\vec x$ и
управления  $\vec u$:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}q_{\mathit{x1}}x_1(t)+q_{\mathit{x2}}x_2(t)+...+q_{\normalsubformula{\text{xn}}}x_n(t)+\hfill\null
\\+q_{\mathit{u1}}u_1(t)+q_{\mathit{u2}}u_2(t)+...+q_{\normalsubformula{\text{un}}_u}u_{n_u}(t)=ε_E(t).\hfill\null
\end{matrix}\hfill $\ \ (2.11.8)
\end{russian}}

{\begin{russian}\sffamily
Это уравнение, используя очевидные обозначения, можно записать иначе:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec q_x^T\vec x(t)+\vec q_x^T\vec u(t)=ε(t)$.\ \ (2.11.9)
\end{russian}}

{\begin{russian}\sffamily
В соответствии с введённой текущей ошибкой  $ε_E(t)$ может быть использован интегральный критерий качества (функционал)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $J=\overset{\infty }{\underset 0{\int }}ε_E^2(t)\normalsubformula{\text{dt}}$.\ \ (2.11.10)
\end{russian}}

{\begin{russian}\sffamily
Квадрат ошибки можно записать с помощью квадратичных форм:
\end{russian}}

{\begin{russian}\sffamily
 $ε_E^2=\left[\begin{matrix}\vec x(t)\\\vec u(t)\end{matrix}\right]^T\left[\begin{matrix}\vec q_x\\\vec
q_u\end{matrix}\right]\left[\begin{matrix}\vec q_x\\\vec q_u\end{matrix}\right]^T\left[\begin{matrix}\vec x(t)\\\vec
u(t)\end{matrix}\right]=\left[\begin{matrix}\vec x(t)\\\vec u(t)\end{matrix}\right]^T\left[\begin{matrix}\vec q_x\vec
q_x^T&\vec q_x\vec q_u^T\\\vec q_u\vec q_x^T&\vec q_u\vec q_u^T\end{matrix}\right]\left[\begin{matrix}\vec x(t)\\\vec
u(t)\end{matrix}\right]$,\ \ (2.11.11)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec q_x=\left[\begin{matrix}q_{\mathit{x1}}\\q_{\mathit{x2}}\\\cdots
\\q_{\normalsubformula{\text{xn}}}\end{matrix}\right]\;;\ \ \vec
q_u=\left[\begin{matrix}q_{\mathit{u1}}\\q_{\mathit{u2}}\\\cdots \\q_{u\;n_u}\end{matrix}\right]\;\;.$\ \ (2.11.12)
\end{russian}}

{\begin{russian}\sffamily
Обозначив
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Q_X=\vec q_x^T\vec q_x\;;\;\;Q_U=\vec q_u^T\vec q_u\;;\;\;Q_{\normalsubformula{\text{XU}}}=\vec q_u^T\vec
q_u$,\ \ (2.11.13)
\end{russian}}

{\begin{russian}\sffamily
в итоге получаем критерий (2.11.4).
\end{russian}}

{\begin{russian}\sffamily
\ \ В связи с тем, что порядки уравнений объекта и \ эталонной системы совпадают, в результате оптимального синтеза
удастся найти оптимальное управление, при котором минимум функционала окажется равным нулю. Так как при этом для
процессов в системе с оптимальным управлением окажется выполнимым равенство (2.11.6) при  $ε_E=0$, то полученная
система будет иметь характеристический полином
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_C(λ)=ϕ_Э(λ)=λ^n+γ_1λ^{n-1}+...+γ_{n-1}λ+γ_n$\ \ (2.11.14)
\end{russian}}

{\begin{russian}\sffamily
и, следовательно, собственные числа синтезированной системы совпадут с собственными числами эталона.
\end{russian}}

{\begin{russian}\sffamily
\ \ Таким образом, результаты АКР при таком подходе обеспечивают не только минимум критерия (2.11.4), равный нулю, но и
позволяют получить систему с желаемыми собственными числами. Поскольку связь переходных процессов с собственными
числами (модами) системы более очевидна и непосредственна, модальный синтез часто оказывается предпочтительнее метода
АКР, тем более, что алгоритм модального синтеза существенно проще алгоритмов АКР.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \ ПРИМЕР 2.11.1. Для иллюстрации изложенного рассмотрим объект, представленный на рис. 2.9. Уравнения объекта имеют
следующий вид:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\dot x_1(t)=x_2(t);\hfill\null \\\dot x_2(t)=-2x_2(t)+x_3(t);\hfill\null \\\dot
x_3(t)=-x_3(t)+u(t)\;.\hfill\null \end{matrix}\hfill $\ \ (2.11.15)
\end{russian}}

{\begin{russian}\sffamily
Пусть эталонная система (эталонный процесс) определяется уравнением
\end{russian}}

{\begin{russian}\sffamily
\ \  $x_Э^{(3)}(t)+γ_1x_Э^{(2)}(t)+γ_2x_Э^{(1)}+γ_3x_Э(t)=γ_3v(t)$,\ \ (2.11.16)
\end{russian}}

{\begin{russian}\sffamily
соответствующим желаемым собственным числам. Из этого уравнения видно, что при постоянном командном сигнале 
$v=v_0=\normalsubformula{\text{const}}$ в статике
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\underset{t\rightarrow \infty }{\text{lim}}(x_Э(t))=x_{Э\;\normalsubformula{\text{уст}}}=v_0$.\ \ (2.11.17)
\end{russian}}

{\begin{russian}\sffamily
Подставив в левую часть равенства (2.11.16) координату объекта  $x_1(t)$, получим уравнение невязки:
\end{russian}}

{\begin{russian}\sffamily
\ \  $ε_E(t)=x_1^{(3)}(t)+γ_1x_1^{(2)}(t)+γ_2x_1^{(1)}(t)+γ_3x_1(t)$.\ \ (2.11.18)
\end{russian}}

{\begin{russian}\sffamily
Заменим производные от координаты  $x_1$ на координаты вектора состояния объекта с учётом уравнений (2.11.15):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}x_1^{(1)}=x_2;\hfill\null \\x_1^{(2)}=x_2^{(1)}=-2x_1+x_3;\hfill\null
\\x_1^{(3)}=-2x_2^{(1)}+x_3^{(1)}=4x_2-3x_3+u\;.\hfill\null \end{matrix}\hfill $\ \ (2.11.19)
\end{russian}}

{\begin{russian}\sffamily
В результате уравнение невязки принимает вид
\end{russian}}

{\begin{russian}\sffamily
 $ε_E(t)=γ_3x_1(t)+(4-2γ_1+γ_2)x_2(t)+(γ_1-3)x_3(t)+u(t)$,\ \ (2.11.20)
\end{russian}}

{\begin{russian}\sffamily
откуда получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec q_x=\left[\begin{matrix}γ_3\\4-2γ_1+γ_2\\γ_1-3\end{matrix}\right]\;;\ \ q_u=1$.\ \ (2.11.21)
\end{russian}}

{\begin{russian}\sffamily
Теперь в соответствии с (2.11.13) могут быть вычислены матрицы  $Q_X$,  $Q_U$,  $Q_{\normalsubformula{\text{XU}}}$ и
получен функционал (2.11.4) для использования при решении задачи АКР.
\end{russian}}

{\begin{russian}\sffamily
\ \ В то же время, приравняв нулю  $ε_E(t)$ в (2.11.20), можно непосредственно получить выражение для формирования
управления  $u(t)$ через координаты вектора состояния объекта. Более того, если потребовать выполнения равенства
\end{russian}}

{\begin{russian}\sffamily
\ \  $x_1^{(3)}(t)+γ_1x_1^{(2)}(t)+γ_2x_1^{(1)}(t)+γ_3x_1(t)=γ_3v(t)$,\ \ (2.11.22)
\end{russian}}

{\begin{russian}\sffamily
то с учётом (2.11.20) получим систему с обратной связью по вектору состояния и управлением
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $u(t)=L\vec x(t)+k^vv(t)$,\ \ (2.11.23)
\end{russian}}

{\begin{russian}\sffamily
где фигурируют матрица обратной связи
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L=\left[\begin{matrix}-γ_3&-4+2γ_1-γ_2&3-γ_1\end{matrix}\right]$\ \ (2.11.24)
\end{russian}}

{\begin{russian}\sffamily
и передаточный коэффициент по командному сигналу
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $k^v=γ_3$.\ \ (2.11.25)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, без решения задачи АКР получено оптимальное управление, обеспечивающее процессы в замкнутой системе,
имеющей собственные числа, соответствующие характеристическому полиному эталонной системы (2.11.14). Кроме того, в
полученной системе обеспечена единичная статика по командному сигналу  $v$ (2.11.17).
\end{russian}}

{\begin{russian}\sffamily
В этом примере проиллюстрирована идентичность задачи АКР с надлежащим образом выбранным критерием оптимальности задаче
модального синтеза. В следующих разделах будет подробно изложена методика модального синтеза.
\end{russian}}


\bigskip

\clearpage\section{Синтез линейных непрерывных систем}
\hypertarget{RefHeadingToc455659730}{}\subsection{Выбор корректирующих звеньев. Метод желаемых ЛЧХ}
\hypertarget{RefHeadingToc455659731}{}
\bigskip

{\begin{russian}\sffamily
Как уже отмечалось, существует связь между частотными характеристиками системы, как в замкнутом, так и в разомкнутом
состоянии, и протекающими в ней переходными процессами. На протяжении многих лет инженерами накоплен большой опыт по
синтезу систем автоматического управления на базе формирования эталонных, желаемых частотных характеристик
соответствующих разомкнутых систем. В литературе имеются обширные таблицы таких эталонных логарифмических
амплитудно-частотных характеристик для большого числа типовых передаточных функций объектов управления. В настоящем
пособии излагается лишь основная идея такого подхода.
\end{russian}}

{\begin{russian}\sffamily
Рассматривается одноконтурная система (рис. 3.1). Разомкнутый контур состоит из последовательно включённых неизменяемой
части системы (в неё входят объект, привод, датчики, преобразующие и согласующие устройства) с передаточной функцией 
$W_0(p)$ и корректирующего звена с передаточной функцией  $W_k(p)$.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=10.028cm,height=3.757cm]{1-img071.png} \par}

\bigskip

{\begin{russian}\sffamily
Предполагается, что заданы требования к основным показателям качества, обсуждавшимся в п.2.10.1. В соответствии с этим
по упомянутым таблицам или на основе подхода, изложенного в п.2.10.4, строится асимптотическая логарифмическая
амплитудно-частотная характеристика (ЛАЧХ)  $L_{\normalsubformula{\text{жел}}}(ω)$ разомкнутой системы, удовлетворяющая
указанным требованиям. На этом же рисунке строится асимптотическая ЛАЧХ неизменяемой части системы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_0(ω)=|W_0(\mathit{jω})|_{\normalsubformula{\text{дБ}}}$.\ \ (3.1.1)
\end{russian}}

{\begin{russian}\sffamily
Потребуем, чтобы комплексный передаточный коэффициент разомкнутой системы был равен функции, определяемой желаемой ЛАЧХ,
то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_k(\mathit{jω})\cdot W_0(\mathit{jω})=W_{\normalsubformula{\text{жел}}}(\mathit{jω})$\ \ (3.1.2)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
или
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_k(ω)+L_0(ω)=L_{\normalsubformula{\text{жел}}}(ω)$.\ \ (3.1.3)
\end{russian}}

{\begin{russian}\sffamily
В соответствии с этим простой операцией графического вычитания легко получить асимптотическую ЛАЧХ корректирующего звена
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_k(ω)=L_{\normalsubformula{\text{жел}}}(ω)-L_0(ω)$.\ \ (3.1.4)
\end{russian}}

{\begin{russian}\sffamily
По ней уже нетрудно восстановить передаточную функцию  $W_k(p)$.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \ ПРИМЕР 3.1.1. Передаточная функция неизменяемой части системы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \  $W_0(p)=\frac 1{p(p+1)(0.1p+1)}$.
\end{russian}}

{\begin{russian}\sffamily
Требования к системе
\end{russian}}

\liststyleWWviiiNumxxxiv
\begin{enumerate}
\item {\begin{russian}\sffamily
при отработке командных сигналов, меняющихся со скоростью \ \ \ \ \ \ \ \ до 10 ед/с, \ ошибка не должна превосходить
0.1 ед.;
\end{russian}}
\item {\begin{russian}\sffamily
время регулирования  $t_р\approx ?$ 1с;
\end{russian}}
\item {\begin{russian}\sffamily
ошибка воспроизведения гармонических сигналов с амплитудой  $A_v$
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ на частотах до 1 рад/\textenglish{c} \ должна быть не более 0.05 $A_v$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Последовательность расчёта
\end{russian}}

\liststyleWWviiiNumlxvi
\begin{enumerate}
\item {\begin{russian}\sffamily
Построить асимптотическую ЛАЧХ неизменяемой части системы  $L_0(ω)$ (рис. 3.2).
\end{russian}}
\item {\begin{russian}\sffamily
Построить желаемую ЛАЧХ  $L_{\normalsubformula{\text{жел}}}(ω)$.
\end{russian}}
\end{enumerate}
\liststyleWWviiiNumliii
\begin{itemize}
\item {\begin{russian}\sffamily
В связи с тем, что согласно п.1 требований к системе при линейно изменяющемся во времени командном сигнале допустима
постоянная ошибка, система должна иметь астатизм первого порядка. Поэтому низкочастотная асимптота должна идти с
наклоном -20 дБ/дек. В соответствии с (2.10.22) добротность системы
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \ \ \  $K=\frac{v_1}{ε(\infty
)}=\frac{10_{[\normalsubformula{\text{ед}}/c]}}{0.1_{[\normalsubformula{\text{ед}}]}}=100c^{-1}$.
\end{russian}}

{\begin{russian}\sffamily
Следовательно, низкочастотная асимптота должна пересекать ось частот при  $ω=100$ рад/с.
\end{russian}}

\liststyleWWviiiNumliv
\begin{itemize}
\item {\begin{russian}\sffamily
Частота среза определяется с учётом требуемого времени регулирования из (2.10.34):
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \  $ω_c=\frac{(3\div 4)π}{t_р}\approx 10\;\normalsubformula{\text{рад}}/c$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, среднечастотный участок желаемой ЛАЧХ на этой частоте пересекает ось абсцисс, имеет наклон -20 дБ/дек,
имеет протяжённость, равную одной декаде, то есть занимает интервал
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $3.16\le ω\le 31.6\;$.
\end{russian}}


\bigskip

\liststyleWWviiiNumxxxvi
\begin{itemize}
\item {\begin{russian}\sffamily
Диапазон частот  $ω>31.6$ считаем высокочастотным. Наклон высокочастотной асимптоты выбираем равным -60 дБ/дек, \ таким
же, как наклон высокочастотной асимптоты неизменяемой части системы.
\end{russian}}
\item {\begin{russian}\sffamily
\ Для того чтобы упростить реализацию корректирующего звена, низкочастотную и среднечастотные асимптоты соединяем
отрезком прямой с наклоном -40 дБ/дек. При этом следует учесть требование по точности воспроизведения гармонического
сигнала: в соответствии с (2.10.33) на частоте 1 рад/\textenglish{c} желаемая ЛАЧХ должна пройти выше уровня 26 дБ.
\end{russian}}
\end{itemize}
{\centering  \includegraphics[width=16.776cm,height=16.568cm]{1-img072.png} \par}

\bigskip


\bigskip

\liststyleWWviiiNumxlv
\begin{enumerate}
\item {\begin{russian}\sffamily
Построить ЛАЧХ корректирующего звена, производя графическое вычитание отрезков прямых в соответствии с (3.1.4).
\end{russian}}
\item {\begin{russian}\sffamily
Замерить значения сопрягающих частот асимптотической ЛАЧХ корректирующего звена и записать соответствующее выражение для
передаточной функции:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $W_k(p)=\frac{100(p+1)(\frac 1{3.16}p+1)(\frac 1{10}p+1)}{(\frac 1{0.33}p+1)(\frac 1{31.6}p+1)^2}$.
\end{russian}}


\bigskip

\subsection{Управляемость линейных стационарных систем}
\hypertarget{RefHeadingToc455659732}{}
\bigskip

{\begin{russian}\sffamily
Непрерывная линейная система
\end{russian}}

{\begin{russian}\sffamily
\ \ \textenglish{\ \ } $\vec{\dot x}(t)=A\vec x(t)+B\vec u(t)$\ \ (3.2.1)
\end{russian}}

{\begin{russian}\sffamily
является полностью управляемой тогда и только тогда, когда она может быть переведена из любого начального состояния 
$\vec x(t_0)$ в произвольный момент времени  $t_0$ в любое конечное состояние  $\vec x(t_1)$ за конечное время 
$t_1-t_0$.
\end{russian}}

{\begin{russian}\sffamily
Примем начальные условия нулевыми:  $\vec x(t_0)=0$. Тогда, в соответствии с формулой Коши,
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x(t_1)=\overset{t_1}{\underset{t_0}{\int }}e^{A(t_1-τ)}B\vec u(τ)\mathit{dτ}$.\ \ (3.2.2)
\end{russian}}

{\begin{russian}\sffamily
\ Принимая во внимание выражение для матричной экспоненты в виде бесконечного ряда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $e^{A(t_1-τ)}=E+\frac{A(t_1-τ)}{1!}+\frac{A^2(t_1-τ)^2}{2!}+\;...$ ,\ \ (3.2.3)
\end{russian}}

{\begin{russian}\sffamily
равенство (3.2.2) можно записать в виде
\end{russian}}

{\begin{russian}\sffamily
 $\vec x(t_1)=B\overset{t_1}{\underset{t_0}{\int }}\vec
u(τ)\mathit{dτ}+\normalsubformula{\text{AB}}\overset{t_1}{\underset{t_0}{\int }}\left(t_1-τ\right)\vec
u(t)\mathit{dτ}+A^2B\overset{t_1}{\underset{t_0}{\int }}\frac{\left(t_1-τ\right)^2}{2!}\vec u(τ)\mathit{dτ}+...$ .
\end{russian}}

{\begin{russian}\sffamily
Обозначим:\ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec α_i=\overset{t_1}{\underset{t_0}{\int }}\frac{\left(t_1-τ\right)^i}{i!}\vec
u(τ)\mathit{dτ}=\left[\begin{matrix}α_{\mathit{i1}}\\α_{\mathit{i2}}\\...\\α_{i,n_u}\end{matrix}\right]$. \ \ (3.2.4)
\end{russian}}

{\begin{russian}\sffamily
Представим произведения  $A^iB$ в виде блочных матриц векторов  $\vec β$:  $ $
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A^iB=\left[\vec β_{i_1}\overset{}{}\vec β_{i_2}\overset{}{}...\vec
β_{i_{\normalsubformula{\text{nu}}}}\right]$.\ \ (3.2.5)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Тогда
\end{russian}}

{\begin{russian}\sffamily
 $A^iB\overset{t_1}{\underset{t_0}{\int }}\frac{\left(t_1-τ\right)^i}{i!}\vec u(τ)\mathit{dτ}=\left[\begin{matrix}\vec
β_{i_1}&\vec β_{i_2}&...&\vec β_{i_{\normalsubformula{\text{nu}}}}\end{matrix}\right]\cdot \vec
α_i=\overset{\normalsubformula{\text{nu}}}{\underset{ν=1}{\sum }}α_{\mathit{iν}}\vec{}β_{\mathit{iν}}$\ \ (3.2.6)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x(t_1)=\overset{\infty }{\underset{i=0}{\sum }}\overset{\normalsubformula{\text{nu}}}{\underset{ν=1}{\sum
}}α_{\mathit{iν}}\cdot \vec β_{\mathit{iν}}$.\ \ (3.2.7)
\end{russian}}

{\begin{russian}\sffamily
В результате вектор  $\vec x(t_1)$ может рассматриваться как линейная комбинация векторов  $\vec β_{\mathit{iν}}$,
являющихся вектор-столбцами матриц \ \  $B,\;\;\normalsubformula{\text{AB}},\;\;A^2B,\;\;A^3B,\;\;...$ . Иначе говоря,
конечное состояние  $\vec x(t_1)$ принадлежит линейному подпространству, порождаемому вектор-столбцами бесконечной
последовательности матриц  $B,\;\;\normalsubformula{\text{AB}},\;\;A^2B,\;\;A^3B,\;\;...$ .
\end{russian}}

{\begin{russian}\sffamily
В этой последовательности должна появиться матрица  $A^lB$, все вектор-столбцы которой линейно зависят от
вектор-столбцов предыдущих матриц \  $B,\;\;\normalsubformula{\text{AB}},\;\;A^2B,\;\;...\;,\;\;A^{l-1}B.$ Такая
матрица обязательно \ должна иметь место, так как в линейном \textit{n-}мерном пространстве не может быть более чем 
$n$ линейно–независимых векторов. Отсюда же следует, что  $l\le n$. 
\end{russian}}

{\begin{russian}\sffamily
Таким образом, можно записать
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A^lB=\mathit{BΛ}_0+\normalsubformula{\text{AB}}Λ_1+...+A^{l-1}\mathit{BΛ}_{l-1}$,\ \ (3.2.8)
\end{russian}}

{\begin{russian}\sffamily
где  $Λ_i$- соответствующие диагональные матричные коэффициенты
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Λ_i=\left[\begin{matrix}λ_{\mathit{i1}}&0&\cdot \cdot \cdot &0\\0&λ_{\mathit{i2}}&\cdot \cdot \cdot &0\\\cdot
\cdot \cdot &\cdot \cdot \cdot &\cdot \cdot \cdot &\cdot \cdot \cdot \\0&0&\cdot \cdot \cdot
&λ_{\normalsubformula{\text{in}}_u}\end{matrix}\right]$.\ \ (3.2.9)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ Очевидно, тем же свойством обладает и матрица  $A^{l+1}B$, так как 
\end{russian}}

{\begin{russian}\sffamily

$A^{l+1}B=\normalsubformula{\text{AA}}^l=\normalsubformula{\text{AB}}Λ_0+A^2\mathit{BΛ}_1+...+A^{l-1}\mathit{BΛ}_{l-2}+A^l\mathit{BΛ}_{l-1}$.\ \ (3.2.10)
\end{russian}}

{\begin{russian}\sffamily
По индукции можно утверждать то же самое и для всех  $A^kB$ при  $k\ge l$.
\end{russian}}

{\begin{russian}\sffamily
Итак, конечное состояние \  $\vec x(t_1)$ принадлежит линейному подпространству, порождаемому вектор-столбцами матриц
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $B,\;\;\normalsubformula{\text{AB}},\;\;A^2B,$ ... , $\;\;A^{n-1}B$ 
\end{russian}}

{\begin{russian}\sffamily
(здесь учтено, что  $l\le n$). Если эти вектор-столбцы не порождают \ \ \ \ \ \ \ \  $n$-мерное пространство, то в такой
\ системе можно достичь лишь тех состояний, которые принадлежат подпространству меньшей размерности. 
\end{russian}}

{\begin{russian}\sffamily
Таким образом, критерий управляемости формулируется следующим образом: 
\end{russian}}

{\begin{russian}\sffamily
\textit{Система } $\vec{\dot x}\left(t\right)=A\vec x\left(t\right)+B\vec u\left(t\right)$\textit{ полностью управляема
тогда и только тогда, когда ранг матрицы управляемости}
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U=[\begin{matrix}B&\normalsubformula{\text{AB}}&A^2B&\cdots &A^{n-1}B\end{matrix}]\text{  }$\ \ (3.2.11)
\end{russian}}

{\begin{russian}\sffamily
\textit{равен } $n$\textit{, то есть полной размерности линейного пространства}. При этом \ \ говорят, что\textit{ пара
матриц \{A, B\} полностью управляема}\textbf{\textit{.}}
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.2.1. Определить управляемость системы
\end{russian}}

\begin{equation*}
\begin{matrix}\dot x_1=-4x_1+5x_2-5u\;;\hfill\null \\\dot x_2=3x_1-2x_2+3u\;;\hfill\null \\y=x_1\;.\hfill\null
\end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Для этой системы 
\end{russian}}

\begin{equation*}
A=\left[\begin{matrix}-4&5\\3&-2\end{matrix}\right]\text{ ,   }B=\left[\begin{matrix}-5\\3\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и матрица управляемости
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$U=\left[\begin{matrix}B&\normalsubformula{\text{AB}}\end{matrix}\right]=\left[\begin{matrix}-5&35\\3&-21\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Определитель этой матрицы равен нулю, она имеет ранг меньше двух, то есть порядка системы, и система является
неуправляемой. 
\end{russian}}

{\begin{russian}\sffamily
\ \ Отметим, что собственные числа матрицы динамики системы 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_1\text{=+}1\;;\;\;\;\;\;\;\;λ_2=-7$,
\end{russian}}

{\begin{russian}\sffamily
то есть система неустойчива. В то же время передаточная функция по выходной координате
\end{russian}}

\begin{equation*}
W_{\normalsubformula{\text{uy}}}(p)=-\frac 5{p+7},
\end{equation*}
{\begin{russian}\sffamily
у неё только один - устойчивый полюс - и по ней не видно, что в действительности система неустойчива.
\end{russian}}

{\begin{russian}\sffamily
\ \ Матричная передаточная функция по вектору состояния
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_{\normalsubformula{\text{ux}}}(p)=\left[\begin{matrix}-\frac 5{p+7}\\\frac 3{p+7}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Ей соответствует решение дифференциального уравнения системы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x(t)=e^{\normalsubformula{\text{At}}}\vec x(0)+\left[\begin{matrix}-5\\3\end{matrix}\right]\;\;\cdot
\overset t{\underset 0{\int }}e^{-7(t-τ)}\vec u(τ)\mathit{dτ}$.
\end{russian}}

{\begin{russian}\sffamily
Как видно, в вынужденной составляющей решения отсутствует одна - неустойчивая - мода. Кроме того, независимо от
управляющего сигнала для координат вынужденной составляющей вектора состояния существует линейная связь
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $x_{2В}(t)=-0.6x_{1В}(t)$. \ 
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.2.2. Определить управляемость системы
\end{russian}}

\begin{equation*}
\begin{matrix}\dot x_1=-4x_1+5x_2-10u\;;\hfill\null \\\dot x_2=3x_1-2x_2+3u\;;\hfill\null \\y=x_1\;.\hfill\null
\end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Для этой системы 
\end{russian}}

\begin{equation*}
A=\left[\begin{matrix}-4&5\\3&-2\end{matrix}\right]\text{ ,   }B=\left[\begin{matrix}-10\\3\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и матрица управляемости
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$U=\left[\begin{matrix}B&\normalsubformula{\text{AB}}\end{matrix}\right]=\left[\begin{matrix}-10&55\\3&-36\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Определитель этой матрицы не равен нулю, она имеет ранг, равный двум, то есть порядку системы, и система является
полностью управляемой. 
\end{russian}}

{\begin{russian}\sffamily
\ \ Отметим, что в данном случае полюсы передаточной функции
\end{russian}}

\begin{equation*}
W_{\normalsubformula{\text{uy}}}(p)=-\frac{5(2p+1)}{(p-1)(p+7)}
\end{equation*}
{\begin{russian}\sffamily
полностью повторяют все собственные числа матрицы  $A$.
\end{russian}}


\bigskip


\bigskip

\subsection{Наблюдаемость линейных стационарных систем}
\hypertarget{RefHeadingToc455659733}{}
\bigskip

{\begin{russian}\sffamily
\ \ \ В теории автоматического управления большую роль играет задача восстановления вектора состояния по результатам
наблюдения за входом и выходом объекта.
\end{russian}}

{\begin{russian}\sffamily
\ \ Непрерывная система
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\dot x(t)=Ax(t)+Bu(t)\;,\hfill\null \\y(t)=Cx(t)\hfill\null \end{matrix}\hfill $ \ \ \ (3.3.1)
\end{russian}}

{\begin{russian}\sffamily
называется наблюдаемой, если вектор состояния  $x(t_0)$ можно определить, зная  $\vec y(t)$ на некотором интервале
времени  $t=[t_0,\;\;t_1\;]$. Если это справедливо для любого  $t_0$, то система называется полностью наблюдаемой.
Задачей настоящего параграфа является вывод критерия наблюдаемости.
\end{russian}}

{\begin{russian}\sffamily
\ \ Достаточно рассмотреть задачу при \  $\vec u(t)=0$. Тогда 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y(t)=\normalsubformula{\text{Ce}}^{\normalsubformula{\text{At}}}\vec x(0)=D(t)\vec x(0)$.\ \ (3.3.2)
\end{russian}}

{\begin{russian}\sffamily
\ В развёрнутом виде - это система алгебраических уравнений
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $\begin{matrix}D(t)_{11}x_1(0)+D(t)_{12}x_2(0)+...+D(t)_{1n}x_n(0)=y_1(t)\hfill\null
\\D(t)_{21}x_1(0)+D(t)_{22}x_2(0)+...+D(t)_{2n}x_n(0)=y_1(t)\hfill\null \\\cdot \cdot \cdot \cdot \cdot \cdot \cdot
\cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot
\cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot
\cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \hfill\null
\\D(t)_{\normalsubformula{\text{ny}},1}x_1(0)+D(t)_{\normalsubformula{\text{ny}},2}x_2(0)+...+D(t)_{\normalsubformula{\text{ny}},n}x_n(0)=y_{\normalsubformula{\text{ny}}}(t)\hfill\null
\end{matrix}\hfill $ ,\ \ (3.3.3)
\end{russian}}

{\begin{russian}\sffamily
в качестве неизвестных в которой выступают координаты вектора состояния. В связи с тем, что, как правило, \  $n_y<n$,
число уравнений оказывается меньше числа неизвестных, и решение невозможно.
\end{russian}}

{\begin{russian}\sffamily
В соответствии с теоремой Кэли-Гамильтона каждая квадратная матрица удовлетворяет собственному характеристическому
уравнению:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A^n+α_1A^{n-1}+...+α_{n-1}A+α_nE=0$.\ \ (3.3.4)
\end{russian}}

{\begin{russian}\sffamily
Поэтому матричная экспонента, являющаяся степенным рядом относительно матрицы  $A$, может быть представлена в виде
полинома степени  $n-1$. С учетом этого равенство (3.3.2) можно записать в виде
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y(t)=\overset{n-1}{\underset{l=0}{\sum }}γ_l(t)\cdot C\cdot A^l\vec x(0)$,\ \ (3.3.5)
\end{russian}}

{\begin{russian}\sffamily
где  $γ_l(t)$ – соответствующие коэффициенты этого полинома. Для i-й составляющей вектора выхода соответственно будем
иметь
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $y_i(t)=\overset{n-1}{\underset{l=0}{\sum }}γ_l(t)(\normalsubformula{\text{CA}}^l)_ix(0)$.\ \ (3.3.6)
\end{russian}}

{\begin{russian}\sffamily
Здесь  $(\normalsubformula{\text{CA}}^l)_i$ –  $i$-я строка матрицы  $(\normalsubformula{\text{CA}}^l)$.
\end{russian}}

{\begin{russian}\sffamily
Если набор \  $(\normalsubformula{\text{CA}}^l)_i$ для  $i=1,2,...,n_y$;  $l=0,1,2,...,n-1$ не содержит полного базиса,
то есть  $n$ линейно независимых строк, иначе говоря, если матрица
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$N=\left[\begin{matrix}C\\\normalsubformula{\text{CA}}\\\normalsubformula{\text{CA}}^2\\...\\\normalsubformula{\text{CA}}^{n-1}\end{matrix}\right]$\ \ (3.3.7)\ \ \ \ \ \ 
\end{russian}}

{\begin{russian}\sffamily
имеет ранг, меньший, чем  $n$, то в качестве ненулевого вектора начальных условий \  $\vec x(0)\neq 0$ может быть выбран
вектор, ортогональный всем строкам матрицы \textit{N}. Тогда в соответствии с (3.3.5) получим, что \  $\vec y(t)=0$ для
всех  $t$, \ т.е. система не наблюдаема.
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \ Теперь докажем, что если ранг матрицы \textit{N }\ равен  $n$, то  $\vec x(t_0)$ может быть определен с
помощью конечного числа измерений вектора выхода  $y(t)$. Обозначим 
\end{russian}}

{\begin{russian}\sffamily
\ \  $Γ(t_k)=\left[γ_0(t_k)E\text{  }γ_1(t_k)E...γ_{n-1}(t_k)E\right]$,\ \ (3.3.8)
\end{russian}}

{\begin{russian}\sffamily
где Е – квадратная единичная матрица размером  $[n_y\times n_y]$. Моменты измерения  $t_k$ выберем таким образом, чтобы
для различных значений  $k$ элементы  $γ_i(t_k)$ отличались друг от друга. С учетом введенного обозначения равенство
(3.3.5) примет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y(t_k)=Γ(t_k)N\vec x(0)$.\ \ (3.3.9)
\end{russian}}

{\begin{russian}\sffamily
Известно, что ранг произведения любых двух матриц не превосходит ранга каждого из сомножителей. Ранг матрицы  $Γ(t_k)$
не превосходит числа ее строк  $n_y<n$. Проводя многократные измерения на интервале времени переходного процесса
системы, построим расширенный вектор выхода \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec Y_R=\left[\begin{matrix}\vec y(t_1)\\\vec y(t_2)\\...\\\vec
y(t_n)\end{matrix}\right]$\ \ (3.3.10)\ \ \ \ 
\end{russian}}

{\begin{russian}\sffamily
\ и обозначим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Γ_R=\left[\begin{matrix}Γ\left(t_1\right)\\...\\Γ\left(t_n\right)\end{matrix}\right]$. \ \ (3.3.11)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ Матрица  $Γ_R$ имеет  $n_y\times n$ строк. Моменты измерений должны быть выбраны таким образом, чтобы
выполнялось условие  $\normalsubformula{\text{rank}}Γ_R=n$. Как было обусловлено, ранг матрицы  $N$ также равен  $n$.
Поэтому уравнение 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Γ_R\cdot N\cdot \vec x(0)=\vec Y_R$\ \ (3.3.12)
\end{russian}}

{\begin{russian}\sffamily
содержит  $n$ линейно независимых скалярных уравнений, то есть оно может быть разрешено относительно вектора  $x(0)$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, доказан следующий \textbf{критерий полной наблюдаемости стационарных линейных систем}:
\end{russian}}

{\begin{russian}
\textsf{\textit{Линейная стационарная система вполне наблюдаема тогда и только тогда, когда ранг матрицы наблюдаемости N
равен }} $n$\textsf{\textit{.}}
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.3.1. \ Объект управления задан \ уравнениями
\end{russian}}

\begin{equation*}
\begin{matrix}\dot x_1=-8x_1+3x_2+3u\;;\hfill\null \\\dot x_2=-x_1-4x_2+2u\;;\hfill\null \\y=x_1-2x_2.\hfill\null
\end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Этим уравнениям соответствуют матрицы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$A=\left[\begin{matrix}-8&3\\-1&-4\end{matrix}\right];\;\;\;\;\;\;\;B=\left[\begin{matrix}3\\2\end{matrix}\right];\;\;\;\;\;\;C=\left[\begin{matrix}1&-2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Определитель матрицы управляемости 
\end{russian}}

\begin{equation*}
U=\left[\begin{matrix}3&-18\\2&-11\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
не равен нулю, поэтому система управляема. Матрица наблюдаемости
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$N=\left[\begin{matrix}C\\\normalsubformula{\text{CA}}\end{matrix}\right]=\left[\begin{matrix}1&-2\\-6&-5\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Её определитель также отличен от нуля, следовательно, система полностью наблюдаема.
\end{russian}}

{\begin{russian}\sffamily
\ \ Для данного объекта нетрудно рассчитать собственные числа
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_1=-5;\;\;\;\;\;\;\;λ_2=-7$,
\end{russian}}

{\begin{russian}\sffamily
\ правые
\end{russian}}

\begin{equation*}
\vec v_1=\left[\begin{matrix}1\\1\end{matrix}\right]\;;\;\;\;\;\;\;\vec v_2=\left[\begin{matrix}3\\1\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и левые
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec d_1^T=\left[\begin{matrix}-0.5&1.5\end{matrix}\right]$ ; \ \ \  $\vec
d_2^T=\left[\begin{matrix}0.5&-0.5\end{matrix}\right]$
\end{russian}}

{\begin{russian}\sffamily
собственные векторы.
\end{russian}}

{\begin{russian}\sffamily
\ \ В соответствии с (2.4.27), (2.6.4) и (2.6.6) нетрудно получить передаточные функции по векторам состояния и выхода:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$W_x(p)=\left[\begin{matrix}\frac{1.5}{p+5}+\frac{1.5}{p+7}\\\frac{1.5}{p+5}+\frac{0.5}{p+7}\end{matrix}\right]$;
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_y(p)=-\frac{1.5}{p+5}+\frac{0.5}{p+7}$.
\end{russian}}

{\begin{russian}\sffamily
В данном случае полюсы передаточной функции по выходу полностью отображают собственные числа матрицы динамики.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.3.2. Объект управления задан \ уравнениями
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\dot x_1=-8x_1+3x_2+3u\hfill\null \\\dot x_2=-x_1-4x_2+2u\hfill\null \end{matrix}\hfill $ ;
\ \ \ \ \ \  $y=x_1-3x_2$.\ \ 
\end{russian}}

{\begin{russian}\sffamily
Матрицы  $A$ и  $B$ здесь такие же, как и в предыдущем примере, следовательно, объект управляем. Матрица выхода
\end{russian}}

{\begin{russian}\sffamily
\ \ \textenglish{\ \ } $\;\;\;\;\;C=\left[\begin{matrix}1&-3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Ранг матрицы наблюдаемости
\end{russian}}

\begin{equation*}
N=\left[\begin{matrix}C\\\normalsubformula{\text{CA}}\end{matrix}\right]=\left[\begin{matrix}1&-3\\-5&15\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
в данном случае меньше порядка объекта и равен единице, так как второй столбец пропорционален первому. Следовательно,
данный объект ненаблюдаем.
\end{russian}}

{\begin{russian}\sffamily
\ \ Правые и левые собственные векторы матрицы динамики и передаточная функция по вектору состояния такие же, как и в
предыдущем примере. Передаточная функция по выходу
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_y(p)=-\frac 3{p+5}$.
\end{russian}}

{\begin{russian}\sffamily
У неё отсутствует полюс, равный второму собственному числу \ \ \ матрицы  $A$.
\end{russian}}

{\begin{russian}\sffamily
Определим сво­бод­ное движение объекта по вектору состояния и по \ выходу:
\end{russian}}

\begin{equation*}
\begin{matrix}\vec x(t)=e^{\normalsubformula{\text{At}}}\vec x(0)=\overset 2{\underset{i=1}{\sum }}e^{λ_it}\vec v_i\vec
d_i^T\vec{}x(0)\;;\hfill\null \\y(t)=C\vec x(t)\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Получаем:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x(t)=\left[\begin{matrix}-0.5&1.5\\-0.5&1.5\end{matrix}\right]\vec
x(0)e^{-5t}+\left[\begin{matrix}1.5&-1.5\\0.5&-0.5\end{matrix}\right]\vec x(0)e^{-7t}$;
\end{russian}}

{\begin{russian}\sffamily
\ \  $y(t)=\left[\begin{matrix}1&-3\end{matrix}\right]\vec x(0)e^{-5t}$.
\end{russian}}

{\begin{russian}\sffamily
Если выбрать 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x(0)=\vec v_2=\left[\begin{matrix}3\\1\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
то, так как векторы  $\vec v_2$ и  $\vec d_1$ взаимно ортогональны и их скалярное произведение равно нулю, получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x(t)=\left[\begin{matrix}3\\1\end{matrix}\right]e^{-7t}$,
\end{russian}}

{\begin{russian}\sffamily
в то время как
\end{russian}}

{\begin{russian}\sffamily
\ \ \textenglish{\ \ } $\vec y(t)=0$.
\end{russian}}

\clearpage\subsection[Замена базиса в линейном конечномерном \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ пространстве]{Замена
базиса в линейном конечномерном \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ пространстве}
\hypertarget{RefHeadingToc455659734}{}
\bigskip

{\begin{russian}\sffamily
Линейное пространство \textit{R} называется конечномерным, а число  $n$ – числом измерений этого пространства или его
размерностью\textit{ (} $\text{dimR}=n$\textit{)}, если в \textit{R} существует  $n$ линейно независимых векторов, в то
время как любые \  $n+1$ \ векторов в  $R$ линейно зависимы.
\end{russian}}

{\begin{russian}\sffamily
Система из  $n$ линейно независимых, заданных в определенном порядке векторов \  $\vec e_1,\vec
e\multiscripts{_2}{{}}{{}}{}{},...,\vec e_n$ в  $n$-мерном пространстве называется базисом этого пространства. 
\end{russian}}

{\begin{russian}\sffamily
Если каждый из векторов базиса ортогонален любому другому вектору этого базиса, т.е. их скалярные произведения равны
нулю, то такой базис называется ортогональным. Если, кроме того, модуль каждого вектора базиса равен единице, то базис
называется ортонормированным.
\end{russian}}

{\begin{russian}\sffamily
Векторы  $\vec x,\vec e_1,\vec e\multiscripts{_2}{{}}{{}}{}{},...,\vec e_n$, где  $\vec x$- любой вектор из 
$R$\textit{,} линейно зависимы, так как их \textrussian{\textrm{\textbf{Ошибка! Ошибка связи.}}}. Отсюда справедливо
равенство
\end{russian}}

{\begin{russian}\sffamily
\ \  $α_0\vec x+α_1\vec e_1+α_2\vec e_2+...+α_n\vec e_n=0$,\ \ (3.4.1)
\end{russian}}

{\begin{russian}\sffamily
откуда
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x=x_{\mathit{e1}}\vec e_1+x_{\mathit{e2}}\vec e_2+...+x_{\normalsubformula{\text{en}}}\vec e_n$.\ \ (3.4.2)
\end{russian}}

{\begin{russian}\sffamily
Здесь
\end{russian}}

{\begin{russian}\sffamily
 $x_{\mathit{e1}},x_{\mathit{e2}},...,x_{\normalsubformula{\text{en}}}$- координаты вектора  $\vec x$ в базисе  $\{e\}$.
\end{russian}}

{\begin{russian}\sffamily
Столбец 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec
x_e=\left[\begin{matrix}x_{\mathit{e1}}\\x_{\mathit{e2}}\\...\\x_{\normalsubformula{\text{en}}}\end{matrix}\right]$\ \ (3.4.3)
\end{russian}}

{\begin{russian}\sffamily
называют координатным столбцом вектора  $\vec x$ в этом базисе. 
\end{russian}}

{\begin{russian}\sffamily
 $\vec x$- вектор в пространстве, и только если в этом пространстве выберем базис, то возникает понятие координатного
вектор-столбца  $\vec x_e$. Если установим другой базис, то ему будет соответствовать другой координатный
вектор-столбец.
\end{russian}}

{\begin{russian}\sffamily
Пусть в  $n$-мерном пространстве задано два базиса:
\end{russian}}

\begin{equation*}
\{e\}\;\;\;:\;\;\;\;\vec e_1,\;\;\vec e_2,\;...\;,\;\;\vec e_n\;
\end{equation*}
{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\{f\}\;\;\;:\;\;\;\;\vec f_1,\;\;\vec f_2,\;...\;,\;\;\vec f_n\;$.
\end{russian}}

{\begin{russian}\sffamily
Так как это векторы одного и того же пространства, то каждый из векторов базиса  $\{f\}$\textit{ }можно разложить через
векторы базиса  $\{e\}$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec f_1=f_{e11}\vec e_1+f_{e21}\vec e_2+\;...\;+f_{\normalsubformula{\text{en}}1}\vec
e_n\;;\hfill\null \\\vec f_2=f_{e12}\vec e_1+f_{e22}\vec e_2+\;...\;+f_{\normalsubformula{\text{en}}2}\vec
e_n\;;\hfill\null \\\cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot
\cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \hfill\null \\\vec
f_n=f_{\mathit{e1n}}\vec e_1+f_{\mathit{e2n}}\vec e_2+\;...\;+f_{\normalsubformula{\text{enn}}}\vec e_n\;.\hfill\null
\end{matrix}\hfill $\ \ (3.4.4)
\end{russian}}

{\begin{russian}\sffamily
Коэффициенты  $f_{\normalsubformula{\text{eik}}}$ (здесь  $i$–номер координаты, а  $k$–номер раскладываемого вектора)
можно представить в виде квадратной матрицы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$F_e=\left[\begin{matrix}f_{\boldsubformula{\text{e11}}}&f_{\boldsubformula{\text{e12}}}&...&f_{\boldsubformula{\text{e1n}}}\\f_{\boldsubformula{\text{e21}}}&f_{\boldsubformula{\text{e22}}}&...&f_{\boldsubformula{\text{e2n}}}\\.....&.....&.....&.....\\f_{\boldsubformula{\text{e
n1}}}&f_{\boldsubformula{\text{e n2}}}&...&f_{\boldsubformula{\text{e nn}}}\end{matrix}\right]$,\ \ (3.4.5)
\end{russian}}

{\begin{russian}\sffamily
или 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=\left[\begin{matrix}\vec f_{\boldsubformula{\text{e1}}}&\vec f_{\boldsubformula{\text{e2}}}&\cdot \cdot
\cdot &\vec f_{\boldsubformula{\text{en}}}\end{matrix}\right]$.\ \ (3.4.6)
\end{russian}}

{\begin{russian}\sffamily
Столбцы матрицы  $F_e$ – это координатные столбцы векторов  $\;\vec f_1,\;\;\vec f_2,\;...\;,\;\;\vec f_n\;$ базиса 
$\{f\}$\textit{ }в базисе  $\{e\}$.
\end{russian}}

{\begin{russian}\sffamily
С учетом введенных обозначений систему равенств (3.4.4) можно записать в виде 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\left\{\vec f_1=\left[\begin{matrix}\vec e_1\hfill\null &\vec e_2\hfill\null &...\hfill\null &\vec
e_n\hfill\null \end{matrix}\right]\cdot \vec f_{e_1}=\left[e\right]\cdot \;\vec f_{e_1}?\right.\left\{\vec
f_2=\left[e\right]\cdot \vec
f_{e_2}?\right.\left\{..................................................?\right.\left\{\vec f_n=\left[e\right]\cdot
\vec f_{e_n}?\right.\mathit{no}\hfill\null \end{matrix}\{??$.\ \ (3.4.7)
\end{russian}}

{\begin{russian}\sffamily
Можно ещё более упростить (укрупнить) эти равенства, используя понятия блочных матриц:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\left[\begin{matrix}\vec f_1&\vec f_2&\cdot \cdot \cdot &\vec f_n\end{matrix}\right]=\left[\begin{matrix}[e]\cdot
\vec f_{\mathit{e1}}&[e]\cdot \vec f_{\mathit{e2}}&\cdot \cdot \cdot &[e]\cdot \vec
f_{\normalsubformula{\text{en}}}\end{matrix}\right]$\ \ (3.4.8)
\end{russian}}

{\begin{russian}\sffamily
или, в итоге,
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $[f]=[e]F_e$.\ \ (3.4.9)
\end{russian}}

{\begin{russian}\sffamily
Матрица \  $F_e$ называется матрицей перехода от базиса  $\{e\}$\textit{ }к базису\textit{ } $\{f\}$. Так как  $F_e$
невырожденная, то
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\left[e\right]=\left[f\right]\cdot E_f$,\ \ (3.4.10)
\end{russian}}

{\begin{russian}\sffamily
где матрица
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $E_f=F_e^{\boldsubformula{\text{-1}}}$\ \ (3.4.11)
\end{russian}}

{\begin{russian}\sffamily
называется матрицей перехода от базиса  $\{f\}$ к базису  $\{e\}$\textit{.}
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.4.1. Пусть в \textenglish{R}\textsuperscript{2} задан базис  $\{e\}$ векторами  $\vec e_1,\vec e_2$ (рис. 3.3).
\end{russian}}


\bigskip

{\centering  \includegraphics[width=9.024cm,height=6.348cm]{1-img073.png} \par}

\bigskip

{\begin{russian}\sffamily
Введем базис  $\{f\}$ следующим образом:
\end{russian}}

\begin{equation*}
\begin{matrix}\vec f_1=1\cdot \vec e_1+1\cdot \vec e_2\;;\hfill\null \\\vec f_2=-1\cdot \vec e_1+0\cdot \vec
e_2\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Запишем матрицу перехода от базиса  $\{e\}$ к базису  $\{f\}$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=\left[\begin{matrix}1&-1\\1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
\ Найдем обратную матрицу
\end{russian}}

\begin{equation*}
F_e^{-1}=\left[\begin{matrix}0&1\\-1&1\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и, в соответствии с (3.4.10), получаем
\end{russian}}

{\begin{russian}\sffamily
\ \  $\left[\begin{matrix}\vec e_1&\vec e_2\end{matrix}\right]=\left[\begin{matrix}\vec f_1&\vec
f_2\end{matrix}\right]\cdot \left[\begin{matrix}0&1\\-1&1\end{matrix}\right]=\left[\begin{matrix}-\vec f_2&\vec
f_1+\vec f_2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Этот результат подтверждается анализом рис. 3.3.
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим, как связаны между собой компоненты (координатные столбцы) одного и того же вектора  $\vec x$ в разных
базисах. В соответствии с (3.4.2)\ \ \ \ \ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=x_{\mathit{e1}}\vec e_1+x_{\mathit{e2}}\vec e_2+\;...\;+x_{\normalsubformula{\text{en}}}\vec
e_n$\ \ (3.4.12)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=x_{\mathit{f1}}\vec f_1+x_{\mathit{f2}}\vec f_2+\;...\;+x_{\normalsubformula{\text{fn}}}\vec
f_n$.\ \ (3.4.13)
\end{russian}}

{\begin{russian}\sffamily
Приравнивая правые части последних двух равенств, получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\left[e\right]\cdot \vec x_e=\left[f\right]\cdot \vec x_f$,\ \ (3.4.14)
\end{russian}}

{\begin{russian}\sffamily
а с учётом (3.4.9)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $[e]\vec x_e=\left[e\right]F_e\vec x_f$.\ \ (3.4.15)
\end{russian}}

{\begin{russian}\sffamily
Окончательно получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x_e=F_e\vec x_f;$ \  $\vec x_f=F_e^{-1}\cdot \vec x_e=E_f\cdot \vec x_e$.\ \ (3.4.16)
\end{russian}}


\bigskip

\subsection[Линейные операторы и матрицы линейных операторов]{Линейные операторы и матрицы линейных операторов}
\hypertarget{RefHeadingToc455659735}{}{\begin{russian}\sffamily
\ \ \ Отображение  $A$\textrm{ }линейного пространства  $X$ в линейное пространство  $Y$
\end{russian}}

\begin{equation*}
A\;:\;\;\;X\rightarrow Y
\end{equation*}
{\begin{russian}\sffamily
называют линейным преобразованием или линейным оператором, если оно удовлетворяет двум условиям:
\end{russian}}

{\begin{russian}\sffamily
а)
\end{russian}}

{\begin{russian}\sffamily
\ \  $A(\vec x+\vec v)=A(\vec x)+A(\vec v)$ \ для всех \  $\vec x,\;\vec v\in X$;\ \ (3.5.1)
\end{russian}}

{\begin{russian}\sffamily
б)
\end{russian}}

{\begin{russian}\sffamily
\ \  $A(α\vec x)=\mathit{αA}(\vec x)$ \ \ для всех \  $\vec x\in X$ и любого  $α$.\ \ (3.5.2)
\end{russian}}

{\begin{russian}\sffamily
Если отображение  $A$ переводит вектор  $\vec x$ в некоторый другой вектор  $\vec y$: \ \ \ \ \ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A\left(\vec x\right)=\vec y$,\ \ (3.5.3)
\end{russian}}

{\begin{russian}\sffamily
\ то вектор  $\vec y$ называют образом вектора  $\vec x$, а  $\vec x$- прообразом вектора  $\vec y$.
\end{russian}}

{\begin{russian}\sffamily
\textit{Линейный оператор, отображающий линейное пространство } $R^n$\textit{ само в себя, называется линейным
оператором в } $R^n$\textit{.}
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Пусть  $\vec x\in R^n;\vec y\in R^n$ и  $\vec y=A(\vec x)$. \ Рассмотрим, как связаны в этом случае координаты векторов 
$\vec x$ и  $\vec y$. Будем ориентироваться сначала на базис  $[e]=\left[\begin{matrix}\vec e_1&\vec e_2&\cdot \cdot
\cdot &\vec e_n\end{matrix}\right]$. Очевидно при этом, что
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=\overset n{\underset{k=1}{\sum }}x_{\normalsubformula{\text{ek}}}\vec e_k$;\ \ (3.5.4)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y=\overset n{\underset{i=1}{\sum }}y_{\normalsubformula{\text{ei}}}\vec e_i$.\ \ (3.5.5)
\end{russian}}

{\begin{russian}\sffamily
Из соотношений (3.5.3) и (3.5.4) следует
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y=\overset n{\underset{k=1}{\sum }}x_{e_k}A\left(\vec e_k\right)$.\ \ (3.5.6)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Рассмотрим прежде всего, как действует оператор  $A$ \ на элементы базиса. Пусть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}A\left(\vec e_1\right)=a_{11}^e\vec e_1+a_{21}^e\vec e_2+...+a_{\mathit{n1}}^e\vec
e_n;\hfill\null \\................................................\hfill\null \\A\left(\vec e_k\right)=a_{1k}^e\vec
e_1+a_{2k}^e\vec e_2+...+a_{\normalsubformula{\text{nk}}}^e\vec e_n;\hfill\null
\\.................................................\hfill\null \\A\left(\vec e_n\right)=a_{1n}^e\vec e_1+a_{2n}^e\vec
e_2+...+a_{\normalsubformula{\text{nn}}}^e\vec e_n\;.\hfill\null \end{matrix}\hfill $\ \ (3.5.7)
\end{russian}}

{\begin{russian}\sffamily
Учтём (3.5.7):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y=\overset n{\underset{k=1}{\sum }}x_{\normalsubformula{\text{ek}}}\overset n{\underset{i=1}{\sum
}}a_{\normalsubformula{\text{ik}}}^e\vec e_i$.\ \ (3.5.8) 
\end{russian}}

{\begin{russian}\sffamily
Сопоставляя это равенство с (3.5.5), получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $y_{\normalsubformula{\text{ei}}}=\overset n{\underset{k=1}{\sum
}}a_{\normalsubformula{\text{ik}}}^ex_{\normalsubformula{\text{ek}}}\text{    , }i=1,2,...,n$.\ \ (3.5.9)
\end{russian}}

{\begin{russian}\sffamily
Запишем этот результат в матричной форме:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y_e=A_e\cdot \vec x_e$ ,\ \ (3.5.10)
\end{russian}}

{\begin{russian}\sffamily
где, как и раньше,  $\vec y_e$ и  $\vec x_e$ - координатные вектор-столбцы соответствующих векторов в базисе  $[e]$, а
матрица
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$A_e=\left[\begin{matrix}a_{11}^e&a_{12}^e&...&a_{1n}^e\\a_{21}^e&a_{22}^e&...&a_{2n}^e\\.....&.....&.....&.....\\a_{\mathit{n1}}^e&a_{\mathit{n2}}^e&...&a_{\normalsubformula{\text{nn}}}^e\end{matrix}\right]$\ \ (3.5.11)
\end{russian}}

{\begin{russian}\sffamily
называется матрицей оператора  $A$ в базисе  $[e]$\textit{. }Элементы её столбцов по построению - это координаты
векторов  $A\left(\vec e_1\right),A\left(\vec e_2\right).....$ в базисе  $[e]$. Аналогично вводится \ понятие матрицы 
$A_f$ того же оператора\textit{ } $A$ в некотором другом базисе  $[f]$\textit{.}
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим теперь, как изменяется \ матрица оператора  $A$ при замене базиса в пространстве  $R^n$. Пусть, как и прежде,
 $\vec y=A\left(\vec x\right)$ \ и матрица  $A_e$, в соответствии с (3.5.10), связывает между собой координатные
столбцы векторов  $\vec x$ и  $\vec y$ в базисе  $[e]$.
\end{russian}}

{\begin{russian}\sffamily
\ \ \ Согласно ранее полученным результатам - соотношениям (3.4.16),
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x_e=F_e\cdot \vec x_f$\ \ (3.5.12)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y_e=F_e\cdot \vec y_f$ .\ \ (3.5.13) \ 
\end{russian}}

{\begin{russian}\sffamily
Из этих двух соотношений и \ (3.5.10) легко выводится равенство 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y_f=A_f\cdot \vec x_f$,\ \ (3.5.14)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_f=F_e^{-1}\cdot A_e\cdot F_e$ .\ \ (3.5.15)
\end{russian}}

{\begin{russian}\sffamily
Эта формула позволяет связать между собой матрицы одного и того же \ оператора в различных базисах. В математике такие
матрицы называются \textit{подобными}. Ранее (п.2.4.3) уже отмечалось, что подобные матрицы имеют одинаковые
собственные числа. \ \ \ \ 
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.5.1. Пусть имеется базис  $[e]$ (рис. 3.4).
\end{russian}}

{\begin{russian}\sffamily
1. Зададим \ оператор  $A$ его действием на векторы базиса  $[e]$:
\end{russian}}

\begin{equation*}
\begin{matrix}A\left(\vec e_1\right)=\vec e_1+2\vec e_2;\hfill\null \\A\left(\vec e_2\right)=-\vec e_1\;.\hfill\null
\end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Тем самым мы определили матрицу оператора  $A$ в базисе $[e]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_e=\left[\begin{matrix}1&-1\\2&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
2. Зададим вектор  $\vec x$ в базисе  $[e]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=\vec e_1-\vec e_2$.
\end{russian}}

{\centering  \includegraphics[width=8.017cm,height=9.366cm]{1-img074.png} \par}

\bigskip

{\begin{russian}\sffamily
Отсюда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x_e=\left[\begin{matrix}\;\;\;\;1\\-1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
3. Рассчитаем координатный вектор, используя (3.5.14):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y_e=A_e\vec x_e=\left[\begin{matrix}1&-1\\2&0\end{matrix}\right]\cdot
\left[\begin{matrix}1\\-1\end{matrix}\right]=\left[\begin{matrix}2\\2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
4. Введем новый базис  $[f]$:
\end{russian}}

\begin{equation*}
\begin{matrix}\vec f_1=-\vec e_2\;;\hfill\null \\\vec f_2=-\vec e_1-\vec e_2\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Тогда матрица перехода от базиса  $[e]$\textit{ }к базису  $[f]$ будет иметь вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=\left[\begin{matrix}0&-1\\-1&-1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
5. Определим матрицу  $A_f$ оператора  $A$ в базисе  $[f]$:
\end{russian}}

{\begin{russian}\sffamily
\ \  $A_f=F_e^{-1}A_eF_e=\left[\begin{matrix}1&-1\\-1&0\end{matrix}\right]\cdot
\left[\begin{matrix}1&-1\\2&0\end{matrix}\right]\cdot
\left[\begin{matrix}0&-1\\-1&-1\end{matrix}\right]=\left[\begin{matrix}1&2\\-1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
6. Найдём координатный столбец вектора  $\vec x$ в базисе  $[f]$. В соответствии с рис. 3.4
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=2\vec f_1-\vec f_2$.
\end{russian}}

{\begin{russian}\sffamily
С другой стороны, согласно (3.5.12)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x_f=F_e^{-1}\cdot \vec x_e$. \ \ (3.5.16) \ 
\end{russian}}

{\begin{russian}\sffamily
Оба подхода дают один и тот же результат:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec x_f=\left[\begin{matrix}2\\-1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
В итоге получим \ координатный столбец вектора  $\vec y$ в базисе  $[f]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y_f=A_f\vec x_f=\left[\begin{matrix}0\\-2\end{matrix}\right]$.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.5.2. \ \ Дана матрица  $A_e$ оператора  $A$ в базисе  $[e]$:
\end{russian}}

\begin{equation*}
A_e=\left[\begin{matrix}0&1\\0&0\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и два вектора -  $\vec f_1$ и  $\vec f_2$, координатные столбцы которых в том же базисе \ имеют вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec f_{\mathit{e1}}=\left[\begin{matrix}1\\2\end{matrix}\right]$; \ \  $\vec
f_{\mathit{e2}}=\left[\begin{matrix}0\\3\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
то есть
\end{russian}}

\begin{equation*}
\begin{matrix}\vec f_1=\vec e_1+2\vec e_2\;;\hfill\null \\\vec f_2=3\vec e_2\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Примем эти векторы в качестве нового базиса и вычислим в нём матрицу  $A_f$ оператора  $A$. Для этого выполним следующие
действия.
\end{russian}}

{\begin{russian}\sffamily
1. Составим матрицу перехода от базиса  $[e]$ к базису  $[f]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=\left[\begin{matrix}1&0\\2&3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
2. Вычислим обратную матрицу:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e^{-1}=\left[\begin{matrix}1&0\\-\frac 2 3&\frac 1 3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
3. Вычислим матрицу  $A_f$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_f=F_e^{-1}\cdot A_e\cdot F_e=\left[\begin{matrix}2&3\\-\frac 4 3&-2\end{matrix}\right]$.
\end{russian}}


\bigskip

\subsection[Замена базиса в \ пространстве состояний \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ динамической
системы]{Замена базиса в \ пространстве состояний \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ динамической системы}
\hypertarget{RefHeadingToc455659736}{}
\bigskip

{\begin{russian}\sffamily
Пусть заданы уравнения системы 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot x}(t)=A\vec x(t)+B\vec u(t)\;;\hfill\null \\\vec y(t)=C\vec x(t)\;.\hfill\null
\end{matrix}\hfill $\ \ (3.6.1) \ 
\end{russian}}

{\begin{russian}\sffamily
Для этой системы могут быть найдены матрицы:
\end{russian}}

{\begin{russian}\sffamily
\ управляемости
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U=\left[\begin{matrix}B&\normalsubformula{\text{AB}}&A^2B&...&A^{n-1}B\end{matrix}\right]$,\ \ (3.6.2) \ 
\end{russian}}

{\begin{russian}\sffamily
наблюдаемости
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$N=\left[\begin{matrix}C\\\normalsubformula{\text{CA}}\\...\\\normalsubformula{\text{CA}}^{n-1}\end{matrix}\right]$,\ \ (3.6.3)
\ 
\end{russian}}

{\begin{russian}\sffamily
передаточной функции
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_y(p)=C(\normalsubformula{\text{pE}}-A)^{-1}B$.\ \ (3.6.4) \ 
\end{russian}}

{\begin{russian}\sffamily
Могут быть также записаны выражения для векторов состояния и выхода
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\vec x(t)=Φ(t-t_0)\vec x(t_0)+\overset t{\underset{t_0}{\int }}Φ(t-τ)B\vec
u(τ)\mathit{dτ}\;;\hfill\null \\\vec y(t)=\mathit{CΦ}(t-t_0)\vec x(t_0)+\overset t{\underset{t_0}{\int
}}\mathit{CΦ}(t-τ)B\vec u(τ)\mathit{dτ}\;.\hfill\null \end{matrix}\hfill $\ \ (3.6.5)
\end{russian}}

{\begin{russian}\sffamily
\ \ Полученные в предыдущих разделах результаты не были ограничены выбором какого-либо конкретного базиса в пространстве
состояний. Все они были справедливы для любого базиса, в котором записаны матрицы 
$A\;,\;\;B\;,\;\;C\;,\;\;Ф\;,\;\;W\;,\;\;U\;,\;\;N$. Для определённости назовём этот базис базисом  $[e]$. В этом
случае \ можно подразумевать, что символы всех векторов и матриц в выражениях (3.6.1) - (3.6.5) снабжены индексом "
$e$". \ \ В дальнейшем нам будет удобно выбирать вполне определенный базис в пространстве состояний  $X$ таким образом,
чтобы матрицы имели «хорошую», каноническую форму. Такой выбор базиса может оказаться целесообразным, так как,
во-первых, канонические представления матриц системы имеют минимальное число ненулевых элементов и поэтому удобны для
моделирования и других вычислений, а во-вторых, канонические представления позволяют получить чрезвычайно простые
алгоритмы синтеза \ управления.
\end{russian}}

{\begin{russian}\sffamily
\ \ Рассмотрим перевод уравнений (3.6.1) в некоторый новый базис  $[f]$. Отметим при этом, что, переходя к новому базису
в пространстве состояний, преобразовывая базис для пространства вектора состояний, не будем изменять базис пространства
входов и пространства выходов системы. Заменим в (3.6.1) \  $\vec x_e$ на  $\vec x_f$ согласно (3.5.12):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}F_e\cdot \vec{\dot x}_f=A_e\cdot F_e\vec x_f+B_e\vec u\;;\hfill\null \\\vec y=C_eF_e\vec
x_f\;.\hfill\null \end{matrix}\hfill $\ \ (3.6.6)
\end{russian}}

{\begin{russian}\sffamily
Умножая слева обе части дифференциального уравнения на  $F^{-1}$, получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}_f=F_e^{-1}A_eF_e\vec x_f+F_e^{-1}B_e\vec u$.\ \ (3.6.7)
\end{russian}}

{\begin{russian}\sffamily
Учитывая (3.5.15) и вводя дополнительные обозначения
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}A_f=F_e^{-1}\cdot A_e\cdot F_e\;;\hfill\null \\B_f=F_e^{-1}\cdot B_e\;;\hfill\null
\\C_f=C_e\cdot F_e\;,\hfill\null \end{matrix}\hfill $\ \ (3.6.8)
\end{russian}}

{\begin{russian}\sffamily
окончательно получаем уравнения системы в базисе  $[f]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot x}_f=A_f\dot x_r+B_f\cdot \vec u\left(t\right)\;;\hfill\null \\\vec{\dot
y}\left(t\right)=C_f\cdot \vec x_f\left(t\right)\;.\hfill\null \end{matrix}\hfill $\ \ (3.6.9)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.6.1. Пусть система задана схемой моделирования, приведенной на рис. 3.5. Выберем в качестве координат вектора
состояний  $\vec x$ в исходном базисе  $[e]$ $ $ выходы интеграторов 1 и 2. В результате получим уравнения системы в
исходном базисе:
\end{russian}}

\begin{equation*}
\begin{matrix}\vec{\dot x}_e(t)=A_e\vec x_e(t)+B_e\cdot \vec u(t)\;;\hfill\null \\\vec y(t)=C_e\cdot \vec
x_e(t)\;,\hfill\null \end{matrix}\hfill 
\end{equation*}

\bigskip


\bigskip

{\centering  \includegraphics[width=12.764cm,height=5.106cm]{1-img075.pdf} \par}

\bigskip

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_e=\left[\begin{matrix}1&-1\\1&-1\end{matrix}\right]$ ; \ \ \ \ 
$B_e=\left[\begin{matrix}1\\0\end{matrix}\right]$ ; \ \ \ \ \  $C_e=\left[\begin{matrix}0&1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Зададим матрицу перехода к новому базису
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=\left[\begin{matrix}1&1\\1&0\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
которой соответствуют уравнения 
\end{russian}}

\begin{equation*}
\begin{matrix}\vec f_1=\vec e_1+\vec e_2\;;\hfill\null \\\vec f_2=\vec e_1\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Вычислим \ обратную матрицу 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e^{-1}=\left[\begin{matrix}0&1\\1&-1\end{matrix}\right]$ .
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (3.6.8) находим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_f=\left[\begin{matrix}0&1\\0&0\end{matrix}\right]$; \ \ \ \ 
$B_f=\left[\begin{matrix}0\\1\end{matrix}\right];$ \ \ \  $C_f=\left[\begin{matrix}1&0\end{matrix}\right]$ .
\end{russian}}

{\begin{russian}\sffamily
Этим матрицам соответствуют уравнения
\end{russian}}

\begin{equation*}
\begin{matrix}\dot x_{f_1}=x_{f_2}\;;\hfill\null \\\dot x_{f_2}=u\;;\hfill\null \\y=x_{f_1}\;,\hfill\null
\end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
которым, в свою очередь, отвечает схема, приведённая на рис. 3.6.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=8.214cm,height=4.023cm]{1-img076.png} \par}
{\begin{russian}\sffamily
Собственные числа системы, естественно, сохранились, так как матрицы $А_l$ \ и  $A_f$ подобны. Связь между входом \ и
выходом осталась неизменной, а схема моделирования стала заметно проще. 
\end{russian}}

\subsection[Вычисление матрицы преобразования базиса в \ \ \ \ \ \ \ пространстве состояний динамической системы
\ \ \ \ с помощью матриц управляемости и наблюдаемости]{Вычисление матрицы преобразования базиса в
\ \ \ \ \ \ \ пространстве состояний динамической системы \ \ \ \ с помощью матриц управляемости и наблюдаемости}
\hypertarget{RefHeadingToc455659737}{}{\begin{russian}\sffamily
Пусть матрицы управляемой системы представлены в двух различных базисах  $[e]$ и  $[f]$ в пространстве состояний вектора
 $\vec x$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\left\{A_e\boldsubformula{\text{,B}}_e\right\},\text{   }\left\{A_f\boldsubformula{\text{,B}}_f\right\}$.\ \ 
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим матрицу управляемости
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_f=\left[\begin{matrix}B_f&A_fB_f&A_f^2B_f&...&A_f^{n-1}B_f\end{matrix}\right]$.\ \ (3.7.1)
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (3.6.8)
\end{russian}}

{\begin{russian}\sffamily
\ \  $A_fB_f=F_e^{-1}A_eB_e$;
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_f^2B_f=F_e^{-1}A_eF_eF_e^{-1}A_eF_eF_e^{-1}B_e=?F_e^{-1}A_e^2B_e$;
\end{russian}}

{\begin{russian}\sffamily
\ \ ………….
\end{russian}}

{\begin{russian}\sffamily
\ \  $A_f^k=F_e^{-1}A_e^kB_e$.\ \ \ \ \ \ (3.7.2)
\end{russian}}

{\begin{russian}\sffamily
Учитывая эти равенства в (3.7.1), получим выражение для перевода матрицы управляемости из одного базиса в другой:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_f=F_e^{-1}U_e$.\ \ (3.7.3)
\end{russian}}

{\begin{russian}\sffamily
Умножая это равенство справа на  $U_e^T$, полу­чаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_fU_e^T=F_e^{-1}U_eU_e^T$.\ \ (3.7.4)
\end{russian}}

{\begin{russian}\sffamily
Если система управляема, то  $\normalsubformula{\text{rank}}\;U_e=\normalsubformula{\text{rank}}\;U_f=n$\textit{.} Это
значит, что матрица  $U_e$ имеет  $n$\textit{ }линейно независимых строк и может быть представлена в виде
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_e=\left[\begin{matrix}\vec z_1^T\\\vec z_2^T\\...\\\vec z_n^T\end{matrix}\right]$,\ \ (3.7.5)
\end{russian}}

{\begin{russian}\sffamily
где векторы  $\vec z_1,\vec z_2...\vec z_n$– линейно независимы. Следовательно, матрица
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_eU_e^T=\left[\begin{matrix}\vec z_1^T\\\vec z_2^T\\...\\\vec z_n^T\end{matrix}\right]\cdot \left[\vec
z_1\text{   \{}\vec{\normalsubformula z}?_2...\vec z_n\right]$,\ \ (3.7.6)
\end{russian}}

{\begin{russian}\sffamily
которая является матрицей Грама, имеет положительный определитель, а значит, – невырождена. Следовательно,
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e^{-1}=U_fU_e^T(U_eU_e^T)^{-1}$.\ \ (3.7.7)
\end{russian}}

{\begin{russian}\sffamily
Если система имеет скалярный вход (\textit{u}-скаляр), то матрица  $B$ ста­новится вектором  $(B=\vec b)$, а матрица 
$U_e$– квадратной, в управляемой системе – невырожденной. Тогда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e^{-1}=U_fU_e^{-1}$.\ \ (3.7.8)
\end{russian}}

{\begin{russian}\sffamily
Отметим, \ что в данном рассуждении  $F_e$\textit{ – }матрица перехода от базиса  $[e]$ к базису  $[f]$, поэтому
обратная ей - это матрица перехода от базиса  $[f]$ к базису  $[e]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e^{-1}=?E_f$.\ \ (3.7.9)
\end{russian}}

{\begin{russian}\sffamily
\ \ Рассмотрим другой случай, когда переход от базиса  $[e]$ к базису  $[f]$ задан парой матриц
\end{russian}}

\begin{equation*}
\left\{A_e\boldsubformula{\text{,C}}_e\right\},\text{   }\left\{A_f\boldsubformula{\text{,C}}_f\right\}
\end{equation*}
{\begin{russian}\sffamily
некоторой наблюдаемой системы. Запишем матрицу наблюдаемости (3.3.7) и с учётом (3.6.8) проведём аналогичные предыдущим
преобразования:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $N_f=\left[\begin{matrix}C_f\\C_fA_f\\\cdot \cdot \cdot
\\C_fA_f^{n-1}\end{matrix}\right]=\left[\begin{matrix}C_eF_e\\C_eA_eF_e\\\\C_eA_e^{n-1}F_e\end{matrix}\right]=N_eF_e$.\ \ (3.7.10)
\end{russian}}

{\begin{russian}\sffamily
Так как система наблюдаема, то 
\end{russian}}

\begin{equation*}
\normalsubformula{\text{rank}}(N_e)=\normalsubformula{\text{rank}}(N_f)=n
\end{equation*}
{\begin{russian}\sffamily
и матрица наблюдаемости имеет  $n$ линейно независимых столбцов
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $N=\left[\begin{matrix}\vec z_1&\vec z_2&\cdot \cdot \cdot &\vec z_n\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
а квадратная матрица
\end{russian}}

\begin{equation*}
N^TN=\left[\begin{matrix}\vec z_1^T\\\vec z_2^T\\\cdot \cdot \cdot \\\vec
z_n^T\end{matrix}\right]\left[\begin{matrix}\vec z_1&\vec z_2&\cdot \cdot \cdot &\vec z_n\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
не вырождена. Умножим обе части равенства (3.7.10) слева на  $N_e^T$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $N_e^TN_f=N_e^TN_eF_e$,\ \ (3.7.11)
\end{russian}}

{\begin{russian}\sffamily
откуда получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=(N_e^TN_e)^{-1}N_e^TN_f$.\ \ (3.7.12)
\end{russian}}

{\begin{russian}\sffamily
Если система имеет скалярный выход, то
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=N_e^{-1}N_f$.\ \ (3.7.13)
\end{russian}}

\subsection{Канонические представления систем}
\hypertarget{RefHeadingToc455659738}{}\subsubsection[Управляемое каноническое представление системы \ \ 
\ \ \ \ \ \ \ \ со ска­лярным входом]{Управляемое каноническое представление системы \ \  \ \ \ \ \ \ \ \ со ска­лярным
входом}
\hypertarget{RefHeadingToc455659739}{}
\bigskip

{\begin{russian}\sffamily
Пусть в некотором исходном базисе  $[h]$ пространства состояний  $X$ записаны уравнения движения объекта со скалярным
управлением:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}_h(t)=A_h\vec x_h(t)+\vec b_hu(t)$;\ \ (3.8.1)
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec y(t)=C_h\vec x_h(t)$.\ \ (3.8.2)
\end{russian}}

{\begin{russian}\sffamily
Более общая запись связывает не координатные столбцы, а сами векторы в  $\vec x\in X$ с помощью соответствующего
оператора  $A$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}(t)=A(\vec{}x(t))+\vec b\cdot u(t)$.\ \ (3.8.3)
\end{russian}}

{\begin{russian}\sffamily
Если система  $\left\{A\;\text{,   \{}\vec{\normalsubformula b}?\right\}$ управляема, то \textit{n }векторов  $\vec
b\;,\;\;A(\vec{}b),\;\;...\;,\;\;\;A^{n-1}(\vec b)$ образуют базис в пространстве \textit{X} в силу того, что 
$\normalsubformula{\text{rank}}\;U=n$. Следовательно, в пространстве \textit{X} в качестве базиса может быть выбрана
следующая сис­тема векторов:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\left\{\vec e_1=\vec b;?\right.\left\{\vec e_2=A(\vec{}b);?\right.\left\{\vec e_3=A^2(\vec
b);?\right.\left\{............?\right.\left\{\vec e_n=A^{n-1}(\vec b).?\right.\mathit{no}\hfill\null
\end{matrix}\{\;?$\ \ (3.8.4)
\end{russian}}

{\begin{russian}\sffamily
Пусть характеристический полином оператора  $A$, а значит, и его матрицы в преобразованном базисе имеет вид:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ϕ_A\left(λ\right)=λ^n+α_1λ^{n-1}+...+α_{n-1}λ+α_n$.\ \ (3.8.5)
\end{russian}}

{\begin{russian}\sffamily
Построим ещё один базис - базис  $[u]$ следующим образом:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\vec u_1=α_{n-1}\underbrace{\vec b}_{e_1}+α_{n-2}\underbrace{A(\vec b)}_{e_2}+\ldots
+α_1\underbrace{A^{n-2}(\vec b)}_{e_{n-1}}\underbrace{+A^{n-1}(\vec b)}_{e_n};\hfill\null \\\vec
u_2=α_{n-2}\underbrace{\vec b}_{e_1}+α_{n-3}\underbrace{A(\vec b)}_{e_2}+\ldots +α_1\underbrace{A^{n-3}(\vec
b)}_{e_{n-2}}\underbrace{+A^{n-2}(\vec b)}_{e_{n-1}};\hfill\null \\\vec u_3=α_{n-3}\underbrace{\vec
b}_{e_1}+α_{n-4}\underbrace{A(\vec b)}_{e_2}+\ldots +α_1\underbrace{A^{n-4}(\vec b)}_{e_{n-3}}\underbrace{+A^{n-3}(\vec
b)}_{e_{n-2}};\hfill\null \\\cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots
\cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \hfill\null \\\vec u_{n-2}=α_2\underbrace{\vec
b}_{e_1}+α_1\underbrace{A(\vec b)}_{e_2}\underbrace{+A^2(\vec b)}_{e_3};\hfill\null \\\vec u_{n-1}=α_1\underbrace{\vec
b}_{e_1}+\underbrace{A(\vec b)}_{e_2};\hfill\null \\\vec u_n=\underbrace{\vec b}_{e_1}.\hfill\null \end{matrix}\hfill
$\ \  (3.8.6)
\end{russian}}

{\begin{russian}\sffamily
Проверим, действительно ли это базис? Матрица перехода от базиса  $[e]$ к базису  $[u]$ в соответствии с (3.4.4) и
(3.4.5) имеет вид
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \ 
$U_e=\left[\begin{matrix}α_{n-1}&α_{n-2}&α_{n-3}&...&α_2&α_1&1\\α_{n-2}&α_{n-3}&α_{n-4}&...&α_1&1&0\\α_{n-3}&α_{n-4}&α_{n-5}&...&1&0&0\\...&...&...&...&...&...&...\\α_2&α_1&1&...&0&0&0\\α_1&1&0&...&0&0&0\\1&0&0&...&0&0&0\end{matrix}\right]$.\ \ (3.8.7)
\end{russian}}

{\begin{russian}\sffamily
Эта матрица является треугольной, её определитель равен про­изведению диагональных элементов, умноженному на  $(-1)^n$,
т.е. не ра­вен нулю. Следовательно,  $U_e$ не вырождена и система векторов  $\left\{\vec u_1\text{  
\{}\vec{\normalsubformula u}?_2...\vec u_n\right\}$ действительно образует базис в пространстве \textit{X}.
\end{russian}}

{\begin{russian}\sffamily
Вычислим теперь представление матрицы оператора  $A$ в базисе  $[u]$. При этом воспользуемся равенством
\end{russian}}

{\begin{russian}\sffamily
\ \  $A\left(\vec u_k\right)=a_{1k}^u\vec u_1+a_{2k}^u\vec u_2+...+a_{\normalsubformula{\text{nk}}}^u\vec u_n=\overset
n{\underset{i=1}{\sum }}a_{\normalsubformula{\text{ik}}}^uA(\vec u_i)$.\ \ (3.8.8)
\end{russian}}

{\begin{russian}\sffamily
С учётом (3.8.6)
\end{russian}}

{\begin{russian}\sffamily
 $\begin{matrix}A\left(\vec u_1\right)=?A^n(\vec b)+α_1A^{n-1}(\vec b)+...+α_{n-1}A(\vec{}b)+α_n\vec b-α_n\vec
b=\hfill\null \\=\left(A^n+α_1A^{n-1}+...+α_{n-1}A+α_nE\right)(\vec b)-α_n\vec b=\hfill\null \\=ϕ_A(A(\vec b))-α_n\vec
b.\hfill\null \end{matrix}\hfill $\ \ (3.8.9)
\end{russian}}

{\begin{russian}\sffamily
По теореме Кэлли-Гамильтона  $ϕ_A(A)=0$, а значит,  $A(\vec u_1)=-α_n\vec b$, откуда следует, что 
$a_{\mathit{n1}}^u=-α_n$ и  $a_{\mathit{i1}}^u=0$ \ при  $i<n$, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec a_{\mathit{u1}}^T=[00...0-α_n]$.\ \ (3.8.10)
\end{russian}}

{\begin{russian}\sffamily
Далее действуем аналогичным образом:
\end{russian}}

{\begin{russian}\sffamily
 $A(\vec u_2)=\underbrace{A^{n-1}(\vec b)+α_1A^{n-2}(\vec b)+...+α_{n-2}A(\vec b)+α_{n-1}\vec b}_{\vec
u_1}-α_{n-1}\underbrace{\vec b}_{\vec u_n}$,\ \ (3.8.11)
\end{russian}}

{\begin{russian}\sffamily
откуда следует, что  $a_{12}^u=1\normalsubformula{\text{,   a}}_{\mathit{i2}}^u=0\text{ при }1<i<n;\text{  
}a_{\mathit{n2}}^u=-α_{n-1}$, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec a_{\mathit{u2}}^T=[\text{0 1 }...\text{ 0}-α_{n-1}]$.
\end{russian}}

{\begin{russian}\sffamily
Далее:\ \ 
\end{russian}}

{\begin{russian}\sffamily
 $A(\vec u_3)=\underbrace{A^{n-2}(\vec b)+α_1A^{n-3}(\vec b)+...+α_{n-3}A(\vec b)+α_{n-2}\vec b}_{\vec
u_2}-α_{n-2}\underbrace{\vec b}_{\vec u_n}$,\ \ (3.8.12)
\end{russian}}

{\begin{russian}\sffamily
откуда следует, что
\end{russian}}

{\begin{russian}\sffamily
\ \   $a_{13}^u=0\normalsubformula{\text{;   a}}_{23}^u=1\normalsubformula{\text{;  a}}_{\mathit{i3}}^u=0\text{  при
2}<i<n;\text{   }a_{\mathit{n3}}^u=-α_{n-2}$,
\end{russian}}

{\begin{russian}\sffamily
то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec a_{\mathit{u3}}^T=[\text{0 0 1 0 }...\text{ 0}-α_{n-2}]$.
\end{russian}}

{\begin{russian}\sffamily
Вычислим предпоследний столбец матрицы:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A(\vec u_{n-1})=\underbrace{A^2(\vec b)+α_1A(\vec b)+α_2\vec b}_{\vec u_{n-2}}-α_2\underbrace{\vec b}_{\vec
u_n}$,\ \ (3.8.13)
\end{russian}}

{\begin{russian}\sffamily
откуда следует, что  $a_{\normalsubformula{\text{i,n-}}1}^u=0$ для  $1\le i<n-2$, \ 
$a_{n-2\normalsubformula{\text{,n}}-1}^u=1$,  $a_{\normalsubformula{\text{n-}}1\normalsubformula{\text{,n-}}1}^u=0$ и 
$a_{\normalsubformula{\text{n,n-}}1}^u=-α_2$, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec a_{u\;n-1}^T=\left[\begin{matrix}0&0&\cdot \cdot \cdot &0&1&0&-α_{n-2}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Наконец,
\end{russian}}

{\begin{russian}\sffamily
\ \  $A\left(\vec u_n\right)=?A(\vec{}b)+α_1\vec b-α_1\vec b=\vec u_{n-1}-α_1\vec u_n$,\ \ (3.8.14)
\end{russian}}

{\begin{russian}\sffamily
откуда следует, что  $a_{\normalsubformula{\text{i,n}}}^u=0$ для  $1\le i<n-1\;и\normalsubformula{\text{
a}}_{n-1\normalsubformula{\text{,n}}}^u=1,\normalsubformula{\text{  a}}_{\normalsubformula{\text{n,n}}}^u=-α_2$,
\end{russian}}

{\begin{russian}\sffamily
то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec a_{\normalsubformula{\text{un}}}^T=\left[\begin{matrix}0&0&\cdot \cdot \cdot
&0&1&-α_1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, матрица  $A_U$ оператора  $A$ в базисе  $[u]$ имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$A_U=\left[\begin{matrix}0&1&0&...&0\\0&0&1&...&0\\0&0&0&...&0\\...&...&...&...&...\\0&0&0&...&0\\0&0&0&...&1\\-α_n&-α_{n-1}&-α_{n-2}&...&-α_1\end{matrix}\right]$.\ \ (3.8.15)
\end{russian}}

{\begin{russian}\sffamily
Так как  $\vec b=\vec u_n$, то есть является последним вектором базиса  $[u]$, то координатный столбец вектора  $\vec b$
в этом базисе
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec b_u^T=[\text{0 0 0 }...\text{ 0 0 1}]$.\ \ (3.8.16)
\end{russian}}

{\begin{russian}\sffamily
\textit{Пара } $\left\{A_U\;,\vec b_U\right\}$\textit{ называется управляемым каноническим представле­нием (УКП) системы
с одним (скалярным) входом. Матрица } $A_U$\textit{ называется сопровождающей по отношению к полиному }
$ϕ_A(λ)$\textit{.}
\end{russian}}

{\begin{russian}\sffamily
\ \ Таким образом, мы доказали, что если \textit{исходная система управ­ляема, то в пространстве состояний Х существует
базис, в котором пара } $\left\{Α,\vec b\right\}$\textit{ имеет управляемое каноническое представление}. 
\end{russian}}

{\begin{russian}\sffamily
Если \ \ в \ некотором \ исходном \ базисе  $[h]$ заданы матрицы  $A_H\text{,   \{}\vec{\normalsubformula b}_H$ \ и если
система управляема, то для того, чтобы вычислить их (матриц) УКП, достаточно вычислить коэффициенты
характеристичес­кого полинома  $ϕ_A(λ)$. После этого может быть вычислена матрица пре­образования от исходного базиса 
$[h]$ к УКП в соответствии с (3.7.8):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_H^{-1}=U_UU_H^{-1}$. \ \ (3.8.17)
\end{russian}}

{\begin{russian}\sffamily
Далее индекс \textit{“h” }для системы в исходном базисе будем опускать.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.8.1. Для системы
\end{russian}}

\begin{equation*}
\begin{matrix}\vec{\dot x}=A\vec x+\vec bu\;;\hfill\null \\y=C\vec x\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
известны матрицы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A=\left[\begin{matrix}2&3\\4&5\end{matrix}\right],\ \vec b=?\begin{matrix}\left[1?\right].\end{matrix}$.
\end{russian}}

{\begin{russian}\sffamily
Нетрудно вычислить матрицу 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U\equiv U_H=\left[\begin{matrix}1&8\\2&14\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Её определитель  $|U|=-2\neq 0$, откуда следует, что система управляема и, значит, для неё существует \ УКП. Вычислим
характеристический полином:
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$ϕ_A\left(λ\right)=|\mathit{λE}-A|=\left[\begin{matrix}λ-2&-3\\-4&λ-5\end{matrix}\right]=λ^2\;\underbrace{-7}_{α_1}λ\;\;\underbrace{-2}_{α_2}$.
\end{russian}}

{\begin{russian}\sffamily
Это позволяет сразу же записать матрицы \textit{A} и\textit{ B} в базисе УКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \   $A_U=\left[\begin{matrix}0&1\\2&7\end{matrix}\right],\text{      \{}\vec{\normalsubformula
b}_U=\left[\begin{matrix}0\\1\end{matrix}\right]$.
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Векторно-матричные уравнения системы в УКП имеют вид
\end{russian}}

\begin{equation*}
\begin{matrix}\vec{\dot x}_u=A_u\vec x_u+\vec b_uu;\hfill\null \\y=C_u\vec x_u.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Для того чтобы найти матрицу  $C_U$, требуется рассчитать матрицу перехода от исходного базиса к базису УКП. Для этого
предварительно вычислим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_H^{-1}=\left[\begin{matrix}-7&4\\1&-0.5\end{matrix}\right]$ \ \ и \ \ 
$U_U=\left[\begin{matrix}0&1\\1&7\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Тогда искомая матрица
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$U_H^{-1}=\left[\begin{matrix}0&1\\1&7\end{matrix}\right]\left[\begin{matrix}-7&4\\1&-1/2\end{matrix}\right]=\left[\begin{matrix}1&-1/2\\0&1/2\end{matrix}\right]$
, \  $U_H=\left[\begin{matrix}1&1\\0&2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
После этого в соответствии с (3.6.8) находим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_U=C_HU_H=\left[\begin{matrix}1&3\end{matrix}\right]$ .
\end{russian}}


\bigskip

\subsubsection[Передаточная функция и структурная схема для системы \ \ \ \ \ \ \ \ в УКП]{Передаточная функция и
структурная схема для системы \ \ \ \ \ \ \ \ в УКП}
\hypertarget{RefHeadingToc455659740}{}{\begin{russian}\sffamily
Уравнения системы 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot x}_U(t)=A_U\vec x_U(t)+\vec b_Uu(t)\hfill\null \\y(t)=C_Ux_U(t)\hfill\null
\end{matrix}\hfill $\ \ (3.8.18)
\end{russian}}

{\begin{russian}\sffamily
со скалярным входом  $u(t)$ и скалярным выходом  $y(t)$, где матрицы  $A_U$ и  $\vec b_U$ определяются выражениями
(3.8.15) и (3.8.16), а матрица  $C_U$ имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $C_U=\left[\begin{matrix}c_{\mathit{u1}}&c_{\mathit{u2}}&\cdots
&c_{\normalsubformula{\text{un}}}\end{matrix}\right]$,\ \ (3.8.19)
\end{russian}}

{\begin{russian}\sffamily
можно записать в развёрнутом виде :
\end{russian}}

{\begin{russian}\sffamily
 $\begin{matrix}\dot x_{u\;1}=x_{u\;2};\hfill\null \\\dot x_{u\;2}=x_{u\;3};\hfill\null \\\dot
x_{u\;3}=x_{u\;4};\hfill\null \\.........\hfill\null \\\dot x_{u\;n-1}=x_{u\;n};\hfill\null \\\dot
x_{u\;n}=-α_nx_{u\;1}-α_{n-1}x_{u\;2}-...-α_2x_{u\;n-1}-α_1x_{u\;n}+u\;;\hfill\null \end{matrix}\hfill $\ \ (3.8.20)
\end{russian}}

{\begin{russian}\sffamily
 $y=c_{u\;\;1}x_{u\;1}+c_{u\;2}x_{\mathit{u2}}+...+c_{u\;n}x_{u\;n}$.\ \ (3.8.21)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Этим уравнениям соответствует схема, представленная на рис.3.7.
\end{russian}}

{\centering  \includegraphics[width=15.78cm,height=9.364cm]{1-img077.png} \par}

\bigskip

{\begin{russian}\sffamily
В соответствии с этим рисунком передаточная функция системы имеет вид\ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$\begin{matrix}W(p)=\frac{c_{u\;1}p^{-n}+c_{u\;2}p^{-\left(n-1\right)}+...+c_{u\;n-1}p^{-2}+c_{u\;n}p^{-1}}{1+α_1p^{-1}+α_2p^{-2}+...+α_np^{-n}}=\hfill\null
\\\text{       
}=\frac{c_{u\;1}+c_{u\;2}p+...+c_{u\;n-1}p^{n-2}+c_{u\;n}p^{n-1}}{p^n+α_1p^{n-1}+α_2p^{n-2}+...+α_{n-1}p+α_n}.\hfill\null
\end{matrix}\hfill $\ \ (3.8.22)
\end{russian}}

{\begin{russian}\sffamily
Отметим, что статический передаточный коэффициент
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W(0)=\frac{c_{u\;1}}{α_n}$.\ \ (3.8.23)
\end{russian}}


\bigskip

\subsubsection[Идентификационное каноническое представление системы \ \ \ \ с одним (скалярным)
выходом]{Идентификационное каноническое представление системы \ \ \ \ с одним (скалярным) выходом}
\hypertarget{RefHeadingToc455659741}{}
\bigskip

{\begin{russian}\sffamily
С помощью рассуждений, аналогичных проведённым в п.3.8.1, можно получить следующие результаты.
\end{russian}}

{\begin{russian}\sffamily
\textit{Если пара матриц \ } $\left\{A,\;C\right\}$\textit{ полностью наблюдаема, \ то \ в \ \ прост­ра­нстве состояний
\ Х \ всегда существует базис, в котором пара } $\left\{A,\;C\right\}$\textit{ имеет идентификационное каноническое
представление (ИКП):}
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$A_I=\left[\begin{matrix}0&0&...&0&0&-α_n\\1&0&...&0&0&-α_{n-1}\\0&1&...&0&0&-α_{n-2}\\...&...&...&...&...&...\\0&0&...&0&0&-α_3\\0&0&...&1&0&-α_2\\0&0&...&0&1&-α_1\end{matrix}\right]$;\ \ (3.8.24)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_I=\left[\begin{matrix}0&0&...&0&0&1\end{matrix}\right]$.\ \ (3.8.25)
\end{russian}}

{\begin{russian}\sffamily
Отметим, что
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_I^T=A_U\text{;      }C_I^T=\vec b_U$.\ \ (3.8.26)
\end{russian}}

{\begin{russian}\sffamily
Если \ \ в \ некотором \ исходном \ базисе  $[h]$ заданы матрицы  $A_H\text{,  C}_H$ \ и если система полностью
наблюдаема, то, для того чтобы вычислить их (матриц) ИКП, достаточно вычислить коэффициенты характеристичес­кого
полинома  $ϕ_A(λ)$. После этого может быть вычислена матрица пре­образования от исходного базиса  $[h]$ к ИКП в
соответствии с (3.7.13):
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $I_H^{-1}=N_I^{-1}N_H$. \ \ (3.8.27)
\end{russian}}

{\begin{russian}\sffamily
\ \ Если известна матрица  $B_H$ при векторе управления в исходном базисе, то с учётом (3.6.8) \ в базисе ИКП она может
быть определена с помощью соотношения
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $B_I=I_H^{-1}B_H$.\ \ (3.8.28) 
\end{russian}}


\bigskip

\subsubsection{Передаточная функция и структура для системы в ИКП}
\hypertarget{RefHeadingToc455659742}{}{\begin{russian}\sffamily
В соответствии с видом матриц  $A_I$ и  $C_I$ уравнения системы со скалярным входом  $u$ и скалярным выходом  $y$ имеют
вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\left\{\begin{matrix}\dot x_{i\;1}=-α_nx_{i\;n}+b_{i\;1}u\;;\\\dot
x_{i\;2}=x_{i\;1}-α_{n-1}x_{i\;n}+b_{i\;2}u\;;\\\dot x_{i\;3}=x_{i\;2}-α_{n-2}x_{i\;n}+b_{i\;3}u\;;\\...\text{  
}...\text{   }...\text{   }...\text{   }...\text{   }...\text{   }\\\dot
x_{i\;n-1}=x_{i\;n-2}-α_2x_{i\;n}+b_{i\;n-1}u\;;\\\dot
x_{i\;n}=x_{i\;n-1}-α_1x_{i\;n}+b_{i\;n}u\;;\end{matrix}\right.$\ \ \ \ (3.8.29)
\end{russian}}

{\begin{russian}\sffamily
\ \  $y=x_{i\;n}$.\ \ \ \ (3.8.30)
\end{russian}}

{\begin{russian}\sffamily
Этим уравнениям соответствует структурная схема, представле­нная на рис. 3.8.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=17.023cm,height=8.382cm]{1-img078.png} \par}
{\begin{russian}\sffamily
В соответствии с этим рисунком передаточная функция системы имеет вид\ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$\begin{matrix}W_{u,y}(p)=\frac{b_{i\;1}\;p^{-n}+b_{i\;2\;}p^{-\left(n-1\right)}+...+b_{i\;n-1}\;p^{-2}+b_{i\;n}\;p^{-1}}{1+α_1\;p^{-1}+α_{2\;}p^{-2}+...+α_n\;p^{-n}}=\hfill\null
\\\text{      
}=\frac{b_{i\;1}+b_{i\;2}\;p+...+b_{i\;n-1}\;p^{n-2}+b_{i\;n\;}p^{n-1}}{p^n+α_1\;p^{n-1}+α_2\;p^{n-2}+...+α_{n-1}\;p+α_n}\;\;\;.\hfill\null
\end{matrix}\hfill $\ \ (3.8.31)
\end{russian}}

{\begin{russian}\sffamily
Отметим, что статический передаточный коэффициент
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_{u,y}(0)=\frac{b_{i\;1}}{α_n}$.\ \ (3.8.32)
\end{russian}}

\clearpage\subsection[Обратная связь по состоянию, обеспечивающая \ \ \ \ \ \ \ \ \ \ заданное (желаемое) расположение
собственных чисел в замкнутой системе с одним \ (скалярным) входом ]{Обратная связь по состоянию, обеспечивающая
\ \ \ \ \ \ \ \ \ \ заданное (желаемое) расположение собственных чисел в замкнутой системе с одним \ (скалярным) входом
}
\hypertarget{RefHeadingToc455659743}{}{\begin{russian}\sffamily
Даны уравнения полностью управляемого объекта управления в некотором исходном базисе
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot x}_H(t)=A_H\vec x_H(t)+\vec b_Hu(t);\hfill\null \\y(t)=C_H\vec x_H(t)\;,\hfill\null
\end{matrix}\hfill $\ \ (3.9.1)
\end{russian}}

{\begin{russian}\sffamily
каждая координата вектора состояния которого доступна для измерения.
\end{russian}}

{\begin{russian}\sffamily
Требуется синтезировать такое управление, которое бы обеспе­чило требуемое качество отработки внешнего командного
сигнала  $v(t)$.
\end{russian}}

{\begin{russian}\sffamily
Динамические свойства системы управления в основном определяются её собственными числами, то есть нулями
характеристического полинома
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_A\left(λ\right)=\overset n{\underset{i=1}{\prod }}\left(λ-λ_i\right)=λ^n+α_1λ^{n-1}+...+α_n$.\ \ (3.9.2)
\end{russian}}

{\begin{russian}\sffamily
\ Время переходного процесса каждой моды определяется расстоянием до мнимой оси вещественной части; колебательность -
соотношением мнимой и вещественной частей соответствующих собственных чисел. Эти зависимости могут быть
проанализированы при изучении характеристик типовых звеньев, кроме того, они рассматриваются в обширной учебной
литературе по теории автоматического регулирования и управления.
\end{russian}}

{\begin{russian}\sffamily
В соответствии со структурной схемой, приведённой на рис. 3.9, сформируем сигнал управления объектом в виде
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $u(t)=L_H\vec x_H(t)+k^vv(t)$,\ \ (3.9.3)
\end{russian}}

{\begin{russian}\sffamily
где \  $L_H$ – некоторая матрица-строка обратной связи:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_H=\left[\begin{matrix}l_{h\;1}&l_{h\;2}&...&l_{h\;n}\end{matrix}\right]$;\ \ (3.9.4)
\end{russian}}

{\begin{russian}\sffamily
 $k^v$ – коэффициент по командному сигналу.
\end{russian}}

{\begin{russian}\sffamily
Тогда уравнение системы примет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot x}_H(t)=A_H\vec x_H(t)+\vec b_HL_H\vec x_H(t)+\vec b_Hk^vv(t)$,\ \ (3.9.5)
\end{russian}}

{\begin{russian}\sffamily
или
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}_H(t)=A_H^C\vec x_H(t)+\vec b_Hk^vv(t)$,\ \ (3.9.6)
\end{russian}}

{\begin{russian}\sffamily
где \  $A_H^C$- матрица замкнутой системы в исходном базисе:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_H^C=A_H+\vec b_HL_H$.\ \ (3.9.7)
\end{russian}}


\bigskip

{\centering  \includegraphics[width=10.16cm,height=6.509cm]{1-img079.png} \par}
{\begin{russian}\sffamily
Поскольку объект полностью управляем, то существует базис  $[u]$, в котором пара  $\left\{A,\vec b\right\}$ имеет
управляемое каноническое представление  $\left\{A_U,\vec b_U\right\}$. Поэтому перейдём к записи уравнений системы в
базисе УКП. В соответствии с (3.4.16) произведём замену 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\text{   \{}\vec{\normalsubformula x}_H=U_H\vec{}x_U$.\ \ (3.9.8)
\end{russian}}

{\begin{russian}\sffamily
Тогда из (3.9.1) получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_H\vec{\dot{}}x_U(t)=A_HU_H\vec{}x_U(t)+\vec b_Hu(t)$;\ \ (3.9.9)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $y(t)=C_HU_H\vec{}x_U$ .\ \ (3.9.10)
\end{russian}}

{\begin{russian}\sffamily
Умножив уравнение (3.9.9) слева на  $U_H^{-1}$, будем иметь
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot x}_U(t)=A_U\vec x_U(t)+\vec b_Uu(t)\;;\hfill\null \\y(t)=C_U\vec x_U(t)\;,\hfill\null
\end{matrix}\hfill $\ \ (3.9.11)
\end{russian}}

{\begin{russian}\sffamily
где  $A_U$  $\vec b_U$ и  $C_U$ - соответствующие матрицы в УКП.
\end{russian}}

{\begin{russian}\sffamily
\ \ Используя подстановку (3.9.8), из (3.9.3) получим 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $u(t)=L_U\vec x_U+k^vv(t)$,\ \ (3.9.12)
\end{russian}}

{\begin{russian}\sffamily
где матрица обратной связи в базисе УКП
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_U=L_HU_H$.\ \ (3.9.13)
\end{russian}}

{\begin{russian}\sffamily
В результате \ уравнение замкнутой системы \ в базисе управляемого канонического представле­ния будет иметь вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}_U(t)=A_U^C\vec x_U(t)+\vec b_U\cdot k^vv(t)$.\ \ (3.9.14)
\end{russian}}

{\begin{russian}\sffamily
Здесь  $A_U^C$ является сопровождающей матрицей по отношению к характеристическому полиному замкнутой системы
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_{A^C}\left(λ\right)=\overset n{\underset{i=1}{\prod }}\left(λ-λ_i^3\right)=λ^n+γ_1λ^{n-1}+...+γ_n$,\ \ (3.9.15)
\end{russian}}

{\begin{russian}\sffamily
поэтому она имеет стандартный вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $A_U^C=\left[\begin{matrix}0&1&0&\cdot \cdot \cdot &0\\0&0&1&\cdot \cdot \cdot &0\\\cdot \cdot \cdot &\cdot \cdot
\cdot &\cdot \cdot \cdot &\cdot \cdot \cdot &\cdot \cdot \cdot \\0&0&0&\cdot \cdot \cdot
&1\\-γ_n&-γ_{n-1}&-γ_{n-2}&\cdot \cdot \cdot &-γ_1\end{matrix}\right]$.\ \ (3.9.16)
\end{russian}}

{\begin{russian}\sffamily
С другой стороны, очевидно, что
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_U^C=A_U+\vec b_UL_U$.\ \ (3.9.17)
\end{russian}}

{\begin{russian}\sffamily
Отсюда сразу же следует связь между коэффициентами характеристического полинома (3.9.2) объекта и коэффициентами
характеристического полинома (3.9.14) желаемой системы:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $-γ_i=-α_i+l_{Un-i+1}\;,\;\;\;\;\;\;i=1\;,\;\;2\;,\;\;\ldots \;,\;\;n\;.$\ \ (3.9.18)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ Далее обусловлены следующие действия.
\end{russian}}

\liststyleWWviiiNumlxxx
\begin{enumerate}
\item {\begin{russian}\sffamily
Задание желаемых собственных чисел замкнутой системы  $λ_1^3,λ_2^3,...,λ_n^3$.
\end{russian}}
\item {\begin{russian}\sffamily
Вычисление коэффициентов характеристического полинома замкну­той системы  $γ_{1\;},\;\;γ_{2\;},\;\;...\;,\;γ_{n\;\;}$ в
соответствии с выражением (3.9.15).
\end{russian}}
\item {\begin{russian}\sffamily
Вычисление согласно (3.9.17) коэффициентов матрицы обратной связи в базисе УКП:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $l_{U,n-i+1}=α\multiscripts{_i}{{}}{{}}{}{}-γ_i,\text{   }i=1,2,...,n$.\ \ (3.9.19)
\end{russian}}

\liststyleWWviiiNumlxxx
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Вычисление в соответствии с (3.9.12) и (3.8.17) матрицы обратной связи в исходном базисе:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $L_H=L_UU_UU_H^{-1}$.\ \ (3.9.20)
\end{russian}}

\liststyleWWviiiNumlxxx
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Определение величины коэффициента  $k^v$ в соответствии с требова­ниями по статике.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
Так, например, если требуется обеспечить единичную статику по командному сигналу  $v$, то это значит, что установившееся
значение пе­реходной функции  $h(t)$ замкнутой системы должно быть равно единице. Одним из свойств передаточной функции
устойчивой системы является равенство
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\underset{t\rightarrow \infty }{\text{lim}}h(t)=\underset{p\rightarrow
0}{\text{lim}}W_{\normalsubformula{\text{vy}}}(p)$.\ \ (3.9.21)
\end{russian}}

{\begin{russian}\sffamily
Согласно структурной схеме, приведённой на \ рис. 3.9, передаточная функция между командным  $v$ и выходным  $y$
сигналами имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  \ \  $W_{\normalsubformula{\text{vy}}}(p)=k^v\cdot W(p)$,\ \ (3.9.22)
\end{russian}}

{\begin{russian}\sffamily
где передаточная функция  $W(p)$ может быть определена аналогично выражению (3.8.22). Таким образом, получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $h\left(\infty \right)=k^v\frac{c_{\mathit{U1}}}{γ_n}=1$,\ \ (3.9.23)
\end{russian}}

{\begin{russian}\sffamily
откуда, окончательно,
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $k^v=\frac{γ_n}{c_{\mathit{U1}}}$.\ \ (3.9.24)
\end{russian}}

\clearpage\subsection{Синтез управления в многомерной системе. Задача разделения каналов}
\hypertarget{RefHeadingToc455659744}{}
\bigskip

{\begin{russian}\sffamily
В предыдущих разделах, посвящённых синтезу, рассматривались объекты со скалярным управлением (входом) и скалярным
выходом. На практике встречаются и более сложные объекты. Один из них был упомянут в разделе 2.2. Это смесительный бак,
у него две входные величины (два входных потока с различными концентрациями растворённого вещества) и две выходные
(концентрация и расход выходного потока). В качестве другого примера может быть взят объект, связанный с перемоткой
некоторой полосы с одного рулона на другой. Для этого объекта выходные переменные – это натяжение и линейная скорость
перемотки; входные – напряжения или токи приводных двигателей моталки и разматывателя. Наконец, самолёт. В качестве
выходных переменных могут выступать углы тангажа, курса и крена; в качестве входных, управляющих - угловые положения
руля высоты, руля направления и элеронов.
\end{russian}}

{\begin{russian}\sffamily
\ Как правило, в таких объектах каждая выходная величина зависит от всех входных. В то же время при синтезе управления
такими объектами часто требуется обеспечить не только заданные динамические и статические свойства системы, но и
независимое управление по каждой из выходных переменных.
\end{russian}}

{\begin{russian}\sffamily
Пусть уравнения объекта имеют вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot x}(t)=A\vec x(t)+B\vec u(t)$;\ \ (3.10.1)
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec y(t)=C\vec x(t)$,\ \ (3.10.2)
\end{russian}}

{\begin{russian}\sffamily
где размерность вектора состояния  $[n\times 1]$, вектор управления и вектор выхода имеют одинаковую размерность 
$[p\times 1]$. Такую же размерность имеет вектор командного сигнала  $\vec v$, поступающий на вход системы. 
\end{russian}}

{\begin{russian}\sffamily
Требуется синтезировать управление  $\vec u$ такое, чтобы:
\end{russian}}

{\begin{russian}\sffamily
1) \textit{i }–я составляющая вектора выхода  $y_i$ зависела только от \textit{i} –й составляющей командного сигнала 
$v_i$;
\end{russian}}

{\begin{russian}\sffamily
2) по каждому из каналов была обеспечена заданная динамика, иными словами, передаточная функция 
$W_{v_i,y_i}(p)=\frac{Y_i(p)}{V_i(p)}$, имеющая заданные полюсы;
\end{russian}}

{\begin{russian}\sffamily
3) для каждого из каналов был обеспечен заданный статический коэффициент передачи.
\end{russian}}


\bigskip

\subsubsection{Разделение исходного объекта на подсистемы интеграторов}
\hypertarget{RefHeadingToc455659745}{}{\begin{russian}\sffamily
Представим (3.10.2) в виде
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec y=C\vec x=\left[\begin{matrix}C_1\\C_2\\\vdots \\C_p\end{matrix}\right]\vec x$,
\end{russian}}

{\begin{russian}\sffamily
где  $C_i$- строки матрицы  $C$. Тогда  $i$-я координата вектора выхода
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $y_i=C_i\vec x$.
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим процедуру многократного дифференцирования координат вектора выхода:
\end{russian}}

{\begin{russian}\sffamily
 $\begin{matrix}y_i^'=C_i\vec{\dot x}=C_iA\vec x+C_iB\vec u;\hfill\null \\y_i^{''}=C_iA^2\vec
x+C_i\normalsubformula{\text{AB \{}}\vec{\normalsubformula u}\hfill\null \end{matrix}+C_iB\vec u^';\hfill $\ \ (3.10.3)
\end{russian}}

{\begin{russian}\sffamily
Сократим запись:
\end{russian}}

{\begin{russian}\sffamily
 $y_i^{(m)}=C_iA^m\vec x+C_iA^{m-1}B\vec u+\overset{m-1}{\underset{ν=1}{\sum }}C_iA^{m-1-ν}B\vec u^{(ν)}$.\ \ (3.10.4)
\end{russian}}

{\begin{russian}\sffamily
Для каждой координаты найдем максимальное число дифференцирований, при котором еще не появляется производная вектора 
$\vec u$, то есть найдем такие числа  $m_i$, что 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_iA^{m_i-1}B\neq 0$ \ и \  $C_iA^{m_i-2}B=0$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, получим систему уравнений:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}y_1^{(m_1)}=C_1A^{m_1}\vec{}x+C_1A^{m_1-1}B\vec u\;;\hfill\null
\\y_2^{(m_2)}=C_2A^{m_2}\vec{}x+C_2A^{m_2-1}B\vec u\;;\hfill\null \\\cdots \cdots \cdots \cdots \cdots \cdots \cdots
\cdots \cdots \cdots \cdots \hfill\null \\y_p^{(m_p)}=C_pA^{m_p}\vec{}x+C_pA^{m_p-1}B\vec u\;.\hfill\null
\end{matrix}\hfill $\ \ (3.10.5)
\end{russian}}

{\begin{russian}\sffamily
Запишем эту систему равенств в \ векторно-матричном \ виде:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\left[\begin{matrix}y_1^{(m_1)}\\y_2^{(m_2)}\\\vdots
\\y_1^{(m_p)}\end{matrix}\right]=\left[\begin{matrix}C_1A^{m_1}\\C_2A^{m_2}\\\vdots
\\C_1A^{m_p}\end{matrix}\right]\vec{}x+\left[\begin{matrix}C_1A^{m_1-1}\\C_2A^{m_2-1}\\\vdots
\\C_1A^{m_p-1}\end{matrix}\right]B\vec u=-F_{\ast }\vec{}x+B_{\ast }\vec{}u$.\ \ (3.10.6)
\end{russian}}

{\begin{russian}\sffamily
Обозначим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec q=\left[\begin{matrix}y_1^{(m_1)}\\y_2^{(m_2)}\\\vdots \\y_1^{(m_p)}\end{matrix}\right]$\ \ (3.10.7)
\end{russian}}

{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\ \  $F_{\ast }=-\left[\begin{matrix}C_1A^{m_1}\\C_2A^{m_2}\\\vdots \\C_1A^{m_p}\end{matrix}\right]$; \ \ \ \  $B_{\ast
}=\left[\begin{matrix}C_1A^{m_1-1}\\C_2A^{m_2-1}\\\vdots \\C_1A^{m_p-1}\end{matrix}\right]B$.\ \ (3.10.8)
\end{russian}}

{\begin{russian}\sffamily
Тогда (3.10.6) можно переписать в виде
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec q=-F_{\ast }\vec x+B_{\ast }\vec u$.\ \ (3.10.9)
\end{russian}}

{\begin{russian}\sffamily
Если задача разделения каналов имеет решение, то матрица \  $B_{\ast }$ \ не вырождена и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec u=B_{\ast }^{-1}\vec q+B_{\ast }^{-1}F_{\ast }\vec x$.\ \ (3.10.10)
\end{russian}}

{\begin{russian}\sffamily
На рис. 3.10 представлена промежуточная структурная схема, соответствующая уравнениям (3.10.1), (3.10.2) и (3.10.8).
\end{russian}}

{\centering  \includegraphics[width=14.737cm,height=5.715cm]{1-img080.png} \par}

\bigskip

{\begin{russian}\sffamily
Для этой схемы справедливы уравнения
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot x}=(A+\normalsubformula{\text{BB}}_{\ast }^{-1}F_{\ast })\vec
x+\normalsubformula{\text{BB}}_{\ast }^{-1}\vec q\;;\hfill\null \\\vec y=C\vec x\;.\hfill\null \end{matrix}\hfill
$\ \ (3.10.11)
\end{russian}}

{\begin{russian}\sffamily
Обозначим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\underset{\vee }{A}=A+\normalsubformula{\text{BB}}_{\ast }^{-1}F_{\ast }\;;\hfill\null
\\\underset{\vee }{B}=\normalsubformula{\text{BB}}_{\ast }^{-1}\;.\hfill\null \end{matrix}\hfill $ \ \ (3.10.12)
\end{russian}}

{\begin{russian}\sffamily
Теперь (3.10.11) превратится в 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\left\{\vec{\dot x}=\underset V{A}\vec x+\underset V{B}\vec q\;;?\right.\left\{\vec y=C\vec
x\;,?\right.\mathit{no}\hfill\null \end{matrix}\{?$\ \ (3.10.13)
\end{russian}}

{\begin{russian}\sffamily
а структурная схема промежуточной системы с входным вектором  $\vec q$ примет вид, представленный на рис. 3.11.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=12.832cm,height=5.424cm]{1-img081.png} \par}

\bigskip

{\begin{russian}\sffamily
С другой стороны, вектор выхода  $\vec y$ связан с вектором  $\vec q$ равенством (3.10.7), и поэтому схеме,
представленной на рис. 3.11, полностью эквивалентна схема, составленная из  $p$ подсистем последовательно включённых
интеграторов. Эта схема представлена на рис. 3.12.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=14.87cm,height=10.848cm]{1-img082.png} \par}

\bigskip

{\begin{russian}\sffamily
Общее количество интеграторов не может быть больше \textit{n }, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \  $\overset p{\underset{i=1}{\sum }}m_i\le n$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, система  $\{\underset V{A},\underset V{B}\}$ (3.10.13), у которой в качестве входного вектора выбран
вектор  $\vec q$, 
\end{russian}}

{\begin{russian}\sffamily
а) развязана по каналам, то есть  $y_i$ зависит только от  $q_i$ для всех значений  $i$; 
\end{russian}}

{\begin{russian}\sffamily
б) имеет  $\overset{_p}{\underset{i=1}{\sum }}m_i$ собственных значений, равных нулю.
\end{russian}}

{\begin{russian}\sffamily
Теперь систему  $\{\underset V{A},\underset V{B}\}$ нужно попытаться привести к удобному базису, в котором следует
синтезировать обратную связь, реализующую желаемые собственные числа по каждому каналу.
\end{russian}}

{\begin{russian}\sffamily
Прежде всего, установим некоторые свойства матриц  $\underset V{A}$ и  $\underset V{B}$. Аналогично (3.10.4) запишем:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $y_i^{(m_i)}=C_i\multiscripts{}V{{}}{A}{^{m_i}}\vec x+C_i\multiscripts{}V{{}}{A}{^{m_i-1}}\underset
V{B}\vec{}q+\overset{m-1}{\underset{ν=1}{\sum }}C_i\multiscripts{}V{{}}{A}{^{m_i-1-ν}}\underset V{B}q^{(ν)}$.
\end{russian}}

{\begin{russian}\sffamily
С другой стороны,  $y_i^{(m_i)}=q_i$. Отсюда следует:
\end{russian}}

{\begin{russian}\sffamily
1)  $C_i\multiscripts{}V{{}}{A}{^{m_i}}=0$ \ \ для всех \  $i=1,2,...,p;$\ \ (3.10.14)
\end{russian}}

{\begin{russian}\sffamily
2)  $C_i\multiscripts{}V{{}}{A}{^{m_i-1}}\underset V{B}\vec
q=C_i\multiscripts{}V{{}}{A}{^{m_i-1}}\left[\begin{matrix}\underset V{\vec b_1}&\underset V{\vec b_2}&...&\underset
V{\vec b_p}\end{matrix}\right]\cdot \left[\begin{matrix}q_1\\q_2\\\vdots
\\q_{\normalsubformula{\text{ny}}}\end{matrix}\right]=q_i$,\ \ (3.10.15)
\end{russian}}

{\begin{russian}\sffamily
откуда
\end{russian}}

{\begin{russian}\sffamily
\ \  $C_i\multiscripts{}V{{}}{A}{^{m_i-1}}\underset V{\vec b_i}=1$;\ \ (3.10.16)
\end{russian}}

{\begin{russian}\sffamily
\ \  $C_i\multiscripts{}V{{}}{A}{^{m_i-1}}\underset V{\vec b_j}=0$ \ \ , \ \ при \ \  $j\neq i$;\ \ (3.10.17)
\end{russian}}

{\begin{russian}\sffamily
3)  $C_i\multiscripts{}V{{}}{A}{^{m_i-ν}}\underset V{\vec b_j}=0$ \ для \  $ν>1$ \ и для всех \ \  $j,i$.\ \ (3.10.18)
\end{russian}}

\subsubsection[Преобразование базиса в пространстве ]{Преобразование базиса в пространстве  $R^n$ }
\hypertarget{RefHeadingToc455659746}{}{\begin{russian}\sffamily
Перейдём от исходного базиса  $[e]$ к новому базису  $[f]$ \ с помощью некоторой матрицы преобразования  $F_е$. \ При
выборе базиса  $[f]$ учтем следующие обстоятельства:
\end{russian}}

\liststyleWWviiiNumxlvii
\begin{itemize}
\item {\begin{russian}\sffamily
объект управляем, поэтому ранг матрицы управляемости 
\end{russian}}
\end{itemize}
{\begin{russian}\sffamily
\ \  $U=\left[\underset V{\vec b_1}\text{  }\underset V{\vec b_2}...\underset V{\vec b_p}\vdots \text{  }\underset
V{A}\underset V{\vec b_1}...\underset V{A}\underset V{\vec b_p}\text{  }\vdots ...\vdots
\multiscripts{}V{{}}{A}{^{n-1}}\underset V{\vec b_1}...\multiscripts{}V{{}}{A}{^{n-1}}\underset V{\vec
b_p}\right]$\ \ (3.10.19)
\end{russian}}

{\begin{russian}\sffamily
\ \ равен порядку системы;
\end{russian}}

\liststyleWWviiiNumxiv
\begin{itemize}
\item {\begin{russian}\sffamily
так как каждый канал этой системы с размерностью  $m_i$ управляем, то столбцы
\end{russian}}
\end{itemize}
\begin{equation*}
\underset V{\vec b_1},\;\;\underset V{A}\underset V{\vec b_1\;,\;}...\;,\;\;\multiscripts{}V{{}}{A}{^{m_1-1}}\underset
V{\vec b_1},\;...\;,\;\underset V{\vec b_p,\;}\underset V{A}\underset V{\vec
b_p\;,\;\;}...\;,\;\;\multiscripts{}V{{}}{A}{^{m_p-1}}\underset V{\vec b_p}
\end{equation*}
{\begin{russian}\sffamily
\ линейно независимы.
\end{russian}}

{\begin{russian}\sffamily
Теперь выберем базис  $[f]$, соответствующий следующим координатным столбцам:
\end{russian}}

\begin{equation*}
\vec f_{\mathit{e1}}=\multiscripts{}{\vee }{{}}{A}{^{m_1-1}}\underset{\vee }{\vec b_1}\;;\;\;\;\;\vec
f_{\mathit{e2}}=\multiscripts{}{\vee }{{}}{A}{^{m_1-2}}\underset{\vee }{\vec b_1}\;;\;\;...\;;\;\;\;\vec
f_{e\;\;m_1}=\underset{\vee }{\vec b_1}\;;
\end{equation*}
{\begin{russian}\sffamily
 $\vec f_{e\;m_1+1}=\multiscripts{}{\vee }{{}}{A}{^{m_2-1}}\underset{\vee }{\vec b_2}\;;\;\;\;\;\vec
f_{e\;m_1+2}=\multiscripts{}{\vee }{{}}{A}{^{m_2-2}}\underset{\vee }{\vec b_2}\;;\;\;...\;\;;\;\;\;\vec
f_{e\;\;m_1+m_2}=\underset{\vee }{\vec b_2}\;;$\ \ (3.10.20)
\end{russian}}

{\begin{russian}\sffamily
\ \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
\end{russian}}

{\begin{russian}\sffamily
 $\vec f_{e\;m_1+...+m_{p-1}+1}=\multiscripts{}{\vee }{{}}{A}{^{m_p-1}}\underset{\vee }{\vec b_p}\;;\;\;\;\;\vec
f_{e\;e\;m_1+...+m_{p-2}}=\multiscripts{}{\vee }{{}}{A}{^{m_p-2}}\underset{\vee }{\vec b_p}\;;\;\;\;\;\;\vec
f_{\;e\;m_1+...+m_p}=\underset{\vee }{\vec b_p}\;$.
\end{russian}}

{\begin{russian}\sffamily
Если  $\overset p{\underset{i=1}{\sum }}m_i<n$, то оставшуюся часть векторов базиса 
$\left[f_{\normalsubformula{\text{ост}}}\right]$ можно выбирать, перебирая оставшиеся столбцы матрицы  $U$:
\end{russian}}

\begin{equation*}
\multiscripts{}V{{}}{A}{^{m_1}}\underset V{\vec b_1},\multiscripts{}V{{}}{A}{^{m_1+1}}\underset V{\vec
b_1},...\multiscripts{}V{{}}{A}{^{ν_1-1}}\underset V{\vec b_1}
\end{equation*}
{\begin{russian}\sffamily
до тех пор, пока следующий вектор \  $\multiscripts{}V{{}}{A}{^ν}\underset V{\vec b_1}$ не будет выражаться в виде
линейной комбинации всех предыдущих векторов базиса. Далее добавим \  $\multiscripts{}V{{}}{A}{^{m_2}}\underset V{\vec
b_2},\multiscripts{}V{{}}{A}{^{m_2+1}}\underset V{\vec b_2}$ и так далее, пока число векторов базиса не достигнет числа
 $n$. Тогда матрица преобразования базиса  $[e]$ в базис  $[f]$ будет иметь вид
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \  $F_e=\left[\multiscripts{}V{{}}{A}{^{m_1-1}}\underset{\vee }{\vec b_1}\;\;\cdots
\multiscripts{}V{{}}{\;\;A}{^{m_1-2}}\underset V{\vec b_1}\;\;\cdots \;\;\;\underset V{\vec b_1}\;\;\cdots
\;\;\multiscripts{}V{{}}{A}{^{m_2-1}}\underset V{\vec b_2}\;\;\cdots \;\;\underset V{\vec b_2}\;\;\cdots
\;\;\;\underset{\vee }{\vec b_p}\;\;\;\;[f_{\normalsubformula{\text{ост}}}]\right]$.
\end{russian}}

{\begin{russian}\sffamily
Рассмотрим вид матрицы  $\underset V{B}$ в базисе  $[f]$. Первый столбец этой матрицы, то есть вектор  $\vec b_1$,
совпадает с  $m_1$-м столбцом базиса  $[f]$; второй столбец матрицы  $B$, то есть вектор  $\vec b_2$, совпадает с 
$(m_1+m_2)$-м столбцом базиса  $[f]$ и так далее. Следовательно,
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $B_f=\left[\begin{matrix}\vec β_1&0&\cdots &0\\0&\vec β_2&\cdots &0\\\cdots &\cdots &\cdots &\cdots
\\0&0&\cdots &\vec β_p\\0&0&\cdots &0\end{matrix}\right]$,\ \ (3.10.21)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec β_i=\left.\left[\begin{matrix}0\\0\\\cdots
\\0\\1\end{matrix}\right]\;\;\right\}m_i\;\text{строк}.$\ \ (3.10.22)
\end{russian}}

{\begin{russian}\sffamily
Теперь обратим внимание на \ \ матрицу  $С$. В соответствии с (3.6.8)
\end{russian}}

{\begin{russian}\sffamily
 $С_f=C$ $F_е$ $=\left[\begin{matrix}C_1\\C_2\\\vdots \\C_p\end{matrix}\right]\cdot \left[\begin{matrix}\vec
f_{e_1}&\vec f_{\mathoverstrike e_2}&\cdots &\vec f_{e_n}\end{matrix}\right]=\left[\begin{matrix}C_1\vec f_{e_1}&\cdots
&C_1\vec f_{e_n}\\C_2\vec f_{e_1}&\cdots &C_2\vec f_{e_n}\\\cdots &\cdots &\cdots \\C_p\vec f_{e_1}&\cdots &C_p\vec
f_{e_n}\end{matrix}\right]$.\ \ (3.10.23)
\end{russian}}

{\begin{russian}\sffamily
Из этого равенства с учётом (3.10.14), (3.10.16), (3.10.17) \ получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_f=\left[\begin{matrix}s_1&0&\cdots &0&0\\0&s_2&\cdots &0&0\\\vdots &\vdots &\vdots &\vdots &\vdots
\\0&0&\cdots &s_p&0\end{matrix}\right]$ ,\ \ (3.10.24)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $s_i=\underbrace{\left[\begin{matrix}1&0&\cdots &0\end{matrix}\right]}_{m_i}$.\ \ (3.10.25)
\end{russian}}

{\begin{russian}\sffamily
Наконец, займемся \ матрицей  $\underset V{A_f}$. Прежде всего, рассмотрим важную интерпретацию элементов матрицы 
$A_f$. В соответствии с \ (3.6.8)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $А_f=$ $F_е^{-1}$ $А_е$ $F_е$,
\end{russian}}

{\begin{russian}\sffamily
поэтому
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_е$ $А_f=$ $А_е$ $F_е$.\ \ (3.10.26)
\end{russian}}

{\begin{russian}\sffamily
Левую часть этого равенства можно расписать следующим образом:
\end{russian}}

{\begin{russian}\sffamily
\ \  $F_е$ $А_f=$ $\left[\begin{matrix}\vec f_{e_1}&\vec f_{e_2}&...&\vec f_{e_n}\end{matrix}\right]\cdot
\left[\begin{matrix}a_{11}^f&a_{12}^f&\cdots &a_{1n}^f\\\vdots &\vdots &\vdots &\vdots
\\a_{\mathit{n1}}^f&a_{\mathit{n2}}^f&\cdots &a_{\normalsubformula{\text{nn}}}^f\end{matrix}\right]=$
\end{russian}}

{\begin{russian}\sffamily
\ \  $=\left[\begin{matrix}a_{11}^f\vec f_{e_1}+...+a_{\mathit{n1}}^f\vec f_{e_n}&a_{12}^f\vec
f_{e_1}+...+a_{\mathit{n2}}^f\vec{}f_{e_n}&\cdots &a_{1n}^f\vec
f_{e_1}+...+a_{\normalsubformula{\text{nn}}}^f\vec{}f_{e_n}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
С другой стороны:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $А_е$ $F_е$ $=\left[А_е\vec f_{e_1}\cdots А_е\vec f_{e_n}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A_e\vec f_{\normalsubformula{\text{ei}}}=a_{1i}^f\vec f_{\mathit{e1}}+a_{2i}^f\vec
f_{\mathit{e2}}+...+a_{\normalsubformula{\text{ni}}}^f\vec f_{\normalsubformula{\text{en}}}$.\ \ (3.10.27)
\end{russian}}

{\begin{russian}\sffamily
Это означает, что элементы  $i$-го \ столбца матрицы  $\underset V{A_f}$
\end{russian}}

\begin{equation*}
\vec a_i^f=\left[\begin{matrix}a_{1i}^f\\a_{2i}^f\\\cdots \\a_{\normalsubformula{\text{ni}}}^f\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
являются коэффициентами \ разложения \ произведения  $\underset{\vee }{A}\vec f_{\normalsubformula{\text{ei}}}\equiv
\underset{\vee }{A_e}\vec f_{\normalsubformula{\text{ei}}}$ по координатным векторам  $\vec f_{\mathit{e1}}\;,\;\;\vec
f_{\mathit{e2}}\;,\;\;...\;,\;\;\vec f_{\normalsubformula{\text{en}}}$. 
\end{russian}}

{\begin{russian}\sffamily
Используя (3.10.20), сопоставим произведения  $\underset{\vee }{A}\vec f_{\normalsubformula{\text{ei}}}$ с координатными
столбцами векторов базиса  $[f]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\underset{\vee }{A}\vec f_{\mathit{e1}}=\multiscripts{}{\vee }{{}}{A}{^{m_1}}\underset{\vee
}{\vec b_1}\;;\hfill\null \\\underset{\vee }{A}\vec f_{\mathit{e2}}=\multiscripts{}{\vee
}{{}}{A}{^{m_1-1}}\underset{\vee }{\vec b_1}=\vec f_{\mathit{e1}}\;;\hfill\null \\\underset{\vee }{A}\vec
f_{\mathit{e3}}=\multiscripts{}{\vee }{{}}{A}{^{m_1-2}}\underset{\vee }{\vec b_1}=\vec f_{\mathit{e2}}\;;\hfill\null
\\\cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \;\;\;.\hfill\null \end{matrix}\hfill $\ \ (3.10.28)
\end{russian}}

{\begin{russian}\sffamily
Так как векторы  $\underset V{A}f_{\mathit{e1}}$,  $\underset V{A}f_{em_1+1}$ и т. д. не совпадают ни с одним из
собственных векторов с номерами от 1 до  $n-\overset p{\underset{i=1}{\sum }}m_i-1$, то в соответствующих столбцах
матрицы  $\underset V{A_f}$ на позициях строк с номерами, большими  $p$, могут находиться ненулевые элементы. Такие
ячейки матрицы помечены символом " $\times $". Кроме того, на данном этапе нет смысла рассматривать столбцы этой
матрицы с номерами, большими  $p$. В результате получаем выражение для матрицы \ \  $\underset{\vee }{A}$ в базисе 
$[f]$:\ \ 
\end{russian}}


\bigskip

\begin{flushleft}
\tablefirsthead{}
\tablehead{}
\tabletail{}
\tablelasttail{}
\begin{supertabular}{m{1.55cm}|m{2.55cm}|m{2.552cm}|m{0.55cm}|m{2.55cm}|m{2.0509999cm}|m{2.1299999cm}|}
\hline
\multicolumn{1}{|m{1.55cm}|}{~

~

~

~

~

~

~

~

~

~

{\begin{russian}\sffamily  $\underset V{A_f}$ \ \ = \end{russian}}

~

~

~

~
} &
{\begin{russian}\sffamily 0 1 0 … 0 \end{russian}}

{\begin{russian}\sffamily 0 0 1 … 0 \ \ \ \ \ \ \ \ \end{russian}}

{\begin{russian}\sffamily …………. \end{russian}}

{\begin{russian}\sffamily 0 0 0 … 1 \ \ \ \ \ 0 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0 \end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}} &
{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0 \end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
~

~

~
 &
~

~

 $m_1$\\\hhline{~--~---}
 &
{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0… 0 …………\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily 0 1 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 1 … 0 ………….\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 1\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}} &
{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0 \end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
~

~

~
 &
~

~

 $m_2$\\\hhline{~--~---}
 &
\multicolumn{1}{m{2.55cm}}{{\begin{russian}\sffamily ………….\end{russian}}} &
\multicolumn{1}{m{2.552cm}}{{\begin{russian}\sffamily ………….\end{russian}}} &
\multicolumn{1}{m{0.55cm}}{~
} &
\multicolumn{1}{m{2.55cm}}{{\begin{russian}\sffamily ………….\end{russian}}} &
~
 &
~
\\\hhline{~--~---}
 &
{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}} &
{\begin{russian}\sffamily 0 1 0 … 0\end{russian}}

{\begin{russian}\sffamily 0 0 1 … 0 \end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 1\end{russian}}

{\begin{russian}\sffamily 0 0 0 … 0\end{russian}} &
~

~

~
 &
~

~

 $m_p$\\\hhline{~--~---}
 &
{\begin{russian}\sffamily \ * 0 0 … 0\end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily \ * 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily \ * 0 0 … 0\end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily \ * 0 0 … 0\end{russian}} &
{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}}

{\begin{russian}\sffamily \ :\end{russian}} &
{\begin{russian}\sffamily \ * 0 0 … 0\end{russian}}

{\begin{russian}\sffamily ………….\end{russian}}

{\begin{russian}\sffamily \ * 0 0 … 0\end{russian}} &
~

~
 &
~

 $n-\sum m_i$\\\hhline{~------}
 &
{\begin{russian}\sffamily \ \ \ \ \ \  $m_1$\end{russian}}

~
 &
{\begin{russian}\sffamily \ \ \ \ \  $m_2$\end{russian}} &
~
 &
{\begin{russian}\sffamily \ \ \ \ \  $m_p$\end{russian}} &
 $n-\sum m_i$ &
~
\\\hhline{~------}
\end{supertabular}
\end{flushleft}
{\begin{russian}\sffamily
Эту же матрицу удобнее записать в блочном виде:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\multiscripts{}V{{}}{A}{_f}=\left[\begin{matrix}A_{11}&0&\cdots &0&A_{10}\\0&A_{22}&\cdots &0&A_{20}\\\vdots
&\vdots &\vdots &\vdots &\vdots \\0&0&\cdots &A_{p\text{ p}}&A_{\mathit{p0}}\\A_{01}&A_{02}&\cdots
&A_{0\;p}&A_{00}\end{matrix}\right]$.\ \ (3.10.29)
\end{russian}}

{\begin{russian}\sffamily
Разобьём вектор состояния  $\vec x$ на систему  $(p+1)$ частных векторов и обозначим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x_f=\left[\begin{matrix}\vec z_1\\\vec z_2\\\vdots \\\vec z_p\\\vec z_0\end{matrix}\right]$,\ \ (3.10.30)
\end{russian}}

{\begin{russian}\sffamily
где  $\vec z_i$ имеет размерность  $\left[m_i\times 1\right]$. \ Тогда уравнения (3.10.13) в базисе  $[f]$ примут вид
\end{russian}}

{\begin{russian}\sffamily
 $\left[\begin{matrix}\vec{\dot z}_1\\\vec{\dot z}_2\\\vdots \\\vec{\dot z}_p\\\vec{\dot z}_0\end{matrix}\right]=$
$\left[\begin{matrix}A_{11}&0&\cdots &0&A_{10}\\0&A_{22}&\cdots &0&A_{20}\\\vdots &\vdots &\vdots &\vdots &\vdots
\\0&0&\cdots &A_{p\;p}&A_{p\;0}\\A_{01}&A_{02}&\cdots &A_{0\;p}&A_{00}\end{matrix}\right]\ast ?$
$\left[\begin{matrix}\vec z_1\\\vec z_2\\\vdots \\\vec z_p\\\vec
z_0\end{matrix}\right]+$\textrussian{\textrm{\textsubscript{ }}};
\end{russian}}

{\begin{russian}\sffamily
 $\left[\begin{matrix}y_1\\y_2\\\vdots \\y_p\end{matrix}\right]=\left[\begin{matrix}s_1&0&\cdots &0&0\\0&s_2&\cdots
&0&0\\\vdots &\vdots &\vdots &\vdots &\vdots \\0&0&\cdots &s_p&0\end{matrix}\right]\ast \left[\begin{matrix}\vec
z_1\\\vec z_2\\\vdots \\\vec z_p\\\vec z_0\end{matrix}\right]$.\ \ (3.10.31)
\end{russian}}

{\begin{russian}\sffamily
Отсюда следуют \ уравнения для частных подсистем:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot z}_i=A_{\normalsubformula{\text{ii}}}\vec z_i+A_{\mathit{i0}}\vec z_0+\vec β_iq_i$;\ \ (3.10.32)
\end{russian}}

{\begin{russian}\sffamily
\ \  $y_i=s_i\vec z_i$ , \ \ \ \ \  $\left(i=1,2,...,p\right)$;
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot z}_0=\overset p{\underset{ν=1}{\sum }}A_{0ν}\vec z_ν+A_{00}\vec z_0$.\ \ (3.10.33)
\end{russian}}

{\begin{russian}\sffamily
Раскроем систему дифференциальных уравнений для  $i$-й подсистемы:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\left\{\dot z_{\mathit{i1}}=z_{\mathit{i2}}+a_1^{i\;10}\vec
z_0=z_{\mathit{i2}}+g_{\mathit{i1}}\;;?\right.\left\{\dot
z_{\mathit{i2}}=z_{\mathit{i3}}+g_{\mathit{i2}}\;;?\right.\left\{.................?\right.\left\{\dot
z_{i,m_i-1}=z_{i,m_i}+g_{i,m_i-1}\;;?\right.\left\{\dot z_{i,m_i}=g_{i,m_i}+q_i\;;?\right.\mathit{no}\hfill\null
\end{matrix}\{?$ \ \ \ (3.10.34)
\end{russian}}

{\begin{russian}\sffamily
 $\left\{y_i=z_{\mathit{i1}}\right.$,
\end{russian}}

{\begin{russian}\sffamily
где  $a_1^{i\;10}$ - первая строка матрицы  $A_{\mathit{i0}}$. Такой подсистеме соответствует структурная схема,
представленная на рис. 3.13.
\end{russian}}

{\centering  \includegraphics[width=14.87cm,height=5.609cm]{1-img083.png} \par}
{\begin{russian}\sffamily
Из сопоставления этой схемы со схемой, приведённой на рис. 3.12, следует:\ \ 
\end{russian}}

{\begin{russian}\sffamily
а)  $z_{\mathit{i1}}=y_i$;  $z_{\mathit{iν}}=y_i^{(ν)}$ при  $ν>1$;
\end{russian}}

{\begin{russian}\sffamily
б)  $q_{\mathit{iν}}=0$ и  $A_{\mathit{ν0}}=0$ для  $ν=1,2,...,p$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, \ выходы интеграторов частных подсистем, показанных на рис. 3.12, совпали с координатами вектора  $\vec
x$ в базисе  $[f]$. \ Кроме того, все \ блочные матрицы \  $A_{00},A_{10},...,A_{\mathit{p0}}$ в (3.10.29)- нулевые. 
\end{russian}}

\subsubsection{Формирование управления }
\hypertarget{RefHeadingToc455659747}{}{\begin{russian}\sffamily
Работая в базисе  $[f]$, мы имеем  $p$ изолированных подсистем, сумма выходов которых подаётся на вход общей подсистемы
с матрицей динамики  $A_{00}$ размерности  $n-\overset p{\underset{i=1}{\sum }}m_i$:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\left\{\vec{\dot z}_1=A_{11}\vec z_1+\vec
β_1q_1;\ y_1=z_{11}\;;?\right.\left\{...................?\right.\left\{\vec{\dot
z}_p=A_{\normalsubformula{\text{pp}}}\vec z_p+\vec β_pq_p;\ y_p=z_{\mathit{p1}}\;;?\right.\left\{\vec{\dot
z}_0=A_{00}\vec z_0+\overset p{\underset{ν=1}{\sum }}A_{0ν}\vec z_ν\;.?\right.\mathit{no}\hfill\null
\end{matrix}\{?$\ \  \ (3.10.35)
\end{russian}}

{\begin{russian}\sffamily
Соответствующая структурная схема представлена на рис. 3.14.
\end{russian}}

{\begin{russian}\sffamily
Пары матриц  $\{A_{\normalsubformula{\text{ii}}},\vec β_i\}$ для  $i=1\;,\;\;2\;,\;\;...\;,\;\;p$ имеют форму УКП,
причем каждая из матриц  $A_{\normalsubformula{\text{ii}}}$ имеет только нулевые собственные значения. Это вполне
согласуется с тем, что в п. 3.10.1 было произведено преобразование объекта на подсистемы последовательно включённых
интеграторов. Сформируем управление  $q_i$ для  $i=1\;,\;\;2\;,\;\;...\;,\;\;p$ в следующем виде:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $q_i=k_iv_i(t)+l_{\normalsubformula{\text{fi}}}\vec z_i(t)$,\ \ (3.10.36)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $l_{\normalsubformula{\text{fi}}}=\left[\begin{matrix}l_{\mathit{i1}}^f&l_{\mathit{i2}}^f&\ldots
&l_{i,m_i}^f\end{matrix}\right]$ -
\end{russian}}

{\begin{russian}\sffamily
матрица обратной связи для  $i$-й подсистемы в базисе  $[f]$.
\end{russian}}

 \includegraphics[width=15.452cm,height=7.938cm]{1-img084.png} 

{\begin{russian}\sffamily
Тогда получим следующее дифференциальное уравнение для  $i$-й подсистемы: 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot z}_i=A_{\normalsubformula{\text{ii}}}\vec z_i+\vec β_il_{\normalsubformula{\text{fi}}}\vec z_i+\vec
β_ik_iv_i$,
\end{russian}}

{\begin{russian}\sffamily
или
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot z}_i=χ_{\normalsubformula{\text{fi}}}\vec z_i+\vec β_ik_iv_i$.\ \ (3.10.37)
\end{russian}}

{\begin{russian}\sffamily
Нетрудно убедиться, что матрица динамики  $i$-й подсистемы в базисе  $[f]$ имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $χ_{\normalsubformula{\text{fi}}}=\left[\begin{matrix}0&1&0&\cdots &0\\0&0&1&\cdots &0\\\vdots &\vdots &\vdots
&\vdots &\vdots \\0&0&0&\cdots &1\\l_{\mathit{i1}}^f&l_{\mathit{i2}}^f&l_{\mathit{i3}}^f&\cdots
&l_{i,m_i}^f\end{matrix}\right]$.\ \ (3.10.38)
\end{russian}}

{\begin{russian}\sffamily
Следовательно, определены характеристические полиномы подсистем:
\end{russian}}

{\begin{russian}\sffamily
 $ϕ_i(λ)=λ^{m_i}-l_{i,m_i}^fλ^{m_i-1}-l_{i,m_i-1}^fλ^{m_i-2}-...-l_{\mathit{i1}}^f$.\ \ (3.10.39)
\end{russian}}

{\begin{russian}\sffamily
Согласно (3.8.22), а также \ с учетом (3.10.13), (3.10.24) и (3.10.37) запишем выражение для передаточной функции
замкнутой  $i$-й подсистемы:
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{v_iy_i}(p)=\frac{k_i}{p^{m_i}-l_{i,m_i}^fp^{m_i-1}-...-l_{\mathit{i1}}^f}$.\ \ (3.10.40)
\end{russian}}

{\begin{russian}\sffamily
Очевидно 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $W_{v_iy_i}(0)=\frac{k_i}{-l_{\mathit{i1}}^f}$.\ \ (3.10.41)
\end{russian}}

{\begin{russian}\sffamily
Задавая расположение полюсов и статику для каждой подсистемы, в итоге получим матрицы
\end{russian}}

{\begin{russian}\sffamily
\ \  $L_f=\left[\begin{matrix}l_{\mathit{f1}}&0&\cdots &0&0\\0&l_{\mathit{f2}}&\cdots &0&0\\\vdots &\vdots &\vdots
&\vdots &\vdots \\0&0&\cdots &l_{f,p}&0\end{matrix}\right]\text{  };\text{  }\underset{\vee
}{k}=\left[\begin{matrix}k_1&0&\cdots &0\\0&k_2&\cdots &0\\\vdots &\vdots &\vdots &\vdots \\0&0&\cdots
&k_p\end{matrix}\right]$.\ \ (3.10.42)
\end{russian}}

{\begin{russian}\sffamily
Возвращаясь в исходный базис для уравнений (3.10.13), получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\underset V{L}=L_f$ $F_е^{-1}$.\ \ (3.10.43)
\end{russian}}

{\begin{russian}\sffamily
При этом вектор  $\vec q$ формируется в соответствии с выражением
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec q(t)=\underset V{L}\vec x(t)+\underset{\vee }{k}\vec v(t)$.\ \ (3.10.44)
\end{russian}}

{\begin{russian}\sffamily
Учитывая (3.10.10), окончательно получим
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec u=B_{\ast }^{-1}F_{\ast }\vec x+B_{\ast }^{-1}\underset V{L}\vec x+B_{\ast }^{-1}\underset V{k}V(t)=L\vec
x+k\vec V$,\ \ (3.10.45)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \  $L=B_{\ast }^{-1}(F_{\ast }+\underset V{L});\ k=B_{\ast }^{-1}\underset V{k}$.\ \ (3.10.46)
\end{russian}}

{\begin{russian}\sffamily
На этом можно закончить синтез, если часть системы, оказавшаяся вне обратной связи, имеет допустимые динамические
свойства. Если же нет, например  $A_{00}$ - неустойчива, то приходится идти на то, чтобы ввести обратную связь  $L_0$,
по вектору  $\vec z_0$, по крайней мере, через один из каналов  $(q_r)$, оставив полностью развязанными остальные 
$(p-1)$ каналов. В этом случае  $\underset V{k_r},l_{\normalsubformula{\text{fr}}},l_{\mathit{f0}}$ нужно рассчитывать
совместно. Связь  $L_0$ должна обеспечить «надзор» за бывшими ранее без контроля  $(n-\sum m_i)$ полюсами (собственными
числами) системы. Эта часть расчета может быть произведена по обычной методике синтеза системы с одним входом.
Результирующая структура в базисе  $[f]$ приведена на рис. \ 3.15.
\end{russian}}

{\centering  \includegraphics[width=16.616cm,height=21.299cm]{1-img085.png} \par}
\subsubsection[Итоговый алгоритм\ \ ]{Итоговый алгоритм\ \ }
\hypertarget{RefHeadingToc455659748}{}\liststyleWWviiiNumxxxi
\begin{enumerate}
\item {\begin{russian}\sffamily
Расчет чисел  $m_i,\;i=1,2,...,p$:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \textenglish{\ \ } $m_i=m_{\text{max}}$\ \ (3.10.47)
\end{russian}}

{\begin{russian}\sffamily
Эти числа можно также находить непосредственно из схемы в переменных состояния.
\end{russian}}

\liststyleWWviiiNumxxxi
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Вычисление матриц  $F_{\ast },B_{\ast }$:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $F_{\ast }=-\left[\begin{matrix}C_1A^{m_1}\\\vdots \\C_pA^{m_p}\end{matrix}\right];\text{  }B_{\ast
}=\left[\begin{matrix}C_1A^{m_1-1}\\\vdots \\C_pA^{m_p-1}\end{matrix}\right]B.$\ \ (3.10.48)
\end{russian}}

\liststyleWWviiiNumxxxi
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Вычисление  $B_{\ast }^{-1}$. Если  $B_{\ast }$ - вырождена, то задача разделения каналов не имеет решения.
\end{russian}}
\item {\begin{russian}\sffamily
Вычисление матриц  $\underset V{A},\;\;\underset V{B}$:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $\underset V{A}=A+\underbrace{\normalsubformula{\text{BB}}_{\ast }^{-1}}_{\underset v{B}}F_{\ast }\text{ ; 
}\underset V{B}=\normalsubformula{\text{BB}}_{\ast }^{-1}$.\ \ (3.10.49)
\end{russian}}

\liststyleWWviiiNumxxii
\begin{enumerate}
\item {\begin{russian}\sffamily
\ Построение матрицы  $F_e$:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $F_e=\left[\multiscripts{}V{{}}{A}{^{m_1-1}}\underset V{\vec b_1}\vdots ...\vdots \underset V{\vec b_1}\vdots
\vdots \multiscripts{}V{{}}{A}{^{m_2-1}}\underset V{\vec b_2}\vdots ...\vdots \underset V{\vec b_2}\vdots ...\underset
V{\vdots \vec b_p}\vdots \left[f_{\normalsubformula{\text{ост}}}\right]\right]$.\ \ (3.10.50)
\end{russian}}

\liststyleWWviiiNumxxii
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчет коэффициентов характеристических уравнений каналов, то есть строк  $l_{\normalsubformula{\text{fi}}}$. Для этого
предварительно должны быть заданы наборы желаемых собственных чисел 
$(λ_{i\;1\;},\;\;λ_{i\;2\;},\;\;...\;,\;\;λ_{i\;m_i})$ по каждому из каналов, после чего в соответствии с равенством
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $\overset{m_i}{\underset{ν=1}{\prod
}}(λ-λ_{\mathit{iν}})=λ^{m_i}-l_{i,m_i}^fλ^{m_i-1}-l_{i,m_i-1}^fλ^{m_i-2}-...-l_{\mathit{i1}}^f$\ \ (3.10.51)
\end{russian}}

{\begin{russian}\sffamily
следует рассчитать
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$l_{\normalsubformula{\text{fi}}}=\left[\begin{matrix}l_{\mathit{i1}}^f&...&l_{i,m_i}^f\end{matrix}\right]$\ \ (3.10.52)
\end{russian}}

{\begin{russian}\sffamily
и сформировать матрицу 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_f=\left[\begin{matrix}l_{\mathit{f1}}&0&\cdots &0\\0&l_{\mathit{f2}}&\cdots &0\\\vdots &\vdots &\vdots
&\vdots \\0&0&\cdots &l_{\normalsubformula{\text{fp}}}\end{matrix}\right]$.
\end{russian}}

\liststyleWWviiiNumxxii
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчет (построение в соответствии с выбранным базисом) матрицы  $A_{00}$ и вычисление ее собственных чисел.
\end{russian}}
\item {\begin{russian}\sffamily
Принятие решения о необходимости завязки каналов для коррекции собственных чисел полинома  $ϕ_0(λ)$. В случае
необходимости - выбрать канал для коррекции и далее провести для него расчет по методике синтеза системы с одним
входом. В конечном итоге должна быть получена  $L_f$ - полная матрица обратной связи промежуточной системы в базисе 
$[f]$.
\end{russian}}
\item {\begin{russian}\sffamily
Расчет матрицы  $\underset V{k}$ по заданным коэффициентам  $W_i(0):$
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $\underset V{k_i}=-W_i(0)l_{\mathit{i1}}^f$\ \ (3.10.53)
\end{russian}}

{\begin{russian}\sffamily
\ \ и
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\underset V{k}=\left[\begin{matrix}\underset V{k_1}&0&\cdots &0\\0&\underset V{k_2}&\cdots &0\\\vdots &\vdots
&\vdots &\vdots \\0&0&\cdots &\underset V{k_p}\end{matrix}\right]$.\ \ (3.10.54)
\end{russian}}

\liststyleWWviiiNumlxxv
\begin{enumerate}
\item {\begin{russian}\sffamily
Расчет матрицы обратной связи промежуточной системы в исходном базисе:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $\underset V{L}=L_fF_e^{-1}.$\ \ (3.10.55)
\end{russian}}

\liststyleWWviiiNumlxxv
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчет результирующей матрицы обратной связи:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $L=B_{\ast }^{-1}(F_{\ast }+\underset V{L})$.\ \ (3.10.56)
\end{russian}}

\liststyleWWviiiNumlxxv
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчет матрицы передаточных коэффициентов по вектору командных сигналов:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $k=B_{\ast }^{-1}\underset V{k}$.\ \ (3.10.57)
\end{russian}}

{\begin{russian}\sffamily
\ \ Вектор управления формируется традиционным образом:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec u(t)=L\vec x(t)+k\vec v(t)$.\ \ (3.10.58)
\end{russian}}

{\begin{russian}\sffamily
При необходимости может быть синтезирован идентификатор (наблюдатель) неизмеряемых координат вектора состояния.
\end{russian}}

\clearpage\subsection[Основы построения идентификаторов состояния \ \ \ \ (на­блюдателей)]{Основы построения
идентификаторов состояния \ \ \ \ (на­блюдателей)}
\hypertarget{RefHeadingToc455659749}{}\subsubsection{Наблюдатель Люенбергера полного порядка}
\hypertarget{RefHeadingToc455659750}{}\paragraph{Синтез архитектуры наблюдателя}
{\begin{russian}\sffamily
Рассмотрим линейную стационарную систему, которая описывается векторно-матричными дифференциальными уравнениями:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\left\{\vec{\dot x}(t)=A\vec x(t)+B\vec u(t);?\right.\left\{\vec y(t)=C\vec
x(t).?\right.\mathit{no}\hfill\null \end{matrix}\{?$\ \ (3.11.1)
\end{russian}}

{\begin{russian}\sffamily
Для такой системы существуют алгоритмы модального синтеза, которые позволяют найти управление
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec u(t)=L\vec x(t)+k\vec v(t)$,\ \ (3.11.2)
\end{russian}}

{\begin{russian}\sffamily
обеспе­чивающее заданные динамику и статику системы. Проблема заключается в необходимости использования вектора обратной
связи для формирова­ния такого управления. Фактически в \ распоряжении разработчика системы управления \ лишь вектор
выхода  $\vec y(t)$. Возникает вопрос: как, наблюдая за вектором  $\vec y(t)$, восстановить вектор  $\vec x(t)$ или
найти его оценку  $\vec x(t)$? \ При этом ошибка оценки вектора  $\vec x(t)$
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec e(t)=\vec x(t)-\vec x(t)$\ \ (3.11.3)
\end{russian}}

{\begin{russian}\sffamily
должна быть относительно малой и тем более с течением времени не должна расти.
\end{russian}}

{\begin{russian}\sffamily
Будем полагать, что \ разработчику достаточно хорошо известны параметры объекта, то есть оценки  $A,\text{  }B,\text{  
\{}\normalsubformula C$ матриц  $A,\;\;B,\text{  }C$. Более того, положим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $A=A,\text{  }B=B,\text{   \{}\normalsubformula C=C$.\ \ (3.11.4)
\end{russian}}

{\begin{russian}\sffamily
В этом случае, если построить аналоговую или цифровую модель объекта в соответствии с уравнениями
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot x}=A\vec x(t)+B\vec u(t);\hfill\null \\\vec y(t)=C\vec x(t)\;\;,\hfill\null
\end{matrix}\hfill $\ \ (3.11.5)
\end{russian}}

{\begin{russian}\sffamily
как показано на рис. 3.16, то можно было бы ожидать выполнения равенств
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=\vec x$ \ \ и \ \  $\vec y=\vec y$.\textenglish{\ \ }(3.11.6)
\end{russian}}


\bigskip

{\centering  \includegraphics[width=11.668cm,height=7.673cm]{1-img086.png} \par}
{\begin{russian}\sffamily
Однако априорное знание объекта (в том числе матриц  $A$, \  $B$ и  $C$) является приближённым, параметры его могут
дрейфовать во времени, начальные условия для вектора состояния, которые следовало бы подставить в модель, неизвестны.
Поэтому в действительности в такой схеме ошибка оценки вектора состояния может иметь склонность к неограниченному росту
с течением времени.
\end{russian}}

{\begin{russian}\sffamily
Американским учёным Д.Г.Люенбергером впервые были изучены структуры работоспособных асимптотических идентификаторов
(наблюдателей, восстановителей) вектора состояния, названных позднее его именем. Основополагающая идея состоит в том,
чтобы в рассмотренную структурную схему ввести дополнительную обратную связь по ошибке оценки \ вектора  $\vec y$,
заведомо обеспечивающую асимптотическое затухание ошибки оценки вектора состояния. Внешне структурная схема наблюдателя
Люенбергера полного порядка, которая приведена на \ \ \ \ \ \ рис. 3.17, совпадает с одной из форм известного фильтра
Калмана. Различие в том, что матрица  $K$, которая в фильтре Калмана называется его именем (матрицей Калмана), в
наблюдателе Люенбергера рассчитывается из других соображений. 
\end{russian}}

{\begin{russian}\sffamily
В соответствии с рис.3.17 уравнение наблюдателя будет иметь вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot x}(t)=A\vec x(t)+B\vec u(t)+K\left(\vec y(t)-\vec y(t)\right)$. \ \ (3.11.7)
\end{russian}}

{\begin{russian}\sffamily
Получим уравнение для \ ошибки оценки вектора состояния. Для этого в равенство (3.11.3) подставим выражения для вектора
состояния и его оценки из (3.11.1) и (3.11.7):
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot e}(t)=A\vec x(t)+B\vec u(t)-A\vec x(t)-B\vec u(t)-K\left(C\vec x(t)-C\vec x(t)\right)$,
\end{russian}}

{\begin{russian}\sffamily
откуда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot e}(t)=L\cdot \vec{}e(t)$,\ \ (3.11.8)
\end{russian}}


\bigskip

{\centering  \includegraphics[width=11.139cm,height=10.345cm]{1-img087.png} \par}
{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L=A-\normalsubformula{\text{KC}}$\ \ (3.11.9)
\end{russian}}

{\begin{russian}\sffamily
называют матрицей динамики наблюдателя. Выражение (3.11.8) является однородным дифференциальным уравнением. Решение его
имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec e(t)=\text{exp}\left(L\cdot ?t\right)\cdot \vec e\left(0\right)$.\ \ (3.11.10)
\end{russian}}

{\begin{russian}\sffamily
Поведение ошибки во времени зависит от \ собственных чисел матрицы наблюдателя  $L$. \ \ Выбрав их соответствующим
образом, можно достаточно быстро свести ошибку к нулю и получать от наблюдателя точную оценку вектора состояния. Далее
будет показано, что если пара  $\left\{A,C\right\}$ наблюдаема, то соот­вет­ствующим выбором матрицы \textit{K }можно
обеспечить любое желаемое рас­положение собственных чисел наблюдателя, т.е. матрицы  $L$. Практически собственные
значения наблюдателя выбираются так, чтобы состояние наблюдателя  $\vec x$ сходилось к состоянию наблюдаемой системы
несколько быстрее \ затухания пере­ходных процессов в \ желаемой замк­нутой системе. Чрезмерное ускорение наблюдателя
приводит к затру­днениям при его реализации.
\end{russian}}

\paragraph[Алгоритм определения матрицы К для систем \ \ \ \ \ \ \ \ \ \ \ \ \ со скалярным выходом ]{Алгоритм
определения матрицы \textup{К} для систем \ \ \ \ \ \ \ \ \ \ \ \ \ со скалярным выходом }

\bigskip

{\begin{russian}\sffamily
Если пара  $\left\{A,\;C\right\}$ наблюдаема, то в пространстве вектора состояния существует базис  $[i]$, в котором эта
пара имеет идентификационное ка­ноническое представление (ИКП)  $\left\{A_I,\text{  }C_I\right\}$.
\end{russian}}

{\begin{russian}\sffamily
Обозначим некоторый исходный базис как  $[h]$. В этом базисе дифференциальное уравнение для ошибки оценки вектора
состояния имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot e}_h(t)=L_h\vec{}e_h(t)$.\ \ (3.11.11)
\end{russian}}

{\begin{russian}\sffamily
Перейдём к базису ИКП. Используем уже известное соотношение, связывающее координатные столбцы одного и того же вектора в
разных базисах:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec e_h=I_h\vec e_I$.\ \ (3.11.12)
\end{russian}}

{\begin{russian}\sffamily
Используя эту подстановку, запишем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $I_h\cdot \vec{\dot e}_I(t)=L_h\cdot I_h\cdot \vec e_I(t)$.
\end{russian}}

{\begin{russian}\sffamily
Умножив обе части последнего равенства на  $I_h^{-1}$, получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot e}_I(t)=L_I\vec e_I(t)$,
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_I=I_h^{-1}L_hI_h$.\ \ (3.11.13)
\end{russian}}

{\begin{russian}\sffamily
Кроме того,
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_I=A_I-K_IC_I$,\ \ (3.11.14)
\end{russian}}

{\begin{russian}\sffamily
где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}A_I=I_h^{-1}A_hI_h;\text{  }\hfill\null \\C_I=C_hI_h;\text{  }K_I=I_h^{-1}K_h.\hfill\null
\end{matrix}\hfill $\ \ (3.11.15)
\end{russian}}

{\begin{russian}\sffamily
Матрица динамики \ наблюдателя в базисе ИКП в соответствии с уравнением (3.11.14) имеет вид
\end{russian}}

\begin{equation*}
L_I=\left[\begin{matrix}0&0&0&\ldots &0&0&-α_n\\1&0&0&\ldots &0&0&-α_{n-1}\\0&1&0&\ldots &0&0&-α_{n-2}\\\ldots &\ldots
&\ldots &\ldots &\ldots &\ldots &\ldots \\0&0&0&\ldots &1&0&-α_2\\0&0&0&\ldots
&0&1&-α_1\end{matrix}\right]-\left[\begin{matrix}0&0&\ldots &0&K_{\mathit{I1}}\\0&0&\ldots
&0&K_{\mathit{I2}}\\0&0&\ldots &0&K_{\mathit{I3}}\\\ldots &\ldots &\ldots &\ldots &\ldots \\0&0&\ldots
&0&K_{\normalsubformula{\text{In}}-1}\\0&0&\ldots &0&K_{\normalsubformula{\text{In}}}\end{matrix}\right]=
\end{equation*}
{\begin{russian}\sffamily
\ \ \ \  $=\left[\begin{matrix}0&0&0&\ldots &0&0&-β_n\\1&0&0&\ldots &0&0&-β_{n-1}\\\ldots &\ldots &\ldots &\ldots
&\ldots &\ldots &\ldots \\0&0&0&\ldots &1&0&-β_2\\0&0&0&\ldots &0&1&-β_1\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
где  $β_j$ – коэффициенты характеристического полинома наблюдателя, которые вычисляются на основании желаемых
собственных чисел наблюдателя  $λ_i^N$ согласно выражению
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_L\left(λ\right)=\overset n{\underset{i=1}{\prod }}\left(λ-λ_i^N\right)=λ^n+β_1λ^{n-1}+...+β_n$.\ \ (3.11.16)
\end{russian}}

{\begin{russian}\sffamily
Очевидно выражение для элементов матрицы  $K$ в базисе ИКП:
\end{russian}}

{\begin{russian}\sffamily
\ \  $k_{I\;j}=β_{n+1-j}-α_{n+1-j}$, \ \  $j=1\;,\;\;2\;,\;\;...\;,\;\;n$.\ \ (3.11.17)
\end{russian}}

{\begin{russian}\sffamily
Перевод матрицы  $K$ в исходный или какой-либо другой базис может быть произведён в соответствии с выражением (3.11.15)
с использованием (3.7.13).
\end{russian}}


\bigskip

{\begin{russian}\sffamily
ПРИМЕР 3.11.1. Построить наблюдатель полного порядка для объекта со структурной схемой, приведённой на рис. 3.18.
\end{russian}}

{\centering  \includegraphics[width=9.869cm,height=5.239cm]{1-img088.png} \par}
{\begin{russian}\sffamily
\ \ Запишем матрицы объекта в исходном базисе:
\end{russian}}

{\begin{russian}\sffamily
 $A=A_H=\left[\begin{matrix}-2&1\\0&-1\end{matrix}\right]$, \ \  $\vec b=\vec
b_H=\left[\begin{matrix}0\\1\end{matrix}\right]$, \ \  $C=C_H=\left[\begin{matrix}1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Характеристический полином объекта (матрицы динамики  $A$)
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_A(λ)=(λ-λ_1)(λ-λ_2)=λ^2+3λ+2$,
\end{russian}}

{\begin{russian}\sffamily
его коэффициенты
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $α_1=3\;;\;\;\;\;\;\;\;\;α_2=2$,
\end{russian}}

{\begin{russian}\sffamily
нули (собственные числа)
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_1=-1\;;\;\;\;\;\;\;λ_2=-2$.
\end{russian}}

{\begin{russian}\sffamily
Время переходного процесса в объекте определяется наиболее близким к мнимой оси собственным числом  $λ_1$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $t_{\text{рег}}\approx \frac 3{-λ_1}_1=3c$.
\end{russian}}

{\begin{russian}\sffamily
Зададим собственные числа наблюдателя
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_1^N=λ_2^N=-3$.
\end{russian}}

{\begin{russian}\sffamily
Им соответствует характеристический полином наблюдателя
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_L(λ)=(λ+3)^2=λ^2+6λ+9$,
\end{russian}}

{\begin{russian}\sffamily
его коэффициенты
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $β_1=6\;;\;\;\;\;\;\;\;\;β_2=9$.
\end{russian}}

{\begin{russian}\sffamily
\ \ В соответствии с (3.11.17) определяем элементы матрицы  $K$ и саму эту матрицу в базисе ИКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}k_{i\;1}=β_2-α_2=7\;;\hfill\null \\k_{i\;2}=β_1-α_1=3\;;\hfill\null \end{matrix}\hfill $ \ \ \ 
$K_I=\left[\begin{matrix}7\\3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Для того чтобы перевести матрицу  $K$ в исходный базис, рассчитаем матрицу наблюдаемости и обратную ей в исходном
базисе:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $N_H=\left[\begin{matrix}1&0\\-2&1\end{matrix}\right]$; \ \ \ \ \ 
$N_H^{-1}=\left[\begin{matrix}1&0\\2&1\end{matrix}\right]$;
\end{russian}}

{\begin{russian}\sffamily
\ учитывая представление в базисе ИКП
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_I=\left[\begin{matrix}0&1\end{matrix}\right]$; \  $A_I=\left[\begin{matrix}0&-2\\1&-3\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
рассчитаем в этом базисе матрицу наблюдаемости
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $N_I=\left[\begin{matrix}0&1\\1&-3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (3.11.13) вычислим матрицу перехода от исходного базиса \ \  $[h]$ к базису ИКП  $[i]$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $I_H=N_H^{-1}N_I=\left[\begin{matrix}0&1\\1&-1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Используя (3.11.15), получим матрицу  $K$ в исходном базисе
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $K_H=I_HK_I=\left[\begin{matrix}3\\4\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Теперь можно заняться уравнением наблюдателя в исходном базисе. В соответствии с (3.11.9) имеем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_H=A_H-K_HC_H=\left[\begin{matrix}-5&1\\-4&-1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Учитывая (3.11.17), запишем, опуская далее индекс исходного базиса:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}=L\cdot \vec x+\normalsubformula{\text{Bu}}+\normalsubformula{\text{Ky}}$.\ \ (3.11.18)
\end{russian}}

{\begin{russian}\sffamily
Тогда уравнение наблюдателя будет иметь вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\left.\hat{\dot x}_1=-5\hat x_1+\hat x_2+3y?\right\}\left.\hat{\dot x}_2=-4\hat x_1-\hat
x_2+4y+u?\right.\mathit{rbra}\hfill\null \end{matrix}$.
\end{russian}}


\bigskip

\subsubsection{Наблюдатель пониженного порядка}
\hypertarget{RefHeadingToc455659751}{}
\bigskip

{\begin{russian}\sffamily
Из предыдущего примера четко видно, что искать  $\hat x_1$ было излишне, так как  $y=x_1$. В тех случаях, когда
некоторые координаты вектора  $\vec y$ совпадают с какими-либо из координат вектора  $\vec x$, то очевидно, что
рассматриваемый \ выше наблюдатель – наблюдатель полного порядка - выдает излишнюю информацию. Рассмотрим, каким
образом можно получить наблюдатель с более простыми алгоритмами, полностью использующими информацию о векторе состояния
 $\vec x$, имеющуюся в векторе выхода  $\vec y$. В более общем случае, когда вектор  $\vec y$ имеет размерность  $n_y$,
оказывается достаточным построить наблюдатель, порядок которого равен  $n-n_y$.
\end{russian}}

{\begin{russian}\sffamily
Пусть вектор  $\vec y$ имеет размерность  $n_y$ и связан с вектором  $\vec x$ равенством
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \   $\vec y=C\vec x$,\ \ (3.11.19)
\end{russian}}

{\begin{russian}\sffamily
или
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \ 
$\begin{matrix}\left.y_1=c_{11}x_1+c_{12}x_2+...+c_{1n}x_n?\right\}\left.y_2=c_{21}x_1+c_{22}x_2+...+c_{2n}x_n?\right\}\left.\cdot
\cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot
\cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot \cdot
?\right\}\left.y_{\normalsubformula{\text{ny}}}=c_{\normalsubformula{\text{ny}},1}x_1+c_{\normalsubformula{\text{ny}},2}x_2+...+c_{\normalsubformula{\text{ny}},n}x_n?\right.\mathit{rbra}\hfill\null
\end{matrix}$.\ \ (3.11.20)
\end{russian}}


\bigskip

{\begin{russian}\sffamily
Если  $x_1,x_2,...,x_n$ рассматривать как неизвестные, то здесь мы имеем  $n$ неизвестных и  $n_y<n$ уравнений. Таким
образом, недостаёт  $\left(n-n_y\right)$ уравнений. Полагаем, что \  $\normalsubformula{\text{rankC}}=n_y$, т. е. все
строки матрицы  $C$ линейно независимы. Введем  $\left(n-n_y\right)$- мерный вектор  $\vec q$, дополнив матрицу  $C$ до
квадратной невырожденной матрицы  $C_p$ с помощью матрицы  $C_q$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \ \  $C_р=\left[\begin{matrix}C\\C_q\end{matrix}\right]$.\ \ (3.11.21)
\end{russian}}

{\begin{russian}\sffamily
Запишем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\left[\begin{matrix}\vec y\\\vec q\end{matrix}\right]=\left[\begin{matrix}C\\C_q\end{matrix}\right]\vec
x$,\ \ (3.11.22)
\end{russian}}

{\begin{russian}\sffamily
откуда следует
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=C_p^{-1}\left[\begin{matrix}\vec y\\\vec q\end{matrix}\right]$.\ \ (3.11.23)
\end{russian}}

{\begin{russian}\sffamily
Обозначим 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_p^{-1}=\left[\begin{matrix}F_{y_{\;[n\times n_y]}}&F_{q\;\;[_{n\times (n-n_y)]}}\end{matrix}\right]$
,\ \ (3.11.24)
\end{russian}}

{\begin{russian}\sffamily
тогда\ \ \ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=F_y\vec y+F_q\vec q$. \ \ \ (3.11.25)
\end{russian}}

{\begin{russian}\sffamily
Если удастся найти оценку  $\vec{\hat q}$ вектора  $\vec q$, то можно будет вычислить оценку вектора состояния \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\hat x}=F_y\vec y+F_q\vec{\hat q}$. \ \ (3.11.26)
\end{russian}}

{\begin{russian}\sffamily
Так как  $\vec q=C_q\vec x$, \ то \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot q}=C_qA\vec x+C_qB\vec u$.\ \ (3.11.27)
\end{russian}}

{\begin{russian}\sffamily
Подставим сюда  $\vec x$ из (3.11.26):
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot q}=C_q\normalsubformula{\text{AF}}_y\vec y+C_q\normalsubformula{\text{AF}}_q\vec q+C_qB\vec
u$.\ \ (3.11.28)
\end{russian}}

{\begin{russian}\sffamily
Построим наблюдатель для вектора  $\vec q$. В последнем уравнении векторы  $\vec u$ и  $\vec y$ выступают в качестве
входов. Если попытаться коррекцию наблюдателя ввести традиционным образом:  $K\;\left(\vec y-\vec y\right)$, то получим
\end{russian}}


\bigskip

{\begin{russian}\sffamily
\ \ \ \  $\vec{\hat y}=C\vec{\hat x}=\normalsubformula{\text{CF}}_y\vec y+\normalsubformula{\text{CF}}_q\vec{\hat
q}$.\ \ (3.11.29)
\end{russian}}

{\begin{russian}\sffamily
Но из (3.11.21) и (3.11.24) имеем
\end{russian}}

{\begin{russian}\sffamily
\ \  
$С_pC_p^{-1}=\left[\begin{matrix}C\\C_q\end{matrix}\right]\left[\begin{matrix}F_y&F_q\end{matrix}\right]=\left[\begin{matrix}\normalsubformula{\text{CF}}_y&\normalsubformula{\text{CF}}_q\\C_qF_y&C_qF_q\end{matrix}\right]=E_n$,
\end{russian}}

{\begin{russian}\sffamily
откуда должно следовать  $\normalsubformula{\text{CF}}_y=E_{\normalsubformula{\text{ny}}}$ ; 
$\normalsubformula{\text{CF}}_q=0$, то есть  $\vec{\hat y}=\vec y$ и информации о  $\vec q$ здесь нет. Поэтому примем
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot q}=C_q\normalsubformula{\text{AF}}_q\vec q+C_qB\vec u+C_q\normalsubformula{\text{AF}}_y\vec
y+K\;\left(\vec{\dot y}-\vec{\dot y}\right)$.\ \ (3.11.30)
\end{russian}}

{\begin{russian}\sffamily
\ \ Проведем необходимые преобразования. Так как
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot y}=C\vec{\dot x}=\normalsubformula{\text{СA \{}}\hat{\normalsubformula x}+\normalsubformula{\text{СB
\{}}\vec{\normalsubformula u}$,
\end{russian}}

{\begin{russian}\sffamily
\ то с учетом (3.11.26) получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\hat{\dot y}}=\normalsubformula{\text{CAF}}_y\vec y+\normalsubformula{\text{CAF}}_q\vec{\hat
q}+\normalsubformula{\text{CB \{}}\vec{\normalsubformula u}$.\ \ (3.11.31)
\end{russian}}

{\begin{russian}\sffamily
Проследим за поведением ошибки оценки
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \   $Δ\vec q(t)=\vec q(t)-\vec{\hat q}(t)$.
\end{russian}}

{\begin{russian}\sffamily
Используя полученные выше выражения для  $\vec{\dot q}$ и  $\vec{\hat{\dot q}}$ - (3.11.28) и (3.11.30), получим:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Δ\vec{\dot q}=C_q\normalsubformula{\text{AF}}_qΔ\vec q-K\;\left(\vec{\dot y}-\vec{\dot y}\right)$.
\end{russian}}

{\begin{russian}\sffamily
Вычислим разность  $\vec{\dot y}-\vec{\hat{\dot y}}$:
\end{russian}}

\begin{equation*}
\begin{matrix}\underset{\text{\_\_\_}}{}\text{   \{}\vec{\dot{\normalsubformula y}}=C\vec{\dot
x}=\normalsubformula{\text{CA \{}}\vec{\normalsubformula x}\hfill\null \end{matrix}+\normalsubformula{\text{CB
\{}}\vec{\normalsubformula u}=\normalsubformula{\text{CAF}}_y\vec y+\normalsubformula{\text{CAF}}_q\vec
q+\normalsubformula{\text{CB \{}}\vec{\normalsubformula u}\hfill 
\end{equation*}
{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot y}-\vec{\hat{\dot y}}=\normalsubformula{\text{CAF}}_y(\vec y-\vec{\hat
y})+\normalsubformula{\text{CAF}}_qΔ\vec q$.
\end{russian}}

{\begin{russian}\sffamily
Так как выше было показано, что  $\vec{\hat y}=\vec y$, то окончательно получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $Δ\vec{\dot q}(t)=L^qΔ\vec q$,\ \ (3.11.32)
\end{russian}}

{\begin{russian}\sffamily
где матрица наблюдателя
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L^q=C_q\normalsubformula{\text{AF}}_q-\normalsubformula{\text{KCAF}}_q$.\ \ (3.11.33)
\end{russian}}


\bigskip


\bigskip

{\begin{russian}\sffamily
Очевидно, что можно «заказать динамику обнуления ошибки», вы­бирая  $К$ ( $C_q\normalsubformula{\text{AF}}_q$ и 
$\normalsubformula{\text{CAF}}_q$ - заданные матрицы). Матрицу  $К$ следует выбирать таким образом, чтобы обеспечить
заданное расположение собственных чисел наблюдателя. Если, например,  $n_y=1$, то  $C_q\normalsubformula{\text{AF}}_q$
имеет размер  $\left[\left(n-n_y\right)\times \left(n-n_y\right)\right]$, а  $\normalsubformula{\text{CAF}}_q$- 
$\left[1\times \left(n-n_y\right)\right]$ и  $К$-  $\left[\left(n-n_y\right)\times 1\right]$. В этом случае задача
решается аналогично расчету наблюдателя полного порядка со скалярным выходом.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, рассчитав собственные значения матрицы  $C_q\normalsubformula{\text{AF}}_q$, задавшись желаемыми
собственными значениями наблюдателя пониженного порядка и получив соответствующие значения коэффициентов его
характеристического полинома, легко записать выражение для матрицы  $K$ в базисе идентификационного канонического
представления. После этого потребуется перевести матрицу  $К$ в исходный базис. Если известна пара матриц 
$\left\{C_q\normalsubformula{\text{AF}}_q,\normalsubformula{\text{CAF}}_q\right\}$, то через матрицы наблюдаемости в
исходном базисе и в базисе идентификационного канонического представления  $N_h$ и  $N_I$, причем  $N_h$ должна быть
построена с использованием пары матриц 
$\left\{C_q\normalsubformula{\text{AF}}_q,\normalsubformula{\text{CAF}}_q\right\}$, можно найти матрицу перехода от
базиса  $[i]$ к исходному базису  $[h]$.
\end{russian}}

{\begin{russian}\sffamily
Теперь следует позаботиться о реализуемости алгоритма наблюдателя. Из уравнения (3.11.30) с учетом (3.11.25) получим
\ \ 
\end{russian}}

{\begin{russian}\sffamily
 $\vec{\dot q}=L^q\vec{}q+\left(C_qB-\normalsubformula{\text{KCB}}\right)\vec
u+\left(C_q\normalsubformula{\text{AF}}_y-\normalsubformula{\text{KCAF}}_y\right)\vec y+K\;\vec{\dot y}$.\ \ (3.11.34)
\end{russian}}

{\begin{russian}\sffamily
Это уравнение \ для реализации не годится, так как в случае его использования пришлось бы осуществлять операции
дифференцирования вектора  $\vec y(t)$. В реальных условиях на вектор выхода объекта, как правило, наложены шумы
измерений и другой физической природы. Эти шумы характеризуются широким спектром, и дифференцирование существенно
увеличивает шумовую составляющую в выходном сигнале.
\end{russian}}

{\begin{russian}\sffamily
Для того чтобы не решать задачу измерения  $\vec{\dot y}$, введем новую переменную  $\vec ξ=\vec q-k\vec y$, тогда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \   $\vec q=\vec ξ+k\vec y$.\ \ (3.11.35)
\end{russian}}

{\begin{russian}\sffamily
Проведем соответствующую замену в (3.11.34) и в результате получим \ первое уравнение наблюдателя
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot ξ}=L^q\vec{}ξ+\left(C_qB-\normalsubformula{\text{KCB}}\right)\vec
u+\left(L^qK+C_q\normalsubformula{\text{AF}}_y-\normalsubformula{\text{KCAF}}_y\right)\vec y$.\ \ (3.11.36)
\end{russian}}

{\begin{russian}\sffamily
Теперь из уравнений (3.11.30) и (3.11.35) имеем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\hat x}=F_y\vec y+F_q\vec{\hat q}=F_y\vec y+F_q\vec ξ+F_qK\vec y$,
\end{russian}}

{\begin{russian}\sffamily
или
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x=(F_y+F_qK)\vec y+F_q\vec ξ$.\ \ (3.11.37)
\end{russian}}

{\begin{russian}\sffamily
Это - второе уравнение наблюдателя. Таким образом, получено уравнение оценки  $\vec{\hat x}$ вектора  $\vec x$ с помощью
наблюдателя пониженного порядка.
\end{russian}}


\bigskip

\subsubsection{Наблюдатель Люенбергера минимального порядка}
\hypertarget{RefHeadingToc455659752}{}{\begin{russian}\sffamily
Рассмотрим ещё один подход к формированию наблюдателя. Так же, как в п.3.11.2, сформируем матрицы  $C_q$,  $C_p$ и
введём вектор 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec q(t)=C_q\vec x(t)$.\ \ (3.11.38)
\end{russian}}

{\begin{russian}\sffamily
Оценку вектора  $\vec q(t)$ будем искать как решение уравнения 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot q}(t)=L^q\vec q(t)+G^y\vec y(t)+G^u\vec u(t)$,\ \ (3.11.39)
\end{russian}}

{\begin{russian}\sffamily
где  $L^q$,  $G^y$ и  $G^u$ - некоторые, пока неизвестные матрицы.
\end{russian}}

{\begin{russian}\sffamily
\ \ Как и прежде, ошибкой оценки вектора  $\vec q$ будем считать разность
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec Δ_q(t)=\vec q(t)-\vec q(t)$.\ \ (3.11.40)
\end{russian}}

{\begin{russian}\sffamily
В соответствии с уравнением объекта и выражением (3.11.38) запишем:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot q}(t)=C_qA\vec x(t)+C_qB\vec u(t)$.\ \ (3.11.41)
\end{russian}}

{\begin{russian}\sffamily
Найдём дифференциальное уравнение для ошибки  $Δ\vec q(t)$:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec{\dot Δ}_q(t)=C_qA\vec x(t)+C_qB\vec u(t)-L^q\vec q(t)-G^y\vec y(t)-G^u\vec u(t)$.\ \ (3.11.42)
\end{russian}}

{\begin{russian}\sffamily
Добавим и вычтем в правой части последнего равенства  $L^q\vec q$ и с учётом \ (3.11.38) получим
\end{russian}}

{\begin{russian}\sffamily
 $\vec{\dot Δ}_q(t)=L^q\vec Δ_q(t)+(C_qB-G^u)\vec u(t)+(C_qA-G^yC-L^qC_q)\vec x(t)$.\ \ (3.11.43)
\end{russian}}

{\begin{russian}\sffamily
Положим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $G^u=C_qB$\ \ (3.11.44)
\end{russian}}

{\begin{russian}\sffamily
и потребуем выполнения равенства
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_qA-G^yC-L^qC_q=0$.\ \ (3.11.45)
\end{russian}}

{\begin{russian}\sffamily
Тогда получим уравнение для ошибки наблюдателя
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot Δ}_q(t)=L^q\vec Δ_q(t)$.\ \ (3.11.46)
\end{russian}}

{\begin{russian}\sffamily
Если \ назначить матрицу  $L^q$ так, чтобы её собственные числа лежали в левой полуплоскости достаточно далеко от мнимой
оси, то ошибка на
\end{russian}}

{\begin{russian}\sffamily
блюдателя, имеющая изначально место при ненулевых начальных условиях, будет с соответствующей скоростью стремиться к
нулю. Так же быстро вектор
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec x(t)=C_p^{-1}\left[\begin{matrix}\vec y\\\vec q\end{matrix}\right]$\ \ (3.11.47)
\end{russian}}

{\begin{russian}\sffamily
будет стремиться к вектору  $\vec x(t)$. Вытекающее из (3.11.45) уравнение
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_qA-L^qC_q=G^yC$\ \ (3.11.48)
\end{russian}}

{\begin{russian}\sffamily
называется \textit{матричным уравнением Люенбергера}.
\end{russian}}

{\begin{russian}\sffamily
\ \ Теперь учтём, что задача построения наблюдателя, то есть нахождения оценки  $\vec x$ вектора состояния  $\vec x$,
возникла из-за необходимости реализовать управление
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec u(t)=L\vec x(t)+k^v\vec v(t)$.\ \ (3.11.49)
\end{russian}}

{\begin{russian}\sffamily
Сама по себе оценка вектора состояния часто не нужна. Поэтому попытаемся найти оценку  $\overset{\wedge }{L\vec x}$
линейной комбинации координат вектора состояния  $L\vec x$. Будем искать эту оценку в виде
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\overset{\wedge }{L\vec x}(t)=χ\vec q(t)+η\vec y(t)$.\ \ (3.11.50)
\end{russian}}

{\begin{russian}\sffamily
Так как с течением времени  $\vec q$ стремится к  $\vec q$, то с учётом \ (3.11.38) и уравнения выхода объекта получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\overset{\wedge }{L\vec x}(t)=\mathit{χC}_q\vec x(t)+\mathit{ηC}\vec x(t)$,\ \ (3.11.51)
\end{russian}}

{\begin{russian}\sffamily
откуда следует
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L=\mathit{χC}_q+\mathit{ηC}$.\ \ (3.11.52)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, необходимо решить следующую систему матричных уравнений:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}C_qA-L^qC_q=G^yC\;;\hfill\null \\\mathit{χC}_q+\mathit{ηC}=L\;.\hfill\null \end{matrix}\hfill
$\ \ (3.11.53)
\end{russian}}

{\begin{russian}\sffamily
Эта система всегда имеет решение, если, во-первых, собственные числа матриц  $L^q$ и  $A$ не совпадают друг с другом и,
во-вторых, размерность вектора  $\vec q$ (размерность матрицы наблюдателя  $L^q$)\ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $s\ge n_u(ν-1)$,\ \ (3.11.54)
\end{russian}}

{\begin{russian}\sffamily
где  $n_u$ - размер вектора управления;  $ν$ - индекс наблюдаемости. Это такое число, для которого матрица
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\tilde  N=\left[\begin{matrix}C\\\normalsubformula{\text{CA}}\\\cdots
\\\normalsubformula{\text{CA}}^{ν-1}\end{matrix}\right]$\ \ (3.11.55)
\end{russian}}

{\begin{russian}\sffamily
имеет ранг, равный  $n$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Таким образом, может быть сформулирован следующий итоговый алгоритм.
\end{russian}}

\liststyleWWviiiNumxi
\begin{enumerate}
\item {\begin{russian}\sffamily
Найти индекс наблюдаемости  $ν$ и размерность наблюдателя  $s$.
\end{russian}}
\item {\begin{russian}\sffamily
Задать желаемую динамику наблюдателя и записать матрицу его динамики  $L^q$ в виде матрицы, сопровождающей свой
характеристический полином.
\end{russian}}
\item {\begin{russian}\sffamily
Вычислить матрицы  $C_q\;,\;\;G^y\;,\;\;χ\;,\;\;η$ \ согласно (3.11.53), а также матрицу  $G^u$ согласно (3.11.44).
\end{russian}}
\item {\begin{russian}\sffamily
Реализовать алгоритмы регулятора, включая наблюдатель Люенбергера минимального порядка:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\vec{\dot q}(t)=L^q\vec q(t)+G^y\vec y(t)+G^u\vec u(t)\;;\hfill\null \\\vec u(t)=χ\vec
q(t)+η\vec y(t)\;+k^v\vec v(t).\hfill\null \end{matrix}\hfill $\ \ (3.11.56)
\end{russian}}

\clearpage\subsection[Синтез реализуемого управления, обеспечивающий заданные динамические и статические свойства
\ \ \ \ \ \ \ \ системы управления]{Синтез реализуемого управления, обеспечивающий заданные динамические и статические
свойства \ \ \ \ \ \ \ \ системы управления}
\hypertarget{RefHeadingToc455659753}{}\subsubsection[Динамические свойства системы с обратной связью
\ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем полного порядка ]{Динамические свойства системы с обратной связью
\ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем полного порядка }
\hypertarget{RefHeadingToc455659754}{}
\bigskip

{\begin{russian}\sffamily
Предполагается, что известны уравнения управляемого и наблюдаемого объекта:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\begin{matrix}\left\{\vec{\dot x}(t)=A\vec x(t)+B\vec u(t);?\right.\left\{\vec y(t)=C\vec
x(t).?\right.\mathit{no}\hfill\null \end{matrix}\{?$\ \ (3.12.1)
\end{russian}}

{\begin{russian}\sffamily
Кроме того, проведён синтез управления и получены матрица  $L$ и коэффициент  $k^v$ для равенства
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec u(t)=L\vec x(t)+k^v\vec v(t)$,\ \ (3.12.2)
\end{russian}}

{\begin{russian}\sffamily
обеспечивающего желаемые собственные числа замкнутой системы  $λ_1^з,\text{  }λ_2^з,...λ_n^з$, или нули
характеристического полинома замкнутой системы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ϕ_{A^C}(λ)=λ^n+γ_1λ^{n-1}+...+γ_{n-1}λ+γ_n$.\ \ (3.12.3)
\end{russian}}

{\begin{russian}\sffamily
Предполагается также, что \ имеется наблюдатель
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\dot x}(t)=(A-\normalsubformula{\text{KC}})\vec x(t)+B\vec u(t)+K\vec y(t)$,\ \ (3.12.4)
\end{russian}}

{\begin{russian}\sffamily
спроектированный таким образом, что его характеристический поли­ном  $ϕ_L(λ)$ имеет коэффициенты  $β_1,\text{ 
}β_2,...β_n$, соответствующие некоторой выбранной совокупности собственных чисел 
$λ_1^N,\;\;λ_2^N,\;\;...\;,\;\;λ_n^N\;\;$.
\end{russian}}

{\begin{russian}\sffamily
Учтём, что при формировании управления фактически можно воспользоваться не самим вектором состояния  $\vec x$, а лишь
его оценкой  $\vec x$, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec u(t)=L\vec x(t)+k^v\vec v(t)$.\ \ (3.12.5)
\end{russian}}

{\begin{russian}\sffamily
\ \ Таким образом, рассматривается функциональная схема полной системы (объект, формирователь управления и наблюдатель),
представленная на рис. 3.19.
\end{russian}}

{\begin{russian}\sffamily
Запишем уравнения этой системы, то есть совместно уравнения объекта с управлением и наблюдателя: 
\end{russian}}

{\begin{russian}\sffamily
\ \  $\begin{matrix}\left\{\vec{\dot x}(t)=A\vec x(t)+\normalsubformula{\text{BL \{}}\vec{\normalsubformula
x}?(t)+\normalsubformula{\text{Bk}}^v\vec v(t);?\right.\left\{\vec{\dot x}(t)=(A-\normalsubformula{\text{KC}})\vec
x(t)+\normalsubformula{\text{BL \{}}\vec{\normalsubformula x}?(t)+\normalsubformula{\text{Bk}}^v\vec
v(t)+\normalsubformula{\text{KC \{}}\vec{\normalsubformula x}?(t).?\right.\mathit{no}\hfill\null
\end{matrix}\{?$\ \ (3.12.6)
\end{russian}}


\bigskip

{\centering  \includegraphics[width=12.806cm,height=6.297cm]{1-img089.png} \par}
{\begin{russian}\sffamily
С использованием блочных матриц получим
\end{russian}}

{\begin{russian}\sffamily
\ \  $\left[\begin{matrix}\vec{\dot x}(t)\\\vec{\dot
x}(t)\end{matrix}\right]=\left[\begin{matrix}A&\normalsubformula{\text{BL}}\\\normalsubformula{\text{KC}}&A-\normalsubformula{\text{KC}}+\normalsubformula{\text{BL}}\end{matrix}\right]\left[\begin{matrix}\vec
x(t)\\\vec
x(t)\end{matrix}\right]+\left[\begin{matrix}\normalsubformula{\text{Bk}}^v\\\normalsubformula{\text{Bk}}^v\end{matrix}\right]\vec
v(t)$.\ \ (3.12.7)
\end{russian}}

{\begin{russian}\sffamily
Поведение этой системы зависит от собственных чисел матрицы динамики полной системы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$X=\left[\begin{matrix}A&\normalsubformula{\text{BL}}\\\normalsubformula{\text{KC}}&A-\normalsubformula{\text{KC}}+\normalsubformula{\text{BL}}\end{matrix}\right]$.\ \ (3.12.8)
\end{russian}}

{\begin{russian}\sffamily
Надо попытаться для  $X$ найти некоторую подобную матрицу, такую, чтобы можно было \ легко определить её собственные
числа. Перейдём к подобной матрице с помощью преобразования
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $X_f=?F_h^{-1}X_hF_h$.\ \ (3.12.9)
\end{russian}}

{\begin{russian}\sffamily
Матрицу  $F_h$ выберем следующей:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=\left[\begin{matrix}E_n&0_n\\E_n&-E_n\end{matrix}\right]$,\ \ (3.12.10)
\end{russian}}

{\begin{russian}\sffamily
где индекс  $n$ указывает на размеры соответствующих нулевой и единичных матриц. Легко убедиться, что 
$F_{h^{-1}}=?F_h$. В результате полу­чим
\end{russian}}

{\begin{russian}\sffamily

$X_f=\left[\begin{matrix}E_n&0\\E_n&-E_n\end{matrix}\right]\left[\begin{matrix}A&\normalsubformula{\text{BL}}\\\normalsubformula{\text{KC}}&A-\normalsubformula{\text{KC}}+\normalsubformula{\text{BL}}\end{matrix}\right]\left[\begin{matrix}E_n&0\\E_n&-E_n\end{matrix}\right]=\left[\begin{matrix}A+\normalsubformula{\text{BL}}&-\normalsubformula{\text{BL}}\\0&A-\normalsubformula{\text{KC}}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Характеристический полином матрицы  $X$ не зависит от базиса и определяется следующим образом:
\end{russian}}

{\begin{russian}\sffamily
\ \  $ϕ_X(λ)=\text{det}\left[\mathit{λE}_{2n}-?X\right]=|\mathit{λE}_n-(A+\normalsubformula{\text{BL}})|\cdot
|\mathit{λE}_n-(A-\normalsubformula{\text{KC}})|$.\ \  $ $
\end{russian}}

{\begin{russian}\sffamily
Отсюда следует
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ϕ_X(λ)=ϕ_{A^C}(λ)ϕ_L(λ)$.\ \ (3.12.11)
\end{russian}}

{\begin{russian}\sffamily
Таким образом, полная система, в которой управление вычисляется в функции оценки вектора состояния, имеет  $2n$
собственных чисел:  $λ_1^з,\text{  }λ_2^з,...λ_n^з$,  $λ_1^N,\text{  }λ_2^N,...λ_n^N$. Собственные числа замкнутой
системы сохранили те значения, которые были заданы при синтезе \ управления.
\end{russian}}

{\begin{russian}\sffamily
Отметим, что в полной системе передаточная функция от ко­мандного сигнала  $\vec v$ до выходного сигнала  $\vec
y$\textit{ }тождественно равна передаточной функции в идеализированной системе без наблю­дателя. Это действительно так,
потому что по определению передаточная функция связывает изображения соответствующих переменных при нулевых начальных
условиях. При нулевых началь­ных условиях выход объекта  $\vec y$\textit{ }и выход \textit{\ }наблюдателя  $\vec y$
тождественно равны.
\end{russian}}


\bigskip

\subsubsection[Динамические свойства системы с обратной связью \ \ \ \ \ управлением и наблюдателем минимального
порядка]{Динамические свойства системы с обратной связью \ \ \ \ \ управлением и наблюдателем минимального порядка}
\hypertarget{RefHeadingToc455659755}{}{\begin{russian}\sffamily
В случае использования наблюдателя \ минимального порядка в соответствии с \ (3.11.56) и (3.11.44) уравнения регулятора
имеют вид
\end{russian}}

\begin{equation*}
\begin{matrix}\vec{\dot q}(t)=L^q\vec q(t)+G^y\vec y(t)+C_qB\vec u(t)\;;\hfill\null \\\vec u(t)=χ\vec q(t)+η\vec
y(t)+k^v\vec v(t)\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
С учётом управления запишем совместно уравнения объекта и наблюдателя:
\end{russian}}

{\begin{russian}\sffamily
 $\begin{matrix}\vec{\dot x}(t)=A\vec x(t)+\mathit{BηC}\vec x(t)+\mathit{Bχ}\vec q(t)+\normalsubformula{\text{Bk}}^v\vec
v(t)\;;\hfill\null \\\vec{\dot q}(t)=G^yC\vec x(t)+C_q\mathit{BηC}\vec x(t)+L^q\vec q(t)+C_q\mathit{Bχ}\vec
q(t)+C_q\normalsubformula{\text{Bk}}^v\vec v(t)\;.\hfill\null \end{matrix}\hfill $\ \ (3.12.12)
\end{russian}}

{\begin{russian}\sffamily
Отсюда матрица динамики полной системы имеет вид
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$X=\left[\begin{matrix}A+\mathit{BηC}&\mathit{Bχ}\\G^yC+C_q\mathit{BηC}&L^q+C_q\mathit{Bχ}\end{matrix}\right]$.\ \ (3.12.13)
\end{russian}}

{\begin{russian}\sffamily
Перейдём к подобной матрице с помощью преобразования (3.12.9), где
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_e=F_e^{-1}=\left[\begin{matrix}E_n&0\\C_q&-E_s\end{matrix}\right]$.\ \ (3.12.14)
\end{russian}}

{\begin{russian}\sffamily
В результате, учитывая (3.11.52) и (3.11.48), \ получим
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $X_f=\left[\begin{matrix}A+\normalsubformula{\text{BL}}&-\mathit{Bχ}\\0&L_q\end{matrix}\right]$.\ \ (3.12.15)
\end{russian}}

{\begin{russian}\sffamily
Отсюда следуют те же выводы, что и полученные выше для системы с наб­­людателем полного порядка.
\end{russian}}


\bigskip

\subsubsection{Результирующий алгоритм синтеза для системы с одним входом и одним выходом}
\hypertarget{RefHeadingToc455659756}{}\liststyleWWviiiNumlxxix
\begin{enumerate}
\item {\begin{russian}\sffamily
Для матрицы объекта \textit{A }вычислить характеристический полином  $ϕ_A(λ)$ и зафиксировать его коэффициенты 
$α_1,\text{  }α_2,\text{  }...,\text{  }α_n$. 
\end{russian}}
\item {\begin{russian}\sffamily
В соответствии с требованиями к динамике замкнутой системы задать желаемые значения собственных чисел  $λ_1^з,\text{ 
}λ_2^з,...λ_n^з$, вычислить 
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $ϕ_{A^C}(λ)=\overset n{\underset{i=1}{\prod }}(λ+λ^3)$,\ \ 
\end{russian}}

{\begin{russian}\sffamily
то есть найти коэффициенты желаемого характеристического поли­нома  $γ_1,\text{  }γ_2,\text{  }...,\text{  }γ_n$.
\end{russian}}

\liststyleWWviiiNumxxvi
\begin{enumerate}
\item {\begin{russian}\sffamily
Рассчитать матрицу обратной связи в базисе УКП:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $L_U=\left[\begin{matrix}l_{u\;1}&l_{u\;2}&\cdot \cdot \cdot &l_{u\;n}\end{matrix}\right]$, \ \ где \ \ \ 
$l_{u\;j}=α_{n+1-j}-γ_{n+1-j}$.
\end{russian}}

\liststyleWWviiiNumxxix
\begin{enumerate}
\item {\begin{russian}\sffamily
Задать желаемые собственные числа наблюдателя  $λ_1^N,\;\;λ_2^N,\;\;...\;,\;\;λ_n^N$ и вы­числить коэффициенты
характеристического полинома наблюдателя  $β_1,\text{  }β_2,\text{  }...\text{  }β_n$.
\end{russian}}
\item {\begin{russian}\sffamily
Рассчитать матрицу обратной связи наблюдателя в базисе ИКП:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $\vec K_I=\left[\begin{matrix}k_{\mathit{I1}}\\k_{\mathit{I2}}\\k_{\mathit{I3}}\\\vdots
\\k_{\normalsubformula{\text{In}}}\end{matrix}\right]$, где  $k_{I\;j}=β_{n+1-j}-α_{n+1-j}$.
\end{russian}}

\liststyleWWviiiNumxliii
\begin{enumerate}
\item {\begin{russian}\sffamily
Рассчитать матрицу перехода от исходного базиса \ к базису УКП \  $U_h=\normalsubformula{\text{UU}}_U^{-1}$, \ матрицу
выхода в этом базисе  $C_U=CU_h$ и, при наличии требования обеспечить единичную статику, \ вычислить коэффициент по
командному сигналу  $k^v=\frac{γ_n}{C_{\mathit{U1}}}$.
\end{russian}}
\item {\begin{russian}\sffamily
Рассчитать матрицу перехода от \ базиса  $[u]$ (УКП) к базису  $[i]$ (ИКП) и обратную ей матрицу \  $I_U=N_U^{-1}\cdot
N_I$, см. (3.7.13).
\end{russian}}
\end{enumerate}
\liststyleWWviiiNumlix
\begin{enumerate}
\item {\begin{russian}\sffamily
Рассчитать вектор  $\vec b$ в базисе ИКП, используя переход от базиса УКП  $\vec b_I=I_U^{-1}\vec b_U$.
\end{russian}}
\item {\begin{russian}\sffamily
Рассчитать матрицу обратной связи  $L$ в базисе ИКП, используя переход от базиса  $[u]$ к базису  $[i]$:  $L_I=L_UI_U$.
\end{russian}}
\item {\begin{russian}\sffamily
Записать уравнение наблюдателя в базисе ИКП:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $\vec{\dot x}_I(t)=\left(A_I-\vec K_IC_I+\vec b_IL_I\right)\vec x_I(t)+\vec K_Iy(t)+\vec b_Ik^vv(t)$.\ \ 
\end{russian}}

\liststyleWWviiiNumxxx
\begin{enumerate}
\item {\begin{russian}\sffamily
Записать уравнение для формирования управления:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $u(t)=L_I\vec x_I(t)+k^vv(t)$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Уравнения, полученные в пунктах 10 и 11, – это уравнения регулятора. Следует подчеркнуть, что в них используется
вектор оценки \ состояния объекта, записанный не в исходном базисе, а в базисе идентификационного канонического
представления.
\end{russian}}


\bigskip

\subsubsection[Итоговые примеры полного синтеза систем управления]{Итоговые примеры полного синтеза систем управления}
\hypertarget{RefHeadingToc455659757}{}\paragraph[Система со скалярными входом и выходом
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем полного порядка]{Система со скалярными входом и выходом
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем полного порядка}
{\begin{russian}\sffamily
Задан объект, представленный структурной схемой на рис. 3.20.
\end{russian}}

{\centering  \includegraphics[width=11.43cm,height=4.119cm]{1-img090.png} \par}
{\begin{russian}\sffamily
Требуется синтезировать реализуемое управление, обеспечивающее единичную статику по командному сигналу, а также динамику
основного контура системы и наблюдателя в соответствии с желаемыми собственными числами
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_{1,2}^з=-5\pm \mathit{j5};$ \ \ \ \ \  $λ_1^N=λ_2^N=-10.$
\end{russian}}

{\begin{russian}\sffamily
Ниже приведены промежуточные результаты расчёта.
\end{russian}}

{\begin{russian}\sffamily
Матрица управляемости объекта и ей обратная в исходном базисе:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U=\left[\begin{matrix}0&1\\1&-1\end{matrix}\right]$; \ \ \ \ 
$U^{-1}=\left[\begin{matrix}1&1\\1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Матрица управляемости объекта и ей обратная в базисе УКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_U=\left[\begin{matrix}0&1\\1&-3\end{matrix}\right];$ \ \ 
$U_U^{-1}=\left[\begin{matrix}3&1\\1&0\end{matrix}\right]$.
\end{russian}}


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip

{\begin{russian}\sffamily
Коэффициенты характеристического полинома объекта, желаемой системы и наблюдателя: 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec α=\left[\begin{matrix}3\\2\end{matrix}\right]$; \ \ \ \ \ \ . $\vec
γ=\left[\begin{matrix}10\\50\end{matrix}\right]$; \ \ \ \ \ \ \ \ \  $\vec
β=\left[\begin{matrix}20\\100\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Матрица обратной связи в базисе УКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ \  $L_U=\left[\begin{matrix}-48&-7\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Матрица наблюдателя:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec K_I=\left[\begin{matrix}98\\17\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Матрица перехода от исходного базиса к базису УКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_H=\left[\begin{matrix}1&0\\2&1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Матрица выхода в базисе УКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_U=\left[\begin{matrix}1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Коэффициент по командному сигналу  $k^v=50$.
\end{russian}}

{\begin{russian}\sffamily
Матрица наблюдаемости в базисе УКП, обратная ей и та же матрица в базисе ИКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $N_U=N_U^{-1}=\left[\begin{matrix}1&0\\0&1\end{matrix}\right]$, \ \ \ 
$N_I=\left[\begin{matrix}0&1\\1&-3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Матрица перехода от базиса ИКП к базису УКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $U_I=\left[\begin{matrix}0&1\\1&-3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Вектор передачи управления в базисе ИКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec b_I=\left[\begin{matrix}1\\-3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Матрица обратной связи в базисе ИКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_I=\left[\begin{matrix}-7&-27\end{matrix}\right]$.
\end{russian}}


\bigskip


\bigskip


\bigskip

{\begin{russian}\sffamily
Матрица динамики наблюдателя в базисе ИКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_I=A_I-\vec K_IC_I=\left[\begin{matrix}0&-100\\1&-20\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Результирующие уравнения регулятора:
\end{russian}}

\begin{equation*}
\begin{matrix}\dot x_1=-\text{100 \{}\normalsubformula x_2+u+98y\;;\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
В этих уравнениях индекс  $i$ при координатах вектора оценки состояния опущен.
\end{russian}}


\bigskip

\paragraph[Система со скалярными входом и выходом \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем пониженного
порядка]{Система со скалярными входом и выходом \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем пониженного
порядка}
{\begin{russian}\sffamily
Для объекта, заданного на рис.3.20, построить наблюдатель пониженного порядка. Учесть, что управление объектом строится
на основе собственных чисел замкнутой системы  $λ_{1,2}^з=-5\pm 5j$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Для этого объекта\ \ 
\end{russian}}

{\begin{russian}\sffamily
\ \  $A=\left[\begin{matrix}-2&1\\0&-1\end{matrix}\right]\text{   ; 
}B=\left[\begin{matrix}0\\1\end{matrix}\right]\text{  ;  }C=\left[\begin{matrix}1&0\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
собственные числа объекта -
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_1=-1\;,\;\;\;\;\;\;\;\;λ_2=-2$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Порядок объекта  $n=2$, размерность выхода  $n_y=1$, следовательно, размерность наблюдателя пониженного порядка 
$n_q=1$.
\end{russian}}

{\begin{russian}\sffamily
Зададимся собственным числом \ наблюдателя  $λ_1^Н=-10$ (оно должно располагаться на комплексной плоскости левее
собственных чисел замкнутой системы).
\end{russian}}

{\begin{russian}\sffamily
Так как  $y=x_1$, то примем  $q=x_2$. Тогда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \ 
$\left[\begin{matrix}y\\q\end{matrix}\right]=\left[\begin{matrix}1&0\\0&1\end{matrix}\right]\left[\begin{matrix}x_1\\x_2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, выбрана матрица 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_q=\left[\begin{matrix}0&1\end{matrix}\right]$.
\end{russian}}


\bigskip


\bigskip


\bigskip


\bigskip

{\begin{russian}\sffamily
Ей соответствует невырожденная квадратная матрица
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $C_p=C_p^{-1}=\left[\begin{matrix}1&0\\0&1\end{matrix}\right]$. 
\end{russian}}

{\begin{russian}\sffamily
Соответственно получаем
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $F_y=\left[\begin{matrix}1\\0\end{matrix}\right]\text{  ;  }F_q=\left[\begin{matrix}0\\1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Теперь в соответствии с (3.11.33) определим  $L^q$:
\end{russian}}

{\begin{russian}\sffamily
\ \  $L^q=\left[\begin{matrix}0&1\end{matrix}\right]\cdot
\left[\begin{matrix}-2&1\\0&-1\end{matrix}\right]\left[\begin{matrix}0\\1\end{matrix}\right]-K\left[\begin{matrix}1&0\end{matrix}\right]\left[\begin{matrix}-2&1\\0&-1\end{matrix}\right]\left[\begin{matrix}0\\1\end{matrix}\right]=-1-K$.
\end{russian}}

{\begin{russian}\sffamily
Поскольку назначено  $λ^Н=-10$, то \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $-1-К=-10$ \ \ \ и \ \  $К=9$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом,  $L^q=-10$, и первое уравнение наблюдателя принимает вид
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\dot ξ=-10ξ-72y+u$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Запишем оценку для  $\vec x$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec{\hat
x}(t)=\left[\begin{matrix}1\\-9\end{matrix}\right]y(t)+\left[\begin{matrix}0\\1\end{matrix}\right]ξ=\left[\begin{matrix}\hat
x_1\\\hat x_2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Отсюда
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\hat x_2=9y+ξ$.
\end{russian}}

{\begin{russian}\sffamily
Замкнем систему (сформируем управление). В п.3.12.4.1 была рассчитана матрица обратной связи
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_U=\left[\begin{matrix}-48&-7\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Переведем её в исходный базис:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L=L_UU_e^{-1}=L_UU_UU_e^{-1}=\left[\begin{matrix}-34&-7\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, управление принимает вид \ 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $u=-34y-7x_2+50v$.
\end{russian}}

{\begin{russian}\sffamily
Структурная схема полной схемы с регулятором и \ наблюдателем пониженного порядка представлена на рис. 3.21.
\end{russian}}

{\centering  \includegraphics[width=11.748cm,height=8.89cm]{1-img091.png} \par}
\paragraph{Система со скалярными входом и выходом и наблюдателем минимального порядка}

\bigskip

{\begin{russian}\sffamily
\ \ Структурная схема объекта представлена на рис. 3.22.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=13.785cm,height=7.832cm]{1-img092.png} \par}
{\begin{russian}\sffamily
Ему соответствуют матрицы
\end{russian}}

{\begin{russian}\sffamily
\ \  $A=\left[\begin{matrix}0&1&0&0\\0&1&1&0\\0&0&-1&0\\0&0&1&-2\end{matrix}\right]$; \ 
$B=\left[\begin{matrix}0\\0\\1\\0\end{matrix}\right]$; \  $C=\left[\begin{matrix}1&0&0&0\\0&0&0&1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Требуется рассчитать управление и построить наблюдатель минимального порядка.
\end{russian}}


\bigskip


\bigskip

{\begin{russian}\sffamily
Объект имеет собственные числа
\end{russian}}

\begin{equation*}
λ_1=0\;;\;\;λ_2\text{=+}1\;;\;\;λ_3=-1\;;\;\;λ_4=-2\;\;
\end{equation*}
{\begin{russian}\sffamily
и характеристический полином
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ϕ_A(λ)=λ^4+2λ^3-λ^2-2λ$.
\end{russian}}

{\begin{russian}\sffamily
Найдём матрицу управляемости:
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$U=\left[\begin{matrix}B&\normalsubformula{\text{AB}}&A^2B&A^3B\end{matrix}\right]=\left[\begin{matrix}0&0&1&0\\0&1&0&1\\1&-1&1&-1\\0&1&-3&7\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Её определитель  $\text{det}U=-6$, то есть отличен от нуля. Это означает, что объект управляем. Рассчитаем закон
управления (матрицу обратной связи), обеспечивающий следующие желаемые собственные числа замкнутой системы:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_1^з=λ_2^з=λ_3^з=λ_4^з=-1$,
\end{russian}}

{\begin{russian}\sffamily
которым соответствует характеристический полином
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $ϕ_{A^c}(λ)=λ^4+4λ^3+6λ^2+4λ+1$.
\end{russian}}

{\begin{russian}\sffamily
Таким образом, имея коэффициенты характеристических полиномов объекта и желаемой замкнутой системы
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\vec α=\left[\begin{matrix}2\\-1\\-2\\0\end{matrix}\right]\;;\;\;\ \;\vec
γ=\left[\begin{matrix}4\\6\\4\\1\end{matrix}\right]$,
\end{russian}}

{\begin{russian}\sffamily
можно в соответствии с (3.9.18) рассчитать матрицу обратной связи в базисе УКП:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_U=\left[\begin{matrix}-1&-6&-7&-2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Чтобы найти эту матрицу в исходном базисе, нужно знать матрицу  $U_H$ перехода от исходного базиса \ к базису УКП. Так
как столбцы этой матрицы являются координатными столбцами векторов базиса  $[u]$ (УКП)  $\vec u_1\;,\;\;\vec
u_2\;,\;\;...\;\;,\;\;\vec u_n$ в исходном базисе  $[h]$, то, используя (3.8.6), можно записать:
\end{russian}}

{\begin{russian}\sffamily
\ \  $\vec u_{\mathit{h4}}=\vec b_h=\left[\begin{matrix}0\\0\\1\\0\end{matrix}\right]\;;\;\;\;\;\vec
u_{\mathit{h3}}=A_H\vec u_{\mathit{h4}}+α_1\vec b_h=\left[\begin{matrix}0\\1\\1\\1\end{matrix}\right]$;
\end{russian}}

\begin{equation*}
\vec u_{\mathit{h2}}=A_H\vec u_{\mathit{h3}}+α_2\vec
b_h=\left[\begin{matrix}1\\2\\-2\\-1\end{matrix}\right]\;;\;\;\;\;\vec u_{\mathit{h1}}=A_H\vec u_{\mathit{h2}}+α_3\vec
b_h=\left[\begin{matrix}2\\0\\0\\0\end{matrix}\right]\;.
\end{equation*}
{\begin{russian}\sffamily
Таким образом, получаем
\end{russian}}

{\begin{russian}\sffamily
\ \  $U_H=\left[\begin{matrix}2&1&0&0\\0&2&1&0\\0&-2&1&1\\0&-1&1&0\end{matrix}\right]$ \ и \ 
$U_H^{-1}=\left[\begin{matrix}\wideslash 12&\wideslash{-1}6&0&\wideslash 16\\0&\wideslash
13&1&\wideslash{-1}3\\0&\wideslash 13&1&\wideslash 23\\0&\wideslash 13&1&\wideslash{-4}3\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (3.9.12)
\end{russian}}

{\begin{russian}\sffamily
\ \  $L\equiv
L_H=L_UU_H^{-1}=\left[\begin{matrix}\wideslash{-1}2&\wideslash{-29}6&-2&\wideslash{-1}6\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (3.6.8)
\end{russian}}

{\begin{russian}\sffamily
\ \  $C_U=\mathit{CU}_H=\left[\begin{matrix}2&1&0&0\\0&-1&1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Используя (3.8.22), запишем передаточные функции:
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{u\;y_1}(p)=\frac 1{p(p+1)(p-1)}$; \  $W_{u\;y_2}(p)=\frac 1{(p+1)(p+2)}$;
\end{russian}}

{\begin{russian}\sffamily
\ \  $W_{v\;y_1}(p)=k^v\frac{p+2}{(p+1)^4}$; \ \  $W_{v\;y_2}(p)=k^v\frac{p(p-1)}{(p+1)^4}$.
\end{russian}}

{\begin{russian}\sffamily
В замкнутой системе будет обеспечена единичная статика по координате  $y_1$, если задать
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $k^v=\frac 1 2$.
\end{russian}}


\bigskip


\bigskip


\bigskip

{\begin{russian}\sffamily
\ \ Теперь перейдём к синтезу наблюдателя. Построим матрицу  $\tilde  N$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $\tilde 
N=\left[\begin{matrix}C\\\normalsubformula{\text{CA}}\end{matrix}\right]=\left[\begin{matrix}1&0&0&0\\0&0&0&1\\0&1&0&0\\0&0&1&-2\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Ранг этой матрицы равен четырём, то есть порядку объекта. Так как старшая степень блока  $\normalsubformula{\text{CA}}$,
входящего в неё, равна единице, то \ индекс наблюдаемости  $ν=2$ и порядок наблюдателя в соответствии с (3.11.54) 
$s=1$. Это означает, что в данном случае может быть построен наблюдатель первого порядка. Зададим единственное
собственное число наблюдателя  $λ_1^N=-4$. Отсюда сразу определяется матрица наблюдателя  $L^q=-4$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Раскроем матричное уравнение Люенбергера (3.11.48), имея в виду, что в данном случае матрица  $C_q$ имеет размер 
$[4\times 1]$. Для этого запишем подробно каждое слагаемое:
\end{russian}}

\begin{equation*}
\begin{matrix}C_qA=\left[\begin{matrix}c_{\mathit{q1}}\hfill\null &c_{\mathit{q2}}\hfill\null
&c_{\mathit{q3}}\hfill\null &c_{\mathit{q4}}\hfill\null \end{matrix}\right]\;\left[\begin{matrix}0\hfill\null
&1\hfill\null &0\hfill\null &0\hfill\null \\0\hfill\null &1\hfill\null &1\hfill\null &0\hfill\null \\0\hfill\null
&0\hfill\null &-1\hfill\null &0\hfill\null \\0\hfill\null &0\hfill\null &1\hfill\null &-2\hfill\null
\end{matrix}\right]=\hfill\null \\=\left[\begin{matrix}0\hfill\null &c_{\mathit{q1}}+c_{\mathit{q2}}\hfill\null
&c_{\mathit{q2}}-c_{\mathit{q3}}+c_{\mathit{q4}}\hfill\null &-2c_{\mathit{q4}}\hfill\null
\end{matrix}\right]\;;\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
\ \ 
$L^qC_q=\left[\begin{matrix}-4c_{\mathit{q1}}&-4c_{\mathit{q2}}&-4c_{\mathit{q3}}&-4c_{\mathit{q4}}\end{matrix}\right]$;
\end{russian}}

{\begin{russian}\sffamily
\ \ 
$G^yC=\left[\begin{matrix}g_{\mathit{y1}}&g_{\mathit{y2}}\end{matrix}\right]\;\left[\begin{matrix}1&0&0&0\\0&0&0&1\end{matrix}\right]=\left[\begin{matrix}g_{\mathit{y1}}&0&0&g_{\mathit{y2}}\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
С учётом этих выражений матричное уравнение Люенбергера можно представить в виде системы скалярных уравнений:
\end{russian}}

\begin{equation*}
\begin{matrix}4c_{\mathit{q1}}=g_{\mathit{y1}};\hfill\null \\c_{\mathit{q1}}+5c_{\mathit{q2}}=0;\hfill\null
\\c_{\mathit{q2}}+3c_{\mathit{q3}}+c_{\mathit{q4}}=0;\hfill\null \\2c_{\mathit{q4}}=g_{\mathit{y2}}\;.\hfill\null
\end{matrix}\hfill 
\end{equation*}

\bigskip

{\begin{russian}\sffamily
Аналогично поступим со вторым матричным уравнением системы (3.11.53), \ учитывая вытекающие из этого уравнения
размерности матриц  $χ$ и  $η$ :
\end{russian}}

\begin{equation*}
\mathit{χC}_q=\left[\begin{matrix}\mathit{χc}_{\mathit{q1}}&\mathit{χc}_{\mathit{q2}}&\mathit{χc}_{\mathit{q3}}&\mathit{χc}_{\mathit{q4}}\end{matrix}\right]\;;
\end{equation*}
\begin{equation*}
\mathit{ηC}=\left[\begin{matrix}η_1&η_2\end{matrix}\right]\;\left[\begin{matrix}1&0&0&0\\0&0&0&1\end{matrix}\right]=\left[\begin{matrix}η_1&0&0&η_2\end{matrix}\right]
\end{equation*}
{\begin{russian}\sffamily
и
\end{russian}}

\begin{equation*}
\begin{matrix}\mathit{χc}_{\mathit{q1}}+η_1=l_1\;;\hfill\null \\\mathit{χc}_{\mathit{q2}}=l_2\;;\hfill\null
\\\mathit{χc}_{\mathit{q3}}=l_3\;;\hfill\null \\\mathit{χc}_{\mathit{q4}}+η_2=l_4\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Таким образом, получено восемь уравнений при наличии девяти неизвестных 
$c_{\mathit{q1}}\;,\;\;c_{\mathit{q2}}\;,\;\;c_{\mathit{q3}}\;,\;\;c_{\mathit{q4}}\;,\;\;g_{\mathit{y1}}\;,\;\;g_{\mathit{y2}}\;,\;\;η_1\;,\;\;η_2\;,\;\;χ$.
Примем  $χ=1$. После этого легко находятся остальные неизвестные:
\end{russian}}

\begin{equation*}
C_q=\left[\begin{matrix}\frac{145} 6&-\frac{29} 6&-2&\frac{65} 6\end{matrix}\right]\;;
\end{equation*}
\begin{equation*}
η=\left[\begin{matrix}-\frac{74} 3&-11\end{matrix}\right]\;;\;\;\;G^y=\left[\begin{matrix}\frac{290} 3&\frac{65}
3\end{matrix}\right]\;.
\end{equation*}
{\begin{russian}\sffamily
В соответствии с (3.11.44) вычисляем 
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $G^u=C_qB=-2$.
\end{russian}}

{\begin{russian}\sffamily
В результате можем записать уравнения регулятора совместно наблюдателем Люенбергера минимального (первого) порядка:
\end{russian}}

\begin{equation*}
\begin{matrix}\vec{\dot q}(t)=-4\vec q(t)-2u(t)+\frac{290} 3y_1(t)+\frac{65} 3y_2(t)\;;\hfill\null \\u(t)=\frac 1
2v(t)+\vec q(t)-\frac{74} 3y_1(t)-11y_2(t)\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Этим уравнениям соответствует структурная схема системы управления, приведённая на рис. 3.23.
\end{russian}}

{\centering  \includegraphics[width=17.33cm,height=12.144cm]{1-img093.png} \par}

\bigskip

\paragraph[Многомерная система с разделением каналов \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем минимального
\ порядка]{Многомерная система с разделением каналов \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ и наблюдателем минимального
\ порядка}
{\begin{russian}\sffamily
Задан объект, представленный структурной схемой на рис. 3.24.
\end{russian}}


\bigskip

{\centering  \includegraphics[width=13.176cm,height=6.006cm]{1-img094.png} \par}
{\begin{russian}\sffamily
Объекту соответствуют матрицы
\end{russian}}

\begin{equation*}
A=\left[\begin{matrix}0&0&0&0\\0&0&0&0\\1&1&0&0\\0&1&1&0\end{matrix}\right]\;;\;\;\;\;B=\left[\begin{matrix}1&0\\0&1\\0&0\\0&0\end{matrix}\right]\;;\;\;\;\;C=\left[\begin{matrix}0&0&1&0\\0&0&0&1\end{matrix}\right]\;.
\end{equation*}
{\begin{russian}\sffamily
Расчёт матриц управляемости и наблюдаемости определяет объект как полностью управляемый и наблюдаемый.
\end{russian}}

\liststyleWWviiiNumxvi
\begin{enumerate}
\item {\begin{russian}\sffamily
\textit{Синтез управления }в соответствии с п.3.10.
\end{russian}}
\end{enumerate}
\liststyleWWviiiNumlxxvi
\begin{enumerate}
\item {\begin{russian}\sffamily
Расчёт чисел  $m_i$:
\end{russian}}
\end{enumerate}
\begin{equation*}
\begin{matrix}C_1A^0B=\left[\begin{matrix}0\hfill\null &0\hfill\null
\end{matrix}\right]\;;\;\;\;\;C_1A^1B=\left[\begin{matrix}1\hfill\null &1\hfill\null \end{matrix}\right]\;;\hfill\null
\\C_2A^0B=\left[\begin{matrix}0\hfill\null &0\hfill\null
\end{matrix}\right]\;;\;\;\;\;C_2A^1B=\left[\begin{matrix}0\hfill\null &1\hfill\null \end{matrix}\right]\;.\hfill\null
\end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Отсюда следует  $m_1=m_2=2$.
\end{russian}}

\liststyleWWviiiNumlxxvi
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Вычисление матриц  $F_{\ast }\;,\;\;B_{\ast }$.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
При  $m_1=m_2=2$
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ }\ \  $F_{\ast
}=-\normalsubformula{\text{CA}}^2=\left[\begin{matrix}0&0&0&0\\-1&-1&0&0\end{matrix}\right]\;;\;\;\;B_{\ast
}=\normalsubformula{\text{CAB}}=\left[\begin{matrix}1&1\\0&1\end{matrix}\right]$.
\end{russian}}

\liststyleWWviiiNumlxxvi
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчёт  $B_{\ast }^{-1}$:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\textenglish{\ \ }\ \  $B_{\ast }^{-1}=\left[\begin{matrix}1&-1\\0&1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Поскольку эта матрица существует, задача разделения каналов имеет решение.
\end{russian}}

\liststyleWWviiiNumlxxvi
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Вычисление матриц  $\underset{\vee }{A}\;,\;\;\underset{\vee }{B}$:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\textenglish{\ \ } $\underset{\vee }{B}=\normalsubformula{\text{BB}}_{\ast
}^{-1}=\left[\begin{matrix}1&-1\\0&1\\0&0\\0&0\end{matrix}\right]\;;\;\;\;\underset{\vee }{A}=A+\underset{\vee
}{B}F_{\ast }=\left[\begin{matrix}1&1&0&0\\-1&-1&0&0\\1&1&0&0\\0&1&1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
В соответствии с (3.10.13) этим матрицам отвечают уравнения
\end{russian}}

\begin{equation*}
\begin{matrix}\dot x_1=x_1+x_2+q_1-q_2\;;\hfill\null \\\dot x_2=-x_1-x_2+q_2\;;\hfill\null \\\dot
x_3=x_1+x_2\;;\hfill\null \\\dot x_4=x_2+x_3\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Соответственно этим уравнениям
\end{russian}}

\begin{equation*}
\begin{matrix}x_3^{(2)}=q_1\;;\hfill\null \\x_4^{(2)}=q_2\;,\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
то есть действительно исходная система разбита на две независимые подсистемы, состоящие из последовательно включённых
интеграторов.
\end{russian}}

\liststyleWWviiiNumlxxvi
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Построение матрицы  $F_e$.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
В данном случае
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ } $F_e=\left[\begin{matrix}\underset{\vee }{A}\underset{\vee }{\vec b_1}&\underset{\vee }{\vec
b_1}&\underset{\vee }{A}\underset{\vee }{\vec b_2}&\underset{\vee }{\vec
b_2}\end{matrix}\right]=\left[\begin{matrix}1&1&0&-1\\-1&0&0&1\\1&0&0&0\\0&0&1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Новому базису соответствуют матрицы
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ }
$A_f=\left[\begin{matrix}0&1&0&0\\0&0&0&0\\0&0&0&1\\0&0&0&0\end{matrix}\right]\;;\;\;\;B_f=\left[\begin{matrix}0&0\\1&0\\0&0\\0&1\end{matrix}\right]\;;\;\;\;C_f=\left[\begin{matrix}1&0&0&0\\0&0&1&0\end{matrix}\right]$.
\end{russian}}

\liststyleWWviiiNumlxxvi
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчёт матрицы обратной связи промежуточной системы в базисе  $[f]$.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
Зададим желаемые собственные числа для первого канала
\end{russian}}

\begin{equation*}
λ_{1\;1,2}=-1\pm \mathit{j1}
\end{equation*}
{\begin{russian}\sffamily
и для второго канала
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $λ_{2\;1,2}=-5\pm \mathit{j5}$.
\end{russian}}

{\begin{russian}\sffamily
Им соответствуют характеристические полиномы
\end{russian}}

\begin{equation*}
\begin{matrix}ϕ_1(λ)=λ^2+2λ+2\;;\hfill\null \\ϕ_2(λ)=λ^2+10λ+50\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Получаем строки матрицы  $L_f$:
\end{russian}}

\begin{equation*}
l_{\mathit{f1}}=\left[\begin{matrix}-2&-2\end{matrix}\right]\;;\;\;\;\;\;\;l_{\mathit{f2}}=\left[\begin{matrix}-50&-10\end{matrix}\right]\;
\end{equation*}
{\begin{russian}\sffamily
и саму матрицу
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $L_f=\left[\begin{matrix}-2&-2&0&0\\0&0&-50&-10\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Пункты 7 и 8 итогового алгоритма расчёта управления для данного случая не нужны, так как в рассматриваемом примере
сумма порядков подсистем  $m_1+m_2$ равна порядку объекта, и матрица  $A_{00}$ отсутствует.
\end{russian}}

\liststyleWWviiiNumix
\begin{enumerate}
\item {\begin{russian}\sffamily
Расчёт матрицы при командном сигнале.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
Потребуем выполнения равенства
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ }\ \  $W_{\mathit{v1}\;\mathit{y1}}(0)=W_{\mathit{v2}\;\mathit{y2}}(0)=1$.
\end{russian}}

{\begin{russian}\sffamily
Тогда
\end{russian}}

\begin{equation*}
\underset{\vee }{k_1^v}=2\;;\;\;\;\;\underset{\vee }{k_2^v}=50\;
\end{equation*}
{\begin{russian}\sffamily
и
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ }\ \  $\underset{\vee }{k^v}=\left[\begin{matrix}2&0\\0&50\end{matrix}\right]$.
\end{russian}}

\liststyleWWviiiNumlxvii
\begin{enumerate}
\item {\begin{russian}\sffamily
Расчёт матрицы обратной связи промежуточной системы в исходном базисе:
\end{russian}}
\end{enumerate}
\begin{equation*}
\begin{matrix}\ \ \ \underset{\vee }{L}=L_fF_e^{-1}=\left[\begin{matrix}-2\hfill\null &-2\hfill\null &0\hfill\null
&0\hfill\null \\0\hfill\null &0\hfill\null &-50\hfill\null &-10\hfill\null
\end{matrix}\right]\;\left[\begin{matrix}0\hfill\null &0\hfill\null &1\hfill\null &0\hfill\null \\1\hfill\null
&1\hfill\null &0\hfill\null &0\hfill\null \\0\hfill\null &0\hfill\null &0\hfill\null &1\hfill\null \\0\hfill\null
&1\hfill\null &1\hfill\null &0\hfill\null \end{matrix}\right]=\hfill\null \\=\left[\begin{matrix}-2\hfill\null
&-2\hfill\null &-2\hfill\null &0\hfill\null \\0\hfill\null &-10\hfill\null &-10\hfill\null &-50\hfill\null
\end{matrix}\right]\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
\liststyleWWviiiNumlxvii
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчёт результирующей матрицы обратной связи:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \  $L=B_{\ast }^{-1}(F_{\ast }+\underset{\vee }{L})=\left[\begin{matrix}-1&9&8&50\\-1&-11&-10&-50\end{matrix}\right]$.
\end{russian}}

\liststyleWWviiiNumlxvii
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Расчёт матрицы передаточных коэффициентов по вектору командных сигналов:
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
\ \ \ \  $k^v=B_{\ast }^{-1}\underset{\vee }{k^v}=\left[\begin{matrix}2&-50\\0&50\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
\ \ Таким образом, получено управление, использующее координаты вектора состояния объекта:
\end{russian}}

\begin{equation*}
\begin{matrix}u_1=-x_1+9x_2+8x_3+50x_4+2v_1-50v_2\;;\hfill\null \\u_2=-x_1-11x_2-10x_3-50x_4+50v_2\;.\hfill\null
\end{matrix}\hfill 
\end{equation*}
\liststyleWWviiiNuml
\begin{enumerate}
\item {\begin{russian}\sffamily
\textit{Синтез наблюдателя }в соответствии с п.3.11.3.
\end{russian}}

\begin{enumerate}
\item {\begin{russian}\sffamily
Расчёт индекса наблюдаемости.
\end{russian}}
\end{enumerate}
\end{enumerate}
{\begin{russian}\sffamily
Строим матрицу  $\tilde  N$:
\end{russian}}

{\begin{russian}\sffamily
\ \ \textenglish{\ \ } $\tilde 
N=\left[\begin{matrix}C\\\normalsubformula{\text{CA}}^{2-1}\end{matrix}\right]=\left[\begin{matrix}0&0&1&0\\0&0&0&1\\1&1&0&0\\0&1&1&0\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
Эта матрица имеет 4 линейно независимые строки, её детерминант отличен от нуля, значит, \ 
$\normalsubformula{\text{rank}}(\tilde  N)=4=n$. Следовательно, индекс наблюдаемости объекта  $ν=2$ и размерность
наблюдателя  $s=2$.
\end{russian}}

\liststyleWWviiiNumxxxviii
\begin{enumerate}
\item {\begin{russian}\sffamily
Задание динамики наблюдателя.
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
Зададим собственные числа  $λ_{1,2}^N=-10$. Соответственно матрица динамики наблюдателя
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \   $L^q=\left[\begin{matrix}-10&0\\0&-10\end{matrix}\right]$.
\end{russian}}

\liststyleWWviiiNumxxxviii
\setcounter{saveenum}{\value{enumi}}
\begin{enumerate}
\setcounter{enumi}{\value{saveenum}}
\item {\begin{russian}\sffamily
Решение системы матричных уравнений \ (3.11.53).
\end{russian}}
\end{enumerate}
{\begin{russian}\sffamily
Матрица  $C_q$ имеет размерность  $[2\times 4]$, матрицы  $G^y$,  $γ\;$,  $η\;$ - \  $[2\times 2]$.
\end{russian}}

{\begin{russian}\sffamily
Следовательно, система скалярных уравнений, соответствующая системе матричных уравнений \ (3.11.53), содержит 16
уравнений и 20 неизвестных. Таким образом, мы имеем право произвольно задать 4 «лишних» неизвестных. Зададим матрицу 
$χ$ единичной, то есть
\end{russian}}

{\begin{russian}\sffamily
\ \ \ \  $χ=\left[\begin{matrix}1&0\\0&1\end{matrix}\right]$.
\end{russian}}

{\begin{russian}\sffamily
С учётом этого из первого матричного уравнения (3.11.53) получим следующую систему уравнений:
\end{russian}}

\begin{equation*}
\begin{matrix}\;1)\;\;c_{q13}+10c_{q11}=0\;;5)\;\;c_{q23}+10c_{q21}=0\;;\hfill\null
\\\;2)\;c_{q13}+c_{q14}+10c_{q12}=0\;;6)\;\;c_{q23}+c_{q24}+10c_{q22}=0\;;\hfill\null
\\\;3)\;c_{q14}+10c_{q13}=g_{11}\;;7)\;\;c_{q24}+10c_{q23}=g_{21}\;;\hfill\null
\\\;4)\;10c_{q14}=g_{12}\;;8)\;\;10c_{q24}=g_{22}\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Второе матричное уравнение (3.11.53) преобразуется в систему скалярных уравнений:
\end{russian}}

{\begin{russian}\sffamily
\ \  $9)\;\;c_{q11}=-1\;;$ \ \ \ \ \ \ \ \ \ \  $12)\;\;c_{q14}+η_{12}=50\;;$ \ \ \ \ \  $15)\;\;c_{q23}+η_{21}=-10\;;$
\end{russian}}

{\begin{russian}\sffamily
 $10)\;\;c_{q12}=9\;;$ \ \ \ \ \ \ \ \ \ \ \ \  $13)\;\;c_{q21}=-1\;;$ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
$16)\;\;c_{q24}+η_{22}=-50\;.$
\end{russian}}

{\begin{russian}\sffamily
 $11)\;\;\;c_{q13}+η_{11}=8\;;$ \ \ \  $14)\;\;c_{q22}=-11\;;$
\end{russian}}

{\begin{russian}\sffamily
Совместное решение последних шестнадцати скалярных уравнений позволяет найти все элементы искомых матриц:
\end{russian}}


\bigskip

\begin{equation*}
C_q=\left[\begin{matrix}-1&9&10&-100\\-1&-11&10&100\end{matrix}\right]\;;\;\;\;\;G^y=\left[\begin{matrix}0&-1000\\200&+1000\end{matrix}\right]\;;\;\;\;\;η=\left[\begin{matrix}-2&150\\-20&-150\end{matrix}\right]\;.
\end{equation*}
{\begin{russian}\sffamily
\ \ Используя (3.11.44), вычислим матрицу
\end{russian}}

{\begin{russian}\sffamily
\textenglish{\ \ }\ \  $G^u=C_qB=\left[\begin{matrix}-1&9\\-1&-11\end{matrix}\right]$ .
\end{russian}}

\liststyleWWviiiNumlxi
\begin{enumerate}
\item {\begin{russian}\sffamily
В соответствии с полученными результатами записать уравнения регулятора, включая наблюдатель:
\end{russian}}
\end{enumerate}
\begin{equation*}
\begin{matrix}\dot q_1(t)=-\text{10 \{}\normalsubformula q_1(t)-1000y_2(t)-u_1(t)+9u_2(t)\;;\hfill\null
\end{matrix}\hfill 
\end{equation*}
\begin{equation*}
\begin{matrix}u_1(t)=q_1(t)-2y_1(t)+150y_2(t)+2v_1(t)-50v_2(t)\;;\hfill\null
\\u_2(t)=q_2(t)-20y_1(t)-150y_2(t)+50v_2(t)\;.\hfill\null \end{matrix}\hfill 
\end{equation*}
{\begin{russian}\sffamily
Результирующая структурная схема замкнутой системы представлена на рис. 3.25. 
\end{russian}}

{\begin{russian}\sffamily
На рис. 3.26 показана итоговая структурная схема системы управления с использованием передаточных функций. Как и
отмечалось выше, передаточные функции, связывающие соответствующие координаты вектора входа и вектора выхода системы,
не зависят от наличия наблюдателя. Из рисунка хорошо видно, что результирующая система имеет полностью развязанные
каналы, по каждому из каналов обеспечены единичная статика и заданные при синтезе собственные числа ( полюсы
передаточных функций).
\end{russian}}


\bigskip

 \includegraphics[width=16.99cm,height=14.656cm]{1-img095.png} 


\bigskip


\bigskip

{\centering  \includegraphics[width=12.779cm,height=7.303cm]{1-img096.png} \par}
\clearpage{\begin{russian}\sffamily\bfseries
\hypertarget{RefHeadingToc455659758}{}Список литературы
\end{russian}}


\bigskip

{\begin{russian}\sffamily
1.Андреев Ю.Н. Управление конечномерными линейными объектами. –М.: Наука, 1976. –424 с. 
\end{russian}}

{\begin{russian}
\textsf{2.Бесекерский В.А., Попов Е.П. Теория систем автоматического регулирования. –М.: Наука, 1982. –304 с.: ил.}
\end{russian}}

{\begin{russian}\sffamily
3. Воронов А.А. Устойчивость, управляемость, наблюдаемость.- М.:Наука, 1979.-335с.:ил.
\end{russian}}

{\begin{russian}
\textsf{4.Деруссо П., Рой Р., Клоуз С. Пространство состояний в теории управления. –М.: Наука, 1970. –620 с.: ил.}
\end{russian}}

{\begin{russian}\sffamily
5.Ерофеев А.А. Теория автоматического управления: Учебник для вузов. -СПб.: Политехника, 1998. -295 с.: ил. 
\end{russian}}

{\begin{russian}\sffamily
6.Квакернаак Х., Сиван Р. Линейные оптимальные системы управления. –М.: Мир, 1977. –650 с.: ил.
\end{russian}}

{\begin{russian}
\textsf{7.Красовский А.А., Поспелов Г.С. Основы автоматики и технической кибернетики. М.-Л.: Госэнергоиздат, 1962.- 600
с. с черт.}
\end{russian}}

{\begin{russian}\sffamily
8.Острём К., Виттенмарк Б. Системы управления с ЭВМ: Пер. с англ. –М.: Мир, 1987. –480 с.: ил.
\end{russian}}

{\begin{russian}\sffamily
9.Попов Е.П. Теория линейных систем автоматического регулирования и управления. –М.: Наука, 1978. –256 с.: ил.
\end{russian}}

{\begin{russian}
\textsf{10.Попов Е.П. Теория нелинейных систем автоматического регулирования и управления. –М.: Наука, 1979. –256 с.:
ил.}
\end{russian}}

{\begin{russian}
\textsf{11.Сборник задач по теории автоматического регулирования и управления / Под ред. В.А.Бесекерского. 5-е изд.,
перераб. и доп.-М.: Наука, 1978. – 510 с.:ил.}
\end{russian}}

{\begin{russian}
\textsf{12.Синтез дискретных регуляторов при помощи ЭВМ / В.В.Григорьев, В.Н.Дроздов, В.В.Лаврентьев, А.В.Ушаков.–Л.:
Машиностроение, Ленингр. отд-ние, 1983. –245 с.}
\end{russian}}

{\begin{russian}
\textsf{13.Современная теория управления / Под ред. К.Т.Леондеса. –М.: Наука, 1970. –512 с.: ил. \ \ }
\end{russian}}

{\begin{russian}
\textsf{14.Теория автоматического управления. Часть }\textenglish{\textsf{I}}\textsf{ / Под ред. А.В.Нетушила. –М.:
Высшая школа, 1968. –424 с.: ил.}
\end{russian}}

{\begin{russian}
\textsf{15.Теория автоматического управления. Часть }\textenglish{\textsf{II}}\textsf{ / Под ред. А.В.Нетушила.–М.:
Высшая школа, 1972. –432 с.: ил.}
\end{russian}}

{\begin{russian}
\textsf{16.Теория автоматического управления. Часть }\textenglish{\textsf{I}}\textsf{ / Под ред. А.А.Воронова. –М.:
Высшая школа, 1977. –303 с.: ил.}
\end{russian}}

{\begin{russian}
\textsf{17.Теория автоматического управления. Часть }\textenglish{\textsf{II}}\textsf{ / Под ред. А.А.Воронова. –М.:
Высшая школа, 1977. –288 с.: ил.}
\end{russian}}

{\begin{russian}\sffamily
18.Ту Юлиус Т. Цифровые и импульсные системы автоматического управления: Пер. с англ.- М.: Машиностроение, 1964. – 703
с.: ил.
\end{russian}}

{\begin{russian}
\textsf{19.Ту Ю.Т. Современная теория управления: Пер. с англ. –М.: Машиностроение, 1965. –704 с.: ил.}
\end{russian}}

{\begin{russian}\sffamily
20.Циплаков А.П. Задачник по теории автоматического регулирования.- М.: Машиностроение,1977. -592 с.: ил.
\end{russian}}

{\begin{russian}\sffamily
21.Цыпкин Я.З. Основы теории автоматических систем. –М.: Наука, 1977. –560 с.: ил.
\end{russian}}

\clearpage
\bigskip

{\begin{russian}\sffamily\bfseries
ОГЛАВЛЕНИЕ
\end{russian}}


\bigskip

\setcounter{tocdepth}{1}
\renewcommand\contentsname{}
\tableofcontents

\bigskip

\clearpage
\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip

{\centering\begin{russian}\sffamily
Евгений Эрастович Страшинин
\end{russian}\par}


\bigskip

{\centering\begin{russian}\sffamily\bfseries
Основы теории автоматического управления
\end{russian}\par}


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip


\bigskip

{\centering\begin{russian}\sffamily
Редактор издательства – Л.Ю.Козяйчева
\end{russian}\par}


\bigskip


\bigskip


\bigskip


\bigskip

{\centering\begin{russian}\sffamily
ЛР № 020315 от 23.12.1996 г.
\end{russian}\par}


\bigskip

{\begin{russian}\sffamily
Подписано в печать 23.06.2000 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Формат 60х84
\ \textsuperscript{1}/\textsubscript{16}
\end{russian}}

{\begin{russian}\sffamily
Бумага писчая \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Офсетная печать
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Усл.печ.л. 12,6 
\end{russian}}

{\begin{russian}\sffamily
Уч.-изд. л. 11,7 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Тираж 220 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Заказ
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Цена «С»
\end{russian}}

{\centering\begin{russian}\sffamily
Издательство УГТУ – УПИ
\end{russian}\par}

{\centering\begin{russian}\sffamily
620002, Екатеринбург, Мира, 19
\end{russian}\par}

{\centering\begin{russian}\sffamily
Цех № 4 \ ОАО «Полиграфист». Екатеринбург, Тургенева, 20
\end{russian}\par}


\bigskip


\bigskip
\end{document}
